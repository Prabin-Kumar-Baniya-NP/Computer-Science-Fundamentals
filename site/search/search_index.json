{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"Computer%20Networking/01.Basics/01.Basics/","text":"Introduction Protocol - A defined set of standards that computers must follow in order to communicate with other computers properly. Computer Networking - The name we've given to the full scope of how computers communicate with each other. OSI VS TCP/IP Model OSI model is a generic model that is based upon functionalities of each layer. TCP/IP model is a protocol-oriented standard. OSI model gives guidelines on how communication needs to be done, while TCP/IP protocols layout standards on which the Internet was developed. So, TCP/IP is a more practical model. TCP/IP 5 Layer Network Model Physical Layer (Cables, Connectors) - It represents the physical devices that interconnect computers. Data Link Layer (Ethernet, Wifi) - It defines how these streams of bits are put together into manageable chunks of data. Network Layer (IP) - It allows devices of different networks to communicate with each other. Transport Layer (TCP/UDP) - It sorts out which client and server programs are supposed to get the data. Application Layer (HTTPS, SMTP) - It allows the user to interact with the application. Hub, Switch, Routers A Hub is a physical layer device that allows for connections from many computers at once. Switch is similar to a hub but a switch is a datalink layer device. A router is a device that knows how to forward data between independent networks. It is network layer device. Types of Computer Network Local Area Network Personal Area Network Metropolitan Area Network Wide Area Network","title":"Terminology"},{"location":"Computer%20Networking/01.Basics/01.Basics/#introduction","text":"Protocol - A defined set of standards that computers must follow in order to communicate with other computers properly. Computer Networking - The name we've given to the full scope of how computers communicate with each other.","title":"Introduction"},{"location":"Computer%20Networking/01.Basics/01.Basics/#_1","text":"","title":""},{"location":"Computer%20Networking/01.Basics/01.Basics/#osi-vs-tcpip-model","text":"OSI model is a generic model that is based upon functionalities of each layer. TCP/IP model is a protocol-oriented standard. OSI model gives guidelines on how communication needs to be done, while TCP/IP protocols layout standards on which the Internet was developed. So, TCP/IP is a more practical model.","title":"OSI VS TCP/IP Model"},{"location":"Computer%20Networking/01.Basics/01.Basics/#tcpip-5-layer-network-model","text":"Physical Layer (Cables, Connectors) - It represents the physical devices that interconnect computers. Data Link Layer (Ethernet, Wifi) - It defines how these streams of bits are put together into manageable chunks of data. Network Layer (IP) - It allows devices of different networks to communicate with each other. Transport Layer (TCP/UDP) - It sorts out which client and server programs are supposed to get the data. Application Layer (HTTPS, SMTP) - It allows the user to interact with the application.","title":"TCP/IP 5 Layer Network Model"},{"location":"Computer%20Networking/01.Basics/01.Basics/#hub-switch-routers","text":"A Hub is a physical layer device that allows for connections from many computers at once. Switch is similar to a hub but a switch is a datalink layer device. A router is a device that knows how to forward data between independent networks. It is network layer device.","title":"Hub, Switch, Routers"},{"location":"Computer%20Networking/01.Basics/01.Basics/#types-of-computer-network","text":"Local Area Network Personal Area Network Metropolitan Area Network Wide Area Network","title":"Types of Computer Network"},{"location":"Computer%20Networking/01.Basics/02.TransmissionMode/","text":"Transmission Mode The way in which data is transmitted from one device to another device is known as transmission mode. It is divided into 3 categories - Simplex Mode, Half-Duplex, Full-Duplex 1. Simplex Mode Definition : Data Flow in one direction Example : Keyboard and monitor - Keyboard can only accept data from the users. Monitor can only display data from the users. Advantage : The station can utilize the entire bandwidth of the communication channel. Disadvantage : Communication is unidirectional. 2. Half-duplex Mode Definition : Data transmission in either direction but not simultaneous. Example : Walkie-talkie. Advantage : Both the device can send and receive data. Disadvantage : When one device is sending data, another has to wait. 3. Full-duplex Mode Definition : Communication is birectional. Example : Telephone Network Advantage : Both the device can send and receive data simultaneously. Disadvantage : Capacity of communication channel is divided into two parts.","title":"Transmission Mode"},{"location":"Computer%20Networking/01.Basics/02.TransmissionMode/#transmission-mode","text":"The way in which data is transmitted from one device to another device is known as transmission mode. It is divided into 3 categories - Simplex Mode, Half-Duplex, Full-Duplex","title":"Transmission Mode"},{"location":"Computer%20Networking/01.Basics/02.TransmissionMode/#1-simplex-mode","text":"Definition : Data Flow in one direction Example : Keyboard and monitor - Keyboard can only accept data from the users. Monitor can only display data from the users. Advantage : The station can utilize the entire bandwidth of the communication channel. Disadvantage : Communication is unidirectional.","title":"1. Simplex Mode"},{"location":"Computer%20Networking/01.Basics/02.TransmissionMode/#2-half-duplex-mode","text":"Definition : Data transmission in either direction but not simultaneous. Example : Walkie-talkie. Advantage : Both the device can send and receive data. Disadvantage : When one device is sending data, another has to wait.","title":"2. Half-duplex Mode"},{"location":"Computer%20Networking/01.Basics/02.TransmissionMode/#3-full-duplex-mode","text":"Definition : Communication is birectional. Example : Telephone Network Advantage : Both the device can send and receive data simultaneously. Disadvantage : Capacity of communication channel is divided into two parts.","title":"3. Full-duplex Mode"},{"location":"Computer%20Networking/01.Basics/03.Topology/","text":"Introduction It defines the structure of network of how all the network devices are interconnnected with each other. [Images From Javatpoint] Bus Topology The bus topology is designed in such a way that all the stations are connected through a single cable. Ring Topology Ring topology is like a bus topology, but with connected ends. The node that receives the message from the previous computer will retransmit to the next node. Star Topology Star topology is an arrangement of the network in which every node is connected to the central hub, switch or a central computer. Tree Topology Tree topology combines the characteristics of bus topology and star topology. Mesh Topology Mesh technology is an arrangement of the network in which computers are interconnected with each other through various redundant connections. Hybrid Topology The combination of various different topologies is known as Hybrid topology.","title":"Topology"},{"location":"Computer%20Networking/01.Basics/03.Topology/#introduction","text":"It defines the structure of network of how all the network devices are interconnnected with each other. [Images From Javatpoint]","title":"Introduction"},{"location":"Computer%20Networking/01.Basics/03.Topology/#bus-topology","text":"The bus topology is designed in such a way that all the stations are connected through a single cable.","title":"Bus Topology"},{"location":"Computer%20Networking/01.Basics/03.Topology/#ring-topology","text":"Ring topology is like a bus topology, but with connected ends. The node that receives the message from the previous computer will retransmit to the next node.","title":"Ring Topology"},{"location":"Computer%20Networking/01.Basics/03.Topology/#star-topology","text":"Star topology is an arrangement of the network in which every node is connected to the central hub, switch or a central computer.","title":"Star Topology"},{"location":"Computer%20Networking/01.Basics/03.Topology/#tree-topology","text":"Tree topology combines the characteristics of bus topology and star topology.","title":"Tree Topology"},{"location":"Computer%20Networking/01.Basics/03.Topology/#mesh-topology","text":"Mesh technology is an arrangement of the network in which computers are interconnected with each other through various redundant connections.","title":"Mesh Topology"},{"location":"Computer%20Networking/01.Basics/03.Topology/#hybrid-topology","text":"The combination of various different topologies is known as Hybrid topology.","title":"Hybrid Topology"},{"location":"Computer%20Networking/02.Physical%20Layer/01.Terminology/","text":"Basic Terminology Bandwidth The maximum amount of data that can be transmitted over an internet connection in a given amount of time. Speed Speed is how fast the information is received. Latency Latency is the delay which we experience in getting the information from the source.","title":"Basic Terminology"},{"location":"Computer%20Networking/02.Physical%20Layer/01.Terminology/#basic-terminology","text":"","title":"Basic Terminology"},{"location":"Computer%20Networking/02.Physical%20Layer/01.Terminology/#bandwidth","text":"The maximum amount of data that can be transmitted over an internet connection in a given amount of time.","title":"Bandwidth"},{"location":"Computer%20Networking/02.Physical%20Layer/01.Terminology/#speed","text":"Speed is how fast the information is received.","title":"Speed"},{"location":"Computer%20Networking/02.Physical%20Layer/01.Terminology/#latency","text":"Latency is the delay which we experience in getting the information from the source.","title":"Latency"},{"location":"Computer%20Networking/02.Physical%20Layer/02.Encoding/","text":"Digital to Digital Encoding / Conversion When the binary 0's and 1's generated by the computer are translated into a sequence of voltage pulses that can be propagated over a wire, then this process is known as digital-to-digital encoding. Categories of Digital-to-digital Encoding Unipolar Polar Bipolar Analog to Digital Encoding / Conversion When an analog signal is digitalized, this is called an analog-to-digital conversion. In analog-to-digital conversion, the information contained in a continuous wave form is converted in digital pulses. Techniques for analog to digital conversion PAM (Pulse Amplitude Modulation) PCM (Pulse Code Modulation) For Detailed Information - Link","title":"Digital to Digital Encoding / Conversion"},{"location":"Computer%20Networking/02.Physical%20Layer/02.Encoding/#digital-to-digital-encoding-conversion","text":"When the binary 0's and 1's generated by the computer are translated into a sequence of voltage pulses that can be propagated over a wire, then this process is known as digital-to-digital encoding.","title":"Digital to Digital Encoding / Conversion"},{"location":"Computer%20Networking/02.Physical%20Layer/02.Encoding/#categories-of-digital-to-digital-encoding","text":"Unipolar Polar Bipolar","title":"Categories of Digital-to-digital Encoding"},{"location":"Computer%20Networking/02.Physical%20Layer/02.Encoding/#analog-to-digital-encoding-conversion","text":"When an analog signal is digitalized, this is called an analog-to-digital conversion. In analog-to-digital conversion, the information contained in a continuous wave form is converted in digital pulses.","title":"Analog to Digital Encoding / Conversion"},{"location":"Computer%20Networking/02.Physical%20Layer/02.Encoding/#techniques-for-analog-to-digital-conversion","text":"PAM (Pulse Amplitude Modulation) PCM (Pulse Code Modulation) For Detailed Information - Link","title":"Techniques for analog to digital conversion"},{"location":"Computer%20Networking/02.Physical%20Layer/03.Transmission%20Media/","text":"Transmission Media A communication channel that carries the information from sender to receiver. Classification of Transmission Media Guided Media Unguided Media 1. Guided Media Coaxial Cable Fibre Optics Cable Twisted Pair Cable 2. Unguided Media Radiowaves Microwaves Infrared","title":"Transmission Media"},{"location":"Computer%20Networking/02.Physical%20Layer/03.Transmission%20Media/#transmission-media","text":"A communication channel that carries the information from sender to receiver.","title":"Transmission Media"},{"location":"Computer%20Networking/02.Physical%20Layer/03.Transmission%20Media/#classification-of-transmission-media","text":"Guided Media Unguided Media","title":"Classification of Transmission Media"},{"location":"Computer%20Networking/02.Physical%20Layer/03.Transmission%20Media/#1-guided-media","text":"Coaxial Cable Fibre Optics Cable Twisted Pair Cable","title":"1. Guided Media"},{"location":"Computer%20Networking/02.Physical%20Layer/03.Transmission%20Media/#2-unguided-media","text":"Radiowaves Microwaves Infrared","title":"2. Unguided Media"},{"location":"Computer%20Networking/02.Physical%20Layer/04.Transmission%20Impairement/","text":"Transmission Impairement When the received signal is not identical with that of transmitted signal, then the quality of signal is degraded. This is called transmission impairement. Causes of Transmission Impairement Attenuation Attenuation means loss of energy i.e. the strength of signal decreases with increasing the distance which causes loss of energy. Distortion Distortion occurs when there is change in shape of the signal. Each frequency componenet has its own propagation speed, so they reach at a different time which leads to distortion. Noise When the data is transmitted over a medium, some unwanted siganl is added to it which causes the noise.","title":"Transmission Impairement"},{"location":"Computer%20Networking/02.Physical%20Layer/04.Transmission%20Impairement/#transmission-impairement","text":"When the received signal is not identical with that of transmitted signal, then the quality of signal is degraded. This is called transmission impairement.","title":"Transmission Impairement"},{"location":"Computer%20Networking/02.Physical%20Layer/04.Transmission%20Impairement/#causes-of-transmission-impairement","text":"Attenuation Attenuation means loss of energy i.e. the strength of signal decreases with increasing the distance which causes loss of energy. Distortion Distortion occurs when there is change in shape of the signal. Each frequency componenet has its own propagation speed, so they reach at a different time which leads to distortion. Noise When the data is transmitted over a medium, some unwanted siganl is added to it which causes the noise.","title":"Causes of Transmission Impairement"},{"location":"Computer%20Networking/02.Physical%20Layer/05.Multiplexing/","text":"Multiplexing Why Multiplexing The transmission medium is used to send the signal from sender to receiver. The medium can have one signal over a time. If there are multiple signal to share one medium, then the medium must be divied in such a way that each signal is given some portion of available bandwidth. When multiple signal share common medium, there is a possibility of collision. Multiplexing concept is used to avoid collision. Introduction to Multiplexing It is a technique used to combine and send the multiple data streams over a medium. This process of combining the data stream is known as multiplexing and hardware used for multiplexing is called multiplexer. Multiplexer : Combines n input lines to generate a single output line. Demultiplexer : Separates a signal into its component signals. Multiplexing Techniques Frequency Division Multiplexing Wavelength Division Multiplexing Time Division Multiplexing","title":"Multiplexing"},{"location":"Computer%20Networking/02.Physical%20Layer/05.Multiplexing/#multiplexing","text":"","title":"Multiplexing"},{"location":"Computer%20Networking/02.Physical%20Layer/05.Multiplexing/#why-multiplexing","text":"The transmission medium is used to send the signal from sender to receiver. The medium can have one signal over a time. If there are multiple signal to share one medium, then the medium must be divied in such a way that each signal is given some portion of available bandwidth. When multiple signal share common medium, there is a possibility of collision. Multiplexing concept is used to avoid collision.","title":"Why Multiplexing"},{"location":"Computer%20Networking/02.Physical%20Layer/05.Multiplexing/#introduction-to-multiplexing","text":"It is a technique used to combine and send the multiple data streams over a medium. This process of combining the data stream is known as multiplexing and hardware used for multiplexing is called multiplexer. Multiplexer : Combines n input lines to generate a single output line. Demultiplexer : Separates a signal into its component signals.","title":"Introduction to Multiplexing"},{"location":"Computer%20Networking/02.Physical%20Layer/05.Multiplexing/#multiplexing-techniques","text":"Frequency Division Multiplexing Wavelength Division Multiplexing Time Division Multiplexing","title":"Multiplexing Techniques"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/","text":"Switching The technique of transferring the information from one computer network to another computer network is known as switching. Switching Mode Store and Forward Cut Through Fragment-Free Switching Techniques Circuit Switching (Time Division, Space Divison) Message Switching Packet Switching (Datagram, Virtual Circuit Approach) 1. Circuit Switching A dedicated path between sender and reciever is established. Used in public telephone network. It has 3 phases: circuit establishment, data transfer, circuit disconnnect 2. Message Switching No dedicated path is established between sender and receiver. Message is traferred as a complete unit and routed through intermediate nodes at which it is stored and forwarded. Each and every node stores the entire message and then forward it to the next node. 3. Packet Switching Messages are splitted into packets. Each packet contains some information in it's header such as source address, destination address, sequence number etc These packets will travel accross the network taking the shortest path as possible. All packets are resembled at the receiving end in correct order. There are 2 approach for packet switching: datagram and virtual circuit approach. In datagram approach, nodes takes the routing decision to forward packets. In virtual circuit approach, nodes doesn't take routing descision. A pre-planned route is established.","title":"Switching"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/#switching","text":"The technique of transferring the information from one computer network to another computer network is known as switching.","title":"Switching"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/#switching-mode","text":"Store and Forward Cut Through Fragment-Free","title":"Switching Mode"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/#switching-techniques","text":"Circuit Switching (Time Division, Space Divison) Message Switching Packet Switching (Datagram, Virtual Circuit Approach)","title":"Switching Techniques"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/#1-circuit-switching","text":"A dedicated path between sender and reciever is established. Used in public telephone network. It has 3 phases: circuit establishment, data transfer, circuit disconnnect","title":"1. Circuit Switching"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/#2-message-switching","text":"No dedicated path is established between sender and receiver. Message is traferred as a complete unit and routed through intermediate nodes at which it is stored and forwarded. Each and every node stores the entire message and then forward it to the next node.","title":"2. Message Switching"},{"location":"Computer%20Networking/02.Physical%20Layer/06.Switching/#3-packet-switching","text":"Messages are splitted into packets. Each packet contains some information in it's header such as source address, destination address, sequence number etc These packets will travel accross the network taking the shortest path as possible. All packets are resembled at the receiving end in correct order. There are 2 approach for packet switching: datagram and virtual circuit approach. In datagram approach, nodes takes the routing decision to forward packets. In virtual circuit approach, nodes doesn't take routing descision. A pre-planned route is established.","title":"3. Packet Switching"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/","text":"Introduction to Datalink Layer Physical vs Datalink layer Physical layer describes the way data is actually transmitted on the network medium. Data link layer defines how these streams of bits are put together into manageable chunks of data. Data link layer is responsible for converting data stream to signals bit by bit and to send that over the underlying hardware. At the receiving end, Data link layer picks up data from hardware which are in the form of electrical signals, assembles them in a recognizable frame format, and hands over to upper layer. Services of data link layer Framing Data link layer takes packets from network layer and encapsulate them into frames. Then it sends each frame bit by bit on the hardware. At the receiver's end, datalink layer picks up signals from the hardware and assembles them into frame. Addressing Data link layer provides hardware addressing mechanism. A unique identification number is encoded into network device at the time of manufacturing. Synchronization When the data frame is sent from the sender to receiver, both the network device must be synchronized in order for data tranfer to take place. Flow Control Stations on the same link may have different speed or capacity. Data link layer enables the flow control that enables both machine to exchange data on same speed. Error Detection and Error Correction Data Link Layer protocol provides a mechanism to detect one or more errors. This is achieved by adding error detection bits in the frame and then receiving node can perform an error check. If errors are detected then data link layer will attempt to recver the actual data bits. Types of Errors Single Bit Error: one bit is corrupted Multiple Bit Error: multiple bits are corrupted Burst Error: multiple consecutive bits are corrupted Error Detection Few extra bits are sent along with the actual data to confirm that bits received at other end are same as they were sent. There are 3 ways: Parity Check Cyclic Redundancy Check Checksum Method Error Correction There are two ways: Backward Error Correction : When the receiver detects an error in the data received, it request back the sender to re-transmit the data unit. Forward Error Correction : When the receiver detects an error in the data received, it executes the error-correcting code, which helps it to auto-revover and to correct some kinds of errors.","title":"Introduction to Datalink Layer"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/#introduction-to-datalink-layer","text":"","title":"Introduction to Datalink Layer"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/#physical-vs-datalink-layer","text":"Physical layer describes the way data is actually transmitted on the network medium. Data link layer defines how these streams of bits are put together into manageable chunks of data. Data link layer is responsible for converting data stream to signals bit by bit and to send that over the underlying hardware. At the receiving end, Data link layer picks up data from hardware which are in the form of electrical signals, assembles them in a recognizable frame format, and hands over to upper layer.","title":"Physical vs Datalink layer"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/#services-of-data-link-layer","text":"Framing Data link layer takes packets from network layer and encapsulate them into frames. Then it sends each frame bit by bit on the hardware. At the receiver's end, datalink layer picks up signals from the hardware and assembles them into frame. Addressing Data link layer provides hardware addressing mechanism. A unique identification number is encoded into network device at the time of manufacturing. Synchronization When the data frame is sent from the sender to receiver, both the network device must be synchronized in order for data tranfer to take place. Flow Control Stations on the same link may have different speed or capacity. Data link layer enables the flow control that enables both machine to exchange data on same speed. Error Detection and Error Correction Data Link Layer protocol provides a mechanism to detect one or more errors. This is achieved by adding error detection bits in the frame and then receiving node can perform an error check. If errors are detected then data link layer will attempt to recver the actual data bits.","title":"Services of data link layer"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/#types-of-errors","text":"Single Bit Error: one bit is corrupted Multiple Bit Error: multiple bits are corrupted Burst Error: multiple consecutive bits are corrupted","title":"Types of Errors"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/#error-detection","text":"Few extra bits are sent along with the actual data to confirm that bits received at other end are same as they were sent. There are 3 ways: Parity Check Cyclic Redundancy Check Checksum Method","title":"Error Detection"},{"location":"Computer%20Networking/03.Datalink%20Layer/01.Introduction/#error-correction","text":"There are two ways: Backward Error Correction : When the receiver detects an error in the data received, it request back the sender to re-transmit the data unit. Forward Error Correction : When the receiver detects an error in the data received, it executes the error-correcting code, which helps it to auto-revover and to correct some kinds of errors.","title":"Error Correction"},{"location":"Computer%20Networking/03.Datalink%20Layer/02.Ethernet%20Frame/","text":"Ethernet It is a type of communication protocol that helps to connect devices accross network. Ethernet Frame Ethernet frame starts with Preamble and SFD, both works at the physical layer. Ethernet header contains both Source and Destination MAC address, after which the payload of the frame is present. The last field is CRC which is used to detect the error. Ethernet Frame Description Preamble indicates the receiver that frame is coming and allow the receiver to lock onto the data stream before the actual frame begins. Start of frame delimiter (SFD) indicates that upcoming bits are starting of the frame, which is the destination address. The SFD warns station or stations that this is the last chance for synchronization. Destination Address contains the MAC address of machine for which data is destined. Source Address \u2013 This is a 6-Byte field which contains the MAC address of source machine. Data \u2013 This is the place where actual data is inserted, also known as Payload. Both IP header and data will be inserted here if Internet Protocol is used over Ethernet. Cyclic Redundancy Check (CRC) \u2013 CRC is 4 Byte field. This field contains a 32-bits hash code of data, which is generated over the Destination Address, Source Address, Length, and Data field. If the checksum computed by destination is not the same as sent checksum value, data received is corrupted.","title":"Ethernet"},{"location":"Computer%20Networking/03.Datalink%20Layer/02.Ethernet%20Frame/#ethernet","text":"It is a type of communication protocol that helps to connect devices accross network.","title":"Ethernet"},{"location":"Computer%20Networking/03.Datalink%20Layer/02.Ethernet%20Frame/#ethernet-frame","text":"Ethernet frame starts with Preamble and SFD, both works at the physical layer. Ethernet header contains both Source and Destination MAC address, after which the payload of the frame is present. The last field is CRC which is used to detect the error.","title":"Ethernet Frame"},{"location":"Computer%20Networking/03.Datalink%20Layer/02.Ethernet%20Frame/#ethernet-frame-description","text":"Preamble indicates the receiver that frame is coming and allow the receiver to lock onto the data stream before the actual frame begins. Start of frame delimiter (SFD) indicates that upcoming bits are starting of the frame, which is the destination address. The SFD warns station or stations that this is the last chance for synchronization. Destination Address contains the MAC address of machine for which data is destined. Source Address \u2013 This is a 6-Byte field which contains the MAC address of source machine. Data \u2013 This is the place where actual data is inserted, also known as Payload. Both IP header and data will be inserted here if Internet Protocol is used over Ethernet. Cyclic Redundancy Check (CRC) \u2013 CRC is 4 Byte field. This field contains a 32-bits hash code of data, which is generated over the Destination Address, Source Address, Length, and Data field. If the checksum computed by destination is not the same as sent checksum value, data received is corrupted.","title":"Ethernet Frame Description"},{"location":"Computer%20Networking/03.Datalink%20Layer/03.MAC%20Address/","text":"MAC Address MAC address are 12 digits hexadecimal number / 48 bits number embedded into network card during the time of manufacturing. It is used to uniquely identify a network device. Some Important Terminologies Unicast (one to one): One sender ----- one specific receiver Multicast (one to many): One sender ----- many specific receiver Broadcast (one to all): One sender ----- all receiver","title":"MAC Address"},{"location":"Computer%20Networking/03.Datalink%20Layer/03.MAC%20Address/#mac-address","text":"MAC address are 12 digits hexadecimal number / 48 bits number embedded into network card during the time of manufacturing. It is used to uniquely identify a network device.","title":"MAC Address"},{"location":"Computer%20Networking/03.Datalink%20Layer/03.MAC%20Address/#some-important-terminologies","text":"Unicast (one to one): One sender ----- one specific receiver Multicast (one to many): One sender ----- many specific receiver Broadcast (one to all): One sender ----- all receiver","title":"Some Important Terminologies"},{"location":"Computer%20Networking/04.Network%20Layer/01.IP%20Address/","text":"IP Address It is a 32 bit unique address having information about how to reach a specific host outside the network. It is used to locate a network device connected to other network. Example: 128.11.3.31 IP Address is divided into 5 subclasses An IP address consists of two components: a network ID and a host ID. The network ID identifies the network segment to which the host belongs. The host ID identifies an individual host on some specific network segment. IPv4 and IPv6 IPv4 and IPv6 are internet protocol version 4 and internet protocol version 6, IP version 6 is the new version of Internet Protocol, which is way better than IP version 4 in terms of complexity and efficiency. IPv4 is a 32 bit address but IPv6 is 128 bit address. IPv4 has limited number of IP address but IPv6 has large number of IP address. In IPv4, end-to-end connection integrity is unachievable but in IPv6, end-to-end connection integrity is achievable. IPv4 doesn't provide encryption and authentication but IPv6 provides encryption and authentication.","title":"IP Address"},{"location":"Computer%20Networking/04.Network%20Layer/01.IP%20Address/#ip-address","text":"It is a 32 bit unique address having information about how to reach a specific host outside the network. It is used to locate a network device connected to other network. Example: 128.11.3.31","title":"IP Address"},{"location":"Computer%20Networking/04.Network%20Layer/01.IP%20Address/#ip-address-is-divided-into-5-subclasses","text":"An IP address consists of two components: a network ID and a host ID. The network ID identifies the network segment to which the host belongs. The host ID identifies an individual host on some specific network segment.","title":"IP Address is divided into 5 subclasses"},{"location":"Computer%20Networking/04.Network%20Layer/01.IP%20Address/#ipv4-and-ipv6","text":"IPv4 and IPv6 are internet protocol version 4 and internet protocol version 6, IP version 6 is the new version of Internet Protocol, which is way better than IP version 4 in terms of complexity and efficiency. IPv4 is a 32 bit address but IPv6 is 128 bit address. IPv4 has limited number of IP address but IPv6 has large number of IP address. In IPv4, end-to-end connection integrity is unachievable but in IPv6, end-to-end connection integrity is achievable. IPv4 doesn't provide encryption and authentication but IPv6 provides encryption and authentication.","title":"IPv4 and IPv6"},{"location":"Computer%20Networking/04.Network%20Layer/02.Address%20Resolution%20Protocol/","text":"Address Resolution Protocol It is a communication protocol which is used to find the MAC address of a device from it's IP address. How ARP works [From Geeks for Geeks] In order to send the data to destination, having IP address is necessary but not sufficient; we also need the physical address of the destination machine. ARP is used to get the physical address (MAC address) of destination machine. Before sending the IP packet, the MAC address of destination must be known. If not so, then sender broadcasts the ARP-discovery packet requesting the MAC address of intended destination. Since ARP-discovery is broadcast, every host inside that network will get this message but the packet will be discarded by everyone except that intended receiver host whose IP is associated. Now, this receiver will send a unicast packet with its MAC address (ARP-reply) to the sender of ARP-discovery packet. After the original sender receives the ARP-reply, it updates ARP-cache and start sending unicast message to the destination.","title":"Address Resolution Protocol"},{"location":"Computer%20Networking/04.Network%20Layer/02.Address%20Resolution%20Protocol/#address-resolution-protocol","text":"It is a communication protocol which is used to find the MAC address of a device from it's IP address.","title":"Address Resolution Protocol"},{"location":"Computer%20Networking/04.Network%20Layer/02.Address%20Resolution%20Protocol/#how-arp-works","text":"[From Geeks for Geeks] In order to send the data to destination, having IP address is necessary but not sufficient; we also need the physical address of the destination machine. ARP is used to get the physical address (MAC address) of destination machine. Before sending the IP packet, the MAC address of destination must be known. If not so, then sender broadcasts the ARP-discovery packet requesting the MAC address of intended destination. Since ARP-discovery is broadcast, every host inside that network will get this message but the packet will be discarded by everyone except that intended receiver host whose IP is associated. Now, this receiver will send a unicast packet with its MAC address (ARP-reply) to the sender of ARP-discovery packet. After the original sender receives the ARP-reply, it updates ARP-cache and start sending unicast message to the destination.","title":"How ARP works"},{"location":"Computer%20Networking/04.Network%20Layer/03.Subnetting/","text":"Subnetting It is a process of taking a large network and splitting it into many individual smaller networks or subnets.","title":"Subnetting"},{"location":"Computer%20Networking/04.Network%20Layer/03.Subnetting/#subnetting","text":"It is a process of taking a large network and splitting it into many individual smaller networks or subnets.","title":"Subnetting"},{"location":"Computer%20Networking/04.Network%20Layer/04.Routing/","text":"Routing Routing is a process of selecting a path where data can be transmitted from source to destination. Routing is performed by a router that forwards the packet based on the information available in the packet header and forwarding table. Routers use Routing Tables to determine out which interface the packet will be sent. A routing table lists all networks for which routes are known. Each router\u2019s routing table is unique and stored in the RAM of the device. A routing table is a set of rules, often viewed in table format, that is used to determine where data packets traveling over an Internet Protocol (IP) network will be directed. All IP-enabled devices, including routers and switches, use routing tables. Types of Routing Static Routing : It is a technique in which the administrator manually adds the routes in a routing table. Default Routing : This is the method where the router is configured to send all packets towards a single router (next hop). It doesn\u2019t matter to which network the packet belongs, it is forwarded out to the router which is configured for default routing. It is generally used with stub routers. A stub router is a router that has only one route to reach all other networks. Dynamic Routing : It is a technique in which a router adds a new route in the routing table for each packet in response to the changes in the condition or topology of the network.","title":"Routing"},{"location":"Computer%20Networking/04.Network%20Layer/04.Routing/#routing","text":"Routing is a process of selecting a path where data can be transmitted from source to destination. Routing is performed by a router that forwards the packet based on the information available in the packet header and forwarding table. Routers use Routing Tables to determine out which interface the packet will be sent. A routing table lists all networks for which routes are known. Each router\u2019s routing table is unique and stored in the RAM of the device. A routing table is a set of rules, often viewed in table format, that is used to determine where data packets traveling over an Internet Protocol (IP) network will be directed. All IP-enabled devices, including routers and switches, use routing tables.","title":"Routing"},{"location":"Computer%20Networking/04.Network%20Layer/04.Routing/#types-of-routing","text":"Static Routing : It is a technique in which the administrator manually adds the routes in a routing table. Default Routing : This is the method where the router is configured to send all packets towards a single router (next hop). It doesn\u2019t matter to which network the packet belongs, it is forwarded out to the router which is configured for default routing. It is generally used with stub routers. A stub router is a router that has only one route to reach all other networks. Dynamic Routing : It is a technique in which a router adds a new route in the routing table for each packet in response to the changes in the condition or topology of the network.","title":"Types of Routing"},{"location":"Computer%20Networking/04.Network%20Layer/05.Network%20Layer%20Protocol/","text":"Network Layer Protocol 1. ARP [Address Resolution Protocol] It is a communication protocol which is used to find the MAC address of a device from it's IP address. 2. RARP [Reverse Address Resolution Protocol] It is a protocol which is used to obtain the IP address from a server. If the host wants to know its IP address, then it broadcast the RARP query packet that contains its physical address to the entire network. A RARP server on the network recognizes the RARP packet and responds back with the host IP address. 3. ICMP [Internet Control Message Protocol] 4. IGMP [Internet Group Message Protocol]","title":"Network Layer Protocol"},{"location":"Computer%20Networking/04.Network%20Layer/05.Network%20Layer%20Protocol/#network-layer-protocol","text":"","title":"Network Layer Protocol"},{"location":"Computer%20Networking/04.Network%20Layer/05.Network%20Layer%20Protocol/#1-arp-address-resolution-protocol","text":"It is a communication protocol which is used to find the MAC address of a device from it's IP address.","title":"1. ARP [Address Resolution Protocol]"},{"location":"Computer%20Networking/04.Network%20Layer/05.Network%20Layer%20Protocol/#2-rarp-reverse-address-resolution-protocol","text":"It is a protocol which is used to obtain the IP address from a server. If the host wants to know its IP address, then it broadcast the RARP query packet that contains its physical address to the entire network. A RARP server on the network recognizes the RARP packet and responds back with the host IP address.","title":"2. RARP [Reverse Address Resolution Protocol]"},{"location":"Computer%20Networking/04.Network%20Layer/05.Network%20Layer%20Protocol/#3-icmp-internet-control-message-protocol","text":"","title":"3. ICMP [Internet Control Message Protocol]"},{"location":"Computer%20Networking/04.Network%20Layer/05.Network%20Layer%20Protocol/#4-igmp-internet-group-message-protocol","text":"","title":"4. IGMP [Internet Group Message Protocol]"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/","text":"Transport Layer The main responsibility of transport layer is to provide communication services directly to the application processes running on different host. Transport layer takes data from upper layer (i.e. Application layer) and then breaks it into smaller size segments, numbers each byte, and hands over to lower layer (Network Layer) for delivery. Various Responsibilities of Transport layer From Geeks For Geeks 1. Process to Process delivery While Data Link Layer requires the MAC address (48 bits address contained inside the Network Interface Card of every host machine) of source-destination hosts to correctly deliver a frame and Network layer requires the IP address for appropriate routing of packets, in a similar way Transport Layer requires a Port number to correctly deliver the segments of data to the correct process amongst the multiple processes running on a particular host. A port number is a 16-bit address used to identify any client-server program uniquely. 2. End-to-End Connection between Hosts The transport layer is also responsible for creating the end-to-end Connection between hosts for which it mainly uses TCP and UDP. TCP is a secure, connection-orientated protocol that uses a handshake protocol to establish a robust connection between two end hosts. TCP ensures reliable delivery of messages and is used in various applications. UDP, on the other hand, is a stateless and unreliable protocol that ensures best-effort delivery. It is suitable for applications that have little concern with flow or error control and requires sending the bulk of data like video conferencing. It is often used in multicasting protocols. 3. Multiplexing and Demultiplexing Multiplexing allows simultaneous use of different applications over a network that is running on a host. The transport layer provides this mechanism which enables us to send packet streams from various applications simultaneously over a network. The transport layer accepts these packets from different processes differentiated by their port numbers and passes them to the network layer after adding proper headers. Similarly, Demultiplexing is required at the receiver side to obtain the data coming from various processes. Transport receives the segments of data from the network layer and delivers it to the appropriate process running on the receiver\u2019s machine. 4. Congestion Control Congestion is a situation in which too many sources over a network attempt to send data and the router buffers start overflowing due to which loss of packets occur. As result retransmission of packets from the sources increases the congestion further. In this situation, the Transport layer provides Congestion Control in different ways. It uses open loop congestion control to prevent the congestion and closed loop congestion control to remove the congestion in a network once it occurred. TCP provides AIMD- additive increase multiplicative decrease, leaky bucket technique for congestion control. 5. Data Integrity and Error Correction The transport layer checks for errors in the messages coming from the application layer by using error detection codes, computing checksums, it checks whether the received data is not corrupted and uses the ACK and NACK services to inform the sender if the data has arrived or not and checks for the integrity of data. 6. Flow Control The transport layer provides a flow control mechanism between the adjacent layers of the TCP/IP model. TCP also prevents data loss due to a fast sender and slow receiver by imposing some flow control techniques. It uses the method of sliding window protocol which is accomplished by the receiver by sending a window back to the sender informing the size of data it can receive.","title":"<b>Transport Layer</b>"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#transport-layer","text":"The main responsibility of transport layer is to provide communication services directly to the application processes running on different host. Transport layer takes data from upper layer (i.e. Application layer) and then breaks it into smaller size segments, numbers each byte, and hands over to lower layer (Network Layer) for delivery.","title":"Transport Layer"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#various-responsibilities-of-transport-layer","text":"From Geeks For Geeks","title":"Various Responsibilities of Transport layer"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#1-process-to-process-delivery","text":"While Data Link Layer requires the MAC address (48 bits address contained inside the Network Interface Card of every host machine) of source-destination hosts to correctly deliver a frame and Network layer requires the IP address for appropriate routing of packets, in a similar way Transport Layer requires a Port number to correctly deliver the segments of data to the correct process amongst the multiple processes running on a particular host. A port number is a 16-bit address used to identify any client-server program uniquely.","title":"1. Process to Process delivery"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#2-end-to-end-connection-between-hosts","text":"The transport layer is also responsible for creating the end-to-end Connection between hosts for which it mainly uses TCP and UDP. TCP is a secure, connection-orientated protocol that uses a handshake protocol to establish a robust connection between two end hosts. TCP ensures reliable delivery of messages and is used in various applications. UDP, on the other hand, is a stateless and unreliable protocol that ensures best-effort delivery. It is suitable for applications that have little concern with flow or error control and requires sending the bulk of data like video conferencing. It is often used in multicasting protocols.","title":"2. End-to-End Connection between Hosts"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#3-multiplexing-and-demultiplexing","text":"Multiplexing allows simultaneous use of different applications over a network that is running on a host. The transport layer provides this mechanism which enables us to send packet streams from various applications simultaneously over a network. The transport layer accepts these packets from different processes differentiated by their port numbers and passes them to the network layer after adding proper headers. Similarly, Demultiplexing is required at the receiver side to obtain the data coming from various processes. Transport receives the segments of data from the network layer and delivers it to the appropriate process running on the receiver\u2019s machine.","title":"3. Multiplexing and Demultiplexing"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#4-congestion-control","text":"Congestion is a situation in which too many sources over a network attempt to send data and the router buffers start overflowing due to which loss of packets occur. As result retransmission of packets from the sources increases the congestion further. In this situation, the Transport layer provides Congestion Control in different ways. It uses open loop congestion control to prevent the congestion and closed loop congestion control to remove the congestion in a network once it occurred. TCP provides AIMD- additive increase multiplicative decrease, leaky bucket technique for congestion control.","title":"4. Congestion Control"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#5-data-integrity-and-error-correction","text":"The transport layer checks for errors in the messages coming from the application layer by using error detection codes, computing checksums, it checks whether the received data is not corrupted and uses the ACK and NACK services to inform the sender if the data has arrived or not and checks for the integrity of data.","title":"5. Data Integrity and Error Correction"},{"location":"Computer%20Networking/05.Transport%20Layer/01.Introduction/#6-flow-control","text":"The transport layer provides a flow control mechanism between the adjacent layers of the TCP/IP model. TCP also prevents data loss due to a fast sender and slow receiver by imposing some flow control techniques. It uses the method of sliding window protocol which is accomplished by the receiver by sending a window back to the sender informing the size of data it can receive.","title":"6. Flow Control"},{"location":"Computer%20Networking/05.Transport%20Layer/02.TCP%20and%20UDP/","text":"TCP VS UDP TCP stands for Transmission Control Protocol whereas UDP stands for User Datagram Protocol. TCP is a connection-oriented protocol, which means that the connection needs to be established before the data is transmitted over the network. Whereas, UDP is a connectionless protocol, which means that it sends the data without checking whether the system is ready to receive or not. TCP is a reliable protocol as it provides assurance for the delivery of data packets. Whereas, UDP is an unreliable protocol as it does not take the guarantee for the delivery of packets. TCP is slower than UDP as it performs error checking, flow control, and provides assurance for the delivery of data packets. Whereas, UDP is faster than TCP as it does not guarantee the delivery of data packets. The size of TCP is 20 bytes. Whereas, The size of the UDP is 8 bytes. TCP uses the three-way-handshake concept. In this concept, if the sender receives the ACK, then the sender will send the data. TCP also has the ability to resend the lost data. Whereas, UDP does not wait for any acknowledgment; it just sends the data. TCP follows the flow control mechanism in which too many packets cannot be sent to the receiver at the same time. Whereas, UDP follows no such mechanism. TCP performs error checking by using a checksum. When the data is corrected, then the data is retransmitted to the receiver. Whereas, It does not perform any error checking, and also does not resend the lost data packets. TCP protocol is mainly used where a secure and reliable communication process is required, like military services, web browsing, and e-mail. Whereas, UDP protocol is used where fast communication is required and does not care about the reliability like VoIP, game streaming, video and music streaming, etc.","title":"TCP VS UDP"},{"location":"Computer%20Networking/05.Transport%20Layer/02.TCP%20and%20UDP/#tcp-vs-udp","text":"TCP stands for Transmission Control Protocol whereas UDP stands for User Datagram Protocol. TCP is a connection-oriented protocol, which means that the connection needs to be established before the data is transmitted over the network. Whereas, UDP is a connectionless protocol, which means that it sends the data without checking whether the system is ready to receive or not. TCP is a reliable protocol as it provides assurance for the delivery of data packets. Whereas, UDP is an unreliable protocol as it does not take the guarantee for the delivery of packets. TCP is slower than UDP as it performs error checking, flow control, and provides assurance for the delivery of data packets. Whereas, UDP is faster than TCP as it does not guarantee the delivery of data packets. The size of TCP is 20 bytes. Whereas, The size of the UDP is 8 bytes. TCP uses the three-way-handshake concept. In this concept, if the sender receives the ACK, then the sender will send the data. TCP also has the ability to resend the lost data. Whereas, UDP does not wait for any acknowledgment; it just sends the data. TCP follows the flow control mechanism in which too many packets cannot be sent to the receiver at the same time. Whereas, UDP follows no such mechanism. TCP performs error checking by using a checksum. When the data is corrected, then the data is retransmitted to the receiver. Whereas, It does not perform any error checking, and also does not resend the lost data packets. TCP protocol is mainly used where a secure and reliable communication process is required, like military services, web browsing, and e-mail. Whereas, UDP protocol is used where fast communication is required and does not care about the reliability like VoIP, game streaming, video and music streaming, etc.","title":"TCP VS UDP"},{"location":"Computer%20Networking/06.Session%20Layer/01.Introduction/","text":"Session Layer This layer allows users on different machines to establish active communications sessions between them. It is responsible for establishing, maintaining, synchronizing, terminating sessions between end-user applications. In Session Layer, streams of data are received and further marked, which is then resynchronized properly, so that the ends of the messages are not cut initially and further data loss is avoided. This layer basically establishes a connection between the session entities. This layer handles and manipulates data which it receives from the Session Layer as well as from the Presentation Layer.","title":"Session Layer"},{"location":"Computer%20Networking/06.Session%20Layer/01.Introduction/#session-layer","text":"This layer allows users on different machines to establish active communications sessions between them. It is responsible for establishing, maintaining, synchronizing, terminating sessions between end-user applications. In Session Layer, streams of data are received and further marked, which is then resynchronized properly, so that the ends of the messages are not cut initially and further data loss is avoided. This layer basically establishes a connection between the session entities. This layer handles and manipulates data which it receives from the Session Layer as well as from the Presentation Layer.","title":"Session Layer"},{"location":"Computer%20Networking/07.Presentation%20Layer/01.Introduction/","text":"Presentation Layer Translation: The processes in two systems exchange the information in the form of character strings, numbers and so on. Different computers use different encoding methods, the presentation layer handles the interoperability between the different encoding methods. It converts the data from sender-dependent format into a common format and changes the common format into receiver-dependent format at the receiving end. Encryption: Encryption is needed to maintain privacy. Encryption is a process of converting the sender-transmitted information into another form and sends the resulting message over the network. Compression: Data compression is a process of compressing the data, i.e., it reduces the number of bits to be transmitted. Data compression is very important in multimedia such as text, audio, video.","title":"Presentation Layer"},{"location":"Computer%20Networking/07.Presentation%20Layer/01.Introduction/#presentation-layer","text":"Translation: The processes in two systems exchange the information in the form of character strings, numbers and so on. Different computers use different encoding methods, the presentation layer handles the interoperability between the different encoding methods. It converts the data from sender-dependent format into a common format and changes the common format into receiver-dependent format at the receiving end. Encryption: Encryption is needed to maintain privacy. Encryption is a process of converting the sender-transmitted information into another form and sends the resulting message over the network. Compression: Data compression is a process of compressing the data, i.e., it reduces the number of bits to be transmitted. Data compression is very important in multimedia such as text, audio, video.","title":"Presentation Layer"},{"location":"Computer%20Networking/08.Application%20Layer/01.Introduction/","text":"Application Layer Network Virtual terminal: An application layer allows a user to log on to a remote host. To do so, the application creates a software emulation of a terminal at the remote host. The user's computer talks to the software terminal, which in turn, talks to the host. The remote host thinks that it is communicating with one of its own terminals, so it allows the user to log on. File Transfer, Access, and Management (FTAM): An application allows a user to access files in a remote computer, to retrieve files from a computer and to manage files in a remote computer. FTAM defines a hierarchical virtual file in terms of file structure, file attributes and the kind of operations performed on the files and their attributes. Addressing: To obtain communication between client and server, there is a need for addressing. When a client made a request to the server, the request contains the server address and its own address. The server response to the client request, the request contains the destination address, i.e., client address. To achieve this kind of addressing, DNS is used. Mail Services: An application layer provides Email forwarding and storage. Directory Services: An application contains a distributed database that provides access for global information about various objects and services.","title":"Application Layer"},{"location":"Computer%20Networking/08.Application%20Layer/01.Introduction/#application-layer","text":"Network Virtual terminal: An application layer allows a user to log on to a remote host. To do so, the application creates a software emulation of a terminal at the remote host. The user's computer talks to the software terminal, which in turn, talks to the host. The remote host thinks that it is communicating with one of its own terminals, so it allows the user to log on. File Transfer, Access, and Management (FTAM): An application allows a user to access files in a remote computer, to retrieve files from a computer and to manage files in a remote computer. FTAM defines a hierarchical virtual file in terms of file structure, file attributes and the kind of operations performed on the files and their attributes. Addressing: To obtain communication between client and server, there is a need for addressing. When a client made a request to the server, the request contains the server address and its own address. The server response to the client request, the request contains the destination address, i.e., client address. To achieve this kind of addressing, DNS is used. Mail Services: An application layer provides Email forwarding and storage. Directory Services: An application contains a distributed database that provides access for global information about various objects and services.","title":"Application Layer"},{"location":"Computer%20Networking/08.Application%20Layer/02.Application%20Layer%20Protocols/","text":"Application Layer Protocol The application layer provides several protocols which allow any software to easily send and receive information and present meaningful data to its users. The following are some of the protocols which are provided by the application layer. TELNET: Telnet stands for Telecommunications Network. This protocol is used for managing files over the Internet. It allows the Telnet clients to access the resources of Telnet server. Telnet uses port number 23. DNS: DNS stands for Domain Name System. The DNS service translates the domain name (selected by user) into the corresponding IP address. For example- If you choose the domain name as www.abcd.com, then DNS must translate it as 192.36.20.8 (random IP address written just for understanding purposes). DNS protocol uses the port number 53. DHCP: DHCP stands for Dynamic Host Configuration Protocol. It provides IP addresses to hosts. Whenever a host tries to register for an IP address with the DHCP server, DHCP server provides lots of information to the corresponding host. DHCP uses port numbers 67 and 68. FTP: FTP stands for File Transfer Protocol. This protocol helps to transfer different files from one device to another. FTP promotes sharing of files via remote computer devices with reliable, efficient data transfer. FTP uses port number 20 for data access and port number 21 for data control. SMTP: SMTP stands for Simple Mail Transfer Protocol. It is used to transfer electronic mail from one user to another user. SMTP is used by end users to send emails with ease. SMTP uses port numbers 25 and 587. HTTP: HTTP stands for Hyper Text Transfer Protocol. It is the foundation of the World Wide Web (WWW). HTTP works on the client server model. This protocol is used for transmitting hypermedia documents like HTML. This protocol was designed particularly for the communications between the web browsers and web servers, but this protocol can also be used for several other purposes. HTTP is a stateless protocol (network protocol in which a client sends requests to server and server responses back as per the given state), which means the server is not responsible for maintaining the previous client\u2019s requests. HTTP uses port number 80. NFS: NFS stands for Network File System. This protocol allows remote hosts to mount files over a network and interact with those file systems as though they are mounted locally. NFS uses the port number 2049. SNMP: SNMP stands for Simple Network Management Protocol. This protocol gathers data by polling the devices from the network to the management station at fixed or random intervals, requiring them to disclose certain information. SNMP uses port numbers 161 (TCP) and 162 (UDP).","title":"Application Layer Protocol"},{"location":"Computer%20Networking/08.Application%20Layer/02.Application%20Layer%20Protocols/#application-layer-protocol","text":"The application layer provides several protocols which allow any software to easily send and receive information and present meaningful data to its users.","title":"Application Layer Protocol"},{"location":"Computer%20Networking/08.Application%20Layer/02.Application%20Layer%20Protocols/#the-following-are-some-of-the-protocols-which-are-provided-by-the-application-layer","text":"TELNET: Telnet stands for Telecommunications Network. This protocol is used for managing files over the Internet. It allows the Telnet clients to access the resources of Telnet server. Telnet uses port number 23. DNS: DNS stands for Domain Name System. The DNS service translates the domain name (selected by user) into the corresponding IP address. For example- If you choose the domain name as www.abcd.com, then DNS must translate it as 192.36.20.8 (random IP address written just for understanding purposes). DNS protocol uses the port number 53. DHCP: DHCP stands for Dynamic Host Configuration Protocol. It provides IP addresses to hosts. Whenever a host tries to register for an IP address with the DHCP server, DHCP server provides lots of information to the corresponding host. DHCP uses port numbers 67 and 68. FTP: FTP stands for File Transfer Protocol. This protocol helps to transfer different files from one device to another. FTP promotes sharing of files via remote computer devices with reliable, efficient data transfer. FTP uses port number 20 for data access and port number 21 for data control. SMTP: SMTP stands for Simple Mail Transfer Protocol. It is used to transfer electronic mail from one user to another user. SMTP is used by end users to send emails with ease. SMTP uses port numbers 25 and 587. HTTP: HTTP stands for Hyper Text Transfer Protocol. It is the foundation of the World Wide Web (WWW). HTTP works on the client server model. This protocol is used for transmitting hypermedia documents like HTML. This protocol was designed particularly for the communications between the web browsers and web servers, but this protocol can also be used for several other purposes. HTTP is a stateless protocol (network protocol in which a client sends requests to server and server responses back as per the given state), which means the server is not responsible for maintaining the previous client\u2019s requests. HTTP uses port number 80. NFS: NFS stands for Network File System. This protocol allows remote hosts to mount files over a network and interact with those file systems as though they are mounted locally. NFS uses the port number 2049. SNMP: SNMP stands for Simple Network Management Protocol. This protocol gathers data by polling the devices from the network to the management station at fixed or random intervals, requiring them to disclose certain information. SNMP uses port numbers 161 (TCP) and 162 (UDP).","title":"The following are some of the protocols which are provided by the application layer."},{"location":"Computer%20Networking/08.Application%20Layer/03.DNS/","text":"DNS (Domain Name System) DNS service translates the domain name into corresponding IP address. DNS servers takes domain name and return back corresponsing IP address. Each domain name is typically served by one or more DNS servers for redundancy. Command to get IP address from domain name: nslookup www.google.com Top Level Domains Examples: .com, .in, .np, .ca","title":"DNS (Domain Name System)"},{"location":"Computer%20Networking/08.Application%20Layer/03.DNS/#dns-domain-name-system","text":"DNS service translates the domain name into corresponding IP address. DNS servers takes domain name and return back corresponsing IP address. Each domain name is typically served by one or more DNS servers for redundancy. Command to get IP address from domain name: nslookup www.google.com","title":"DNS (Domain Name System)"},{"location":"Computer%20Networking/08.Application%20Layer/03.DNS/#top-level-domains","text":"Examples: .com, .in, .np, .ca","title":"Top Level Domains"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/","text":"HTTP Stands for Hyper Text Transfer Protocol Web Server is HTTP server. Web Browser is HTTP client. HTTP protocol generally takes place over TCP connection. It listens on port 80. In HTTP, clients sends a HTTP request and server sends backs HTTP response. HTTP is stateless. Client Server Model A server is a process that offers some service. A client is a process that is requesting the service. Server waits for clients to get the request. HTTP Request and Response Message a. HTTP Request Message Request Line Headers A blank Line Body a. HTTP Response Message Status Line Headers A blank Line Body HTTP Methods Get - Requests data from the server HEAD - Requests information about a data but not the data itself. POST - Sends some data to the server PUT - Updates some data to the server TRACE - Echoes the incoming request CONNECT - Reserved OPTION - Inquires about available options HTTP Status Code Informational 100 - Continue 101 - Switching Success 200 - OK : The request is successful 201 - Created : A new URL is created. 202 - Accepted : The request is accepted but it - is not immediately acted upon. 204 - No content : There is no content in the body. Redirection 301 - Moved Permanently : The requested URL is no longer used by the server. 302 - Moved Temporarily : The requested URL has moved temporarily. 304 - Not modified : The document has not been modified. Client Error 400 - Bad Request : There is a error in the request. 401 - Unauthorized : The request lacks proper authorization. 403 - Forbidden : Service is denied. 404 - Not Found : The document is not found. 405 - Method not allowed : This method is not supported in the URL. 406 - Not acceptable : The format reqested is not acceptable. Server Error 500 - Internal Server Error : There is an error at the server side. 501 - Not implemented : The action requeted cannot be performed. 503 - Service unavaible : The service is temporarily unavailable, but may be requested in the future. HTTP Request Header Cache-control : Specifies information about caching. Connection : Shows whether the connection should be closed or not. Date : Shows the current date. MIME-version : Shows the MIME version used. Upgrade : Specifies the preferred communication protocol. Accept Accept-charset Accept-language Authorization User-agent, etc HTTP Response Headers Accept-range Age Public Retry-after Server HTTP Entity Headers Allow Content-encoding Content-language Content-length Content-range Content-type Expires Last-modified Location HTTP1 vs HTTP2 HTTP2 is much faster and more reliable than HTTP1. HTTP1 loads a single request for every TCP connection, while HTTP2 avoids network delay by using multiplexing. Features of HTTP2 Binary Protocol - While HTTP/1.x was a text based protocol, HTTP/2 is a binary protocol resulting in less error during data transfer process. Multiplexed Streams - All HTTP/2 connections are multiplexed streams meaning multiple files can be transferred in a single stream of binary data. Compressed Header - HTTP/2 compresses header data in responses resulting in faster transfer of data. Server Push - This capability allows the server to send linked resources to the client automatically, greatly reducing the number of requests to the server. Stream Prioritization - HTTP/2 can prioritize data streams based on their type resulting in better bandwidth allocation where necessary.","title":"HTTP"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http","text":"Stands for Hyper Text Transfer Protocol Web Server is HTTP server. Web Browser is HTTP client. HTTP protocol generally takes place over TCP connection. It listens on port 80. In HTTP, clients sends a HTTP request and server sends backs HTTP response. HTTP is stateless.","title":"HTTP"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#client-server-model","text":"A server is a process that offers some service. A client is a process that is requesting the service. Server waits for clients to get the request.","title":"Client Server Model"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http-request-and-response-message","text":"","title":"HTTP Request and Response Message"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#a-http-request-message","text":"Request Line Headers A blank Line Body","title":"a. HTTP Request Message"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#a-http-response-message","text":"Status Line Headers A blank Line Body","title":"a. HTTP Response Message"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http-methods","text":"Get - Requests data from the server HEAD - Requests information about a data but not the data itself. POST - Sends some data to the server PUT - Updates some data to the server TRACE - Echoes the incoming request CONNECT - Reserved OPTION - Inquires about available options","title":"HTTP Methods"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http-status-code","text":"Informational 100 - Continue 101 - Switching Success 200 - OK : The request is successful 201 - Created : A new URL is created. 202 - Accepted : The request is accepted but it - is not immediately acted upon. 204 - No content : There is no content in the body. Redirection 301 - Moved Permanently : The requested URL is no longer used by the server. 302 - Moved Temporarily : The requested URL has moved temporarily. 304 - Not modified : The document has not been modified. Client Error 400 - Bad Request : There is a error in the request. 401 - Unauthorized : The request lacks proper authorization. 403 - Forbidden : Service is denied. 404 - Not Found : The document is not found. 405 - Method not allowed : This method is not supported in the URL. 406 - Not acceptable : The format reqested is not acceptable. Server Error 500 - Internal Server Error : There is an error at the server side. 501 - Not implemented : The action requeted cannot be performed. 503 - Service unavaible : The service is temporarily unavailable, but may be requested in the future.","title":"HTTP Status Code"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http-request-header","text":"Cache-control : Specifies information about caching. Connection : Shows whether the connection should be closed or not. Date : Shows the current date. MIME-version : Shows the MIME version used. Upgrade : Specifies the preferred communication protocol. Accept Accept-charset Accept-language Authorization User-agent, etc","title":"HTTP Request Header"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http-response-headers","text":"Accept-range Age Public Retry-after Server","title":"HTTP Response Headers"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http-entity-headers","text":"Allow Content-encoding Content-language Content-length Content-range Content-type Expires Last-modified Location","title":"HTTP Entity Headers"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#http1-vs-http2","text":"HTTP2 is much faster and more reliable than HTTP1. HTTP1 loads a single request for every TCP connection, while HTTP2 avoids network delay by using multiplexing.","title":"HTTP1 vs HTTP2"},{"location":"Computer%20Networking/08.Application%20Layer/04.HTTP/#features-of-http2","text":"Binary Protocol - While HTTP/1.x was a text based protocol, HTTP/2 is a binary protocol resulting in less error during data transfer process. Multiplexed Streams - All HTTP/2 connections are multiplexed streams meaning multiple files can be transferred in a single stream of binary data. Compressed Header - HTTP/2 compresses header data in responses resulting in faster transfer of data. Server Push - This capability allows the server to send linked resources to the client automatically, greatly reducing the number of requests to the server. Stream Prioritization - HTTP/2 can prioritize data streams based on their type resulting in better bandwidth allocation where necessary.","title":"Features of HTTP2"},{"location":"Computer%20Networking/09.Other%20Concepts/01.DNS/","text":"DNS DNS stands for Domain Name System. DNS is a directory service that provides a mapping between the name of a host on the network and its numerical address. DNS is a service that translates the domain name into IP addresses. This allows the users of networks to utilize user-friendly names when looking for other hosts instead of remembering the IP addresses. DNS uses UDP.","title":"DNS"},{"location":"Computer%20Networking/09.Other%20Concepts/01.DNS/#dns","text":"DNS stands for Domain Name System. DNS is a directory service that provides a mapping between the name of a host on the network and its numerical address. DNS is a service that translates the domain name into IP addresses. This allows the users of networks to utilize user-friendly names when looking for other hosts instead of remembering the IP addresses. DNS uses UDP.","title":"DNS"},{"location":"Computer%20Networking/09.Other%20Concepts/02.DHCP/","text":"DHCP Dynamic Host Configuration Protocol (DHCP) is a network management protocol used to dynamically assign an IP address to any device, or node, on a network so they can communicate using IP (Internet Protocol). DHCP automates and centrally manages these configurations. There is no need to manually assign IP addresses to new devices. Therefore, there is no requirement for any user configuration to connect to a DHCP based network. DHCP can be implemented on local networks as well as large enterprise networks. DHCP is the default protocol used by the most routers and networking equipment.","title":"DHCP"},{"location":"Computer%20Networking/09.Other%20Concepts/02.DHCP/#dhcp","text":"Dynamic Host Configuration Protocol (DHCP) is a network management protocol used to dynamically assign an IP address to any device, or node, on a network so they can communicate using IP (Internet Protocol). DHCP automates and centrally manages these configurations. There is no need to manually assign IP addresses to new devices. Therefore, there is no requirement for any user configuration to connect to a DHCP based network. DHCP can be implemented on local networks as well as large enterprise networks. DHCP is the default protocol used by the most routers and networking equipment.","title":"DHCP"},{"location":"Computer%20Networking/09.Other%20Concepts/03.Routers%20and%20Gateways/","text":"","title":"03.Routers and Gateways"},{"location":"Computer%20Networking/09.Other%20Concepts/04.URL%20vs%20URI/","text":"URI A URI or Uniform Resource Identifier is a string identifier that refers to a resource on the internet. It is a string of characters that is used to identify any resource on the internet using location, name, or both. A URI has two subsets; URL (Uniform Resource Locator) and URN (Uniform Resource Number). URL A URL or Uniform Resource Locator is used to find the location of the resource on the web. It is a reference for a resource and a way to access that resource. A URL always shows a unique resource, and it can be an HTML page, a CSS document, an image, etc.","title":"URI"},{"location":"Computer%20Networking/09.Other%20Concepts/04.URL%20vs%20URI/#uri","text":"A URI or Uniform Resource Identifier is a string identifier that refers to a resource on the internet. It is a string of characters that is used to identify any resource on the internet using location, name, or both. A URI has two subsets; URL (Uniform Resource Locator) and URN (Uniform Resource Number).","title":"URI"},{"location":"Computer%20Networking/09.Other%20Concepts/04.URL%20vs%20URI/#url","text":"A URL or Uniform Resource Locator is used to find the location of the resource on the web. It is a reference for a resource and a way to access that resource. A URL always shows a unique resource, and it can be an HTML page, a CSS document, an image, etc.","title":"URL"},{"location":"Computer%20Networking/09.Other%20Concepts/05.SSH%20and%20SSL/","text":"SSH SSH stands for Secure Socket Shell. It is used to login to a remote server to execute commands and data transfer from one machine to another machine. SSL SSL stands for Secure Sockets Layer. It is the standard security technology (a protocol) that offers secure communication between web servers and browsers (web clients) over an insecure network, such as the internet. It maintains the privacy and integrity of the data exchanged between a web server and browsers. It makes the data, which is shared between users and sites, impossible to read. It uses encryption algorithms to scramble data in transit, to prevent hackers from reading it. This data may be your bank login id and password, credit card details, social media login details, and other financial information, etc. For example, when you shop online, the details you share with the websites remain safe.","title":"SSH"},{"location":"Computer%20Networking/09.Other%20Concepts/05.SSH%20and%20SSL/#ssh","text":"SSH stands for Secure Socket Shell. It is used to login to a remote server to execute commands and data transfer from one machine to another machine.","title":"SSH"},{"location":"Computer%20Networking/09.Other%20Concepts/05.SSH%20and%20SSL/#ssl","text":"SSL stands for Secure Sockets Layer. It is the standard security technology (a protocol) that offers secure communication between web servers and browsers (web clients) over an insecure network, such as the internet. It maintains the privacy and integrity of the data exchanged between a web server and browsers. It makes the data, which is shared between users and sites, impossible to read. It uses encryption algorithms to scramble data in transit, to prevent hackers from reading it. This data may be your bank login id and password, credit card details, social media login details, and other financial information, etc. For example, when you shop online, the details you share with the websites remain safe.","title":"SSL"},{"location":"Computer%20Networking/09.Other%20Concepts/06.HTTP/","text":"HTTP Hypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML. -It was designed for communication between web browsers and web servers, but it can also be used for other purposes. HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response. HTTP is a stateless protocol, meaning that the server does not keep any data (state) between two requests. Difference between HTTP and HTTPS HTTP stands for HyperText Transfer Protocol. Whereas, HTTPS for HyperText Transfer Protocol Secure. HTTP works at Application Layer. Whereas, HTTPS works at Transport Layer. In HTTP, Encryption is absent. Whereas, Encryption is present in HTTPS. HTTP does not require any certificates. Whereas, HTTPS needs SSL Certificates. Port number for HTTP is 80 and Port number for HTTPS is 443.","title":"HTTP"},{"location":"Computer%20Networking/09.Other%20Concepts/06.HTTP/#http","text":"Hypertext Transfer Protocol (HTTP) is an application-layer protocol for transmitting hypermedia documents, such as HTML. -It was designed for communication between web browsers and web servers, but it can also be used for other purposes. HTTP follows a classical client-server model, with a client opening a connection to make a request, then waiting until it receives a response. HTTP is a stateless protocol, meaning that the server does not keep any data (state) between two requests.","title":"HTTP"},{"location":"Computer%20Networking/09.Other%20Concepts/06.HTTP/#difference-between-http-and-https","text":"HTTP stands for HyperText Transfer Protocol. Whereas, HTTPS for HyperText Transfer Protocol Secure. HTTP works at Application Layer. Whereas, HTTPS works at Transport Layer. In HTTP, Encryption is absent. Whereas, Encryption is present in HTTPS. HTTP does not require any certificates. Whereas, HTTPS needs SSL Certificates. Port number for HTTP is 80 and Port number for HTTPS is 443.","title":"Difference between HTTP and HTTPS"},{"location":"Computer%20Networking/09.Other%20Concepts/Important%20Questions/","text":"1. What happens when you enter google.com in the web browser? Below are the steps that are being followed: Check the browser cache first if the content is fresh and present in cache display the same. If not, the browser checks if the IP of the URL is present in the cache (browser and OS) if not then request the OS to do a DNS lookup using UDP to get the corresponding IP address of the URL from the DNS server to establish a new TCP connection. A new TCP connection is set between the browser and the server using three-way handshaking. An HTTP request is sent to the server using the TCP connection. The web servers running on the Servers handle the incoming HTTP request and send the HTTP response. The browser process the HTTP response sent by the server and may close the TCP connection or reuse the same for future requests. If the response data is cacheable then browsers cache the same. Browser decodes the response and renders the content.","title":"Important Questions"},{"location":"Computer%20Networking/09.Other%20Concepts/Important%20Questions/#1-what-happens-when-you-enter-googlecom-in-the-web-browser","text":"Below are the steps that are being followed: Check the browser cache first if the content is fresh and present in cache display the same. If not, the browser checks if the IP of the URL is present in the cache (browser and OS) if not then request the OS to do a DNS lookup using UDP to get the corresponding IP address of the URL from the DNS server to establish a new TCP connection. A new TCP connection is set between the browser and the server using three-way handshaking. An HTTP request is sent to the server using the TCP connection. The web servers running on the Servers handle the incoming HTTP request and send the HTTP response. The browser process the HTTP response sent by the server and may close the TCP connection or reuse the same for future requests. If the response data is cacheable then browsers cache the same. Browser decodes the response and renders the content.","title":"1. What happens when you enter google.com in the web browser?"},{"location":"Computer%20Networking/09.Other%20Concepts/URI/","text":"URI [From Udacity - HTTP and Web Server Course] A URI is a name for a resource \u2014 such as this lesson page, or a Wikipedia article, or a data source like the Google Maps API. URIs are made out of several different parts, each of which has its own syntax. Many of these parts are optional, which is why URIs for different services look so different from one another. Here is an example of a URI: https://en.wikipedia.org/wiki/Fish This URI has three visible parts, separated by a little bit of punctuation: https is the scheme; en.wikipedia.org is the hostname; and /wiki/Fish is the path. Scheme The first part of a URI is the scheme, which tells the client how to go about accessing the resource. Some URI schemes you've seen before include http, https, and file. File URIs tell the client to access a file on the local filesystem. HTTP and HTTPS URIs point to resources served by a web server. mailto is used for links to email addresses. data is used to put a piece of hardcoded data directly into a web page, for instance a small image. magnet is used for links to some file-sharing services such as BitTorrent. Hostname In an HTTP URI, the next thing that appears after the scheme is a hostname \u2014 something like www.udacity.com or localhost. This tells the client which server to connect to. You'll often see web addresses written as just a hostname in print. But in the HTML code of a web page, you can't write this and get a working link to Google. A hostname can only appear after a URI scheme that supports it, such as http or https. In these URIs, there will always be a :// between the scheme and hostname. By the way, not every URI has a hostname. For instance, a mailto URI just has an email address: mailto:spam@example.net is a well-formed mailto URI. This also reveals a bit more about the punctuation in URIs: the : goes after the scheme, but the // goes before the hostname. Mailto links don't have a hostname part, so they don't have a //. Path In an HTTP URI (and many others), the next thing that appears is the path, which identifies a particular resource on a server. A server can have many resources on it \u2014 such as different web pages, videos, or APIs. The path tells the server which resource the client is looking for.","title":"URI"},{"location":"Computer%20Networking/09.Other%20Concepts/URI/#uri","text":"","title":"URI"},{"location":"Computer%20Networking/09.Other%20Concepts/URI/#from-udacity-http-and-web-server-course","text":"A URI is a name for a resource \u2014 such as this lesson page, or a Wikipedia article, or a data source like the Google Maps API. URIs are made out of several different parts, each of which has its own syntax. Many of these parts are optional, which is why URIs for different services look so different from one another. Here is an example of a URI: https://en.wikipedia.org/wiki/Fish This URI has three visible parts, separated by a little bit of punctuation: https is the scheme; en.wikipedia.org is the hostname; and /wiki/Fish is the path.","title":"[From Udacity - HTTP and Web Server Course]"},{"location":"Computer%20Networking/09.Other%20Concepts/URI/#scheme","text":"The first part of a URI is the scheme, which tells the client how to go about accessing the resource. Some URI schemes you've seen before include http, https, and file. File URIs tell the client to access a file on the local filesystem. HTTP and HTTPS URIs point to resources served by a web server. mailto is used for links to email addresses. data is used to put a piece of hardcoded data directly into a web page, for instance a small image. magnet is used for links to some file-sharing services such as BitTorrent.","title":"Scheme"},{"location":"Computer%20Networking/09.Other%20Concepts/URI/#hostname","text":"In an HTTP URI, the next thing that appears after the scheme is a hostname \u2014 something like www.udacity.com or localhost. This tells the client which server to connect to. You'll often see web addresses written as just a hostname in print. But in the HTML code of a web page, you can't write this and get a working link to Google. A hostname can only appear after a URI scheme that supports it, such as http or https. In these URIs, there will always be a :// between the scheme and hostname. By the way, not every URI has a hostname. For instance, a mailto URI just has an email address: mailto:spam@example.net is a well-formed mailto URI. This also reveals a bit more about the punctuation in URIs: the : goes after the scheme, but the // goes before the hostname. Mailto links don't have a hostname part, so they don't have a //.","title":"Hostname"},{"location":"Computer%20Networking/09.Other%20Concepts/URI/#path","text":"In an HTTP URI (and many others), the next thing that appears is the path, which identifies a particular resource on a server. A server can have many resources on it \u2014 such as different web pages, videos, or APIs. The path tells the server which resource the client is looking for.","title":"Path"},{"location":"Database%20Management%20System/Postgres/00.Commands/","text":"","title":"00.Commands"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/","text":"How to Start psql terminal sudo -i -u postgres psql List all the database \\l List all the user \\du Create a new user create user prabin with password 'abcde@12345'; Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | {} prabin | | {} Make superuser Alter user prabin with superuser; Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | {} prabin | Superuser | {} Drop user postgres=# create user user1 with password 'abcde@12345'; CREATE ROLE postgres=# Drop user user1; DROP ROLE Show current user select current_user; current_user -------------- postgres (1 row) Change user and database postgres@linux:~$ psql -U prabin -h 127.0.0.1 -d mydb Reset the password Alter user prabin with password 'abcde@12345';","title":"01.User and Roles"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#how-to-start-psql-terminal","text":"sudo -i -u postgres psql","title":"How to Start psql terminal"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#list-all-the-database","text":"\\l","title":"List all the database"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#list-all-the-user","text":"\\du","title":"List all the user"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#create-a-new-user","text":"create user prabin with password 'abcde@12345'; Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | {} prabin | | {}","title":"Create a new user"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#make-superuser","text":"Alter user prabin with superuser; Role name | Attributes | Member of -----------+------------------------------------------------------------+----------- postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | {} prabin | Superuser | {}","title":"Make superuser"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#drop-user","text":"postgres=# create user user1 with password 'abcde@12345'; CREATE ROLE postgres=# Drop user user1; DROP ROLE","title":"Drop user"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#show-current-user","text":"select current_user; current_user -------------- postgres (1 row)","title":"Show current user"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#change-user-and-database","text":"postgres@linux:~$ psql -U prabin -h 127.0.0.1 -d mydb","title":"Change user and database"},{"location":"Database%20Management%20System/Postgres/01.User%20and%20Roles/#reset-the-password","text":"Alter user prabin with password 'abcde@12345';","title":"Reset the password"},{"location":"Database%20Management%20System/Postgres/02.Database/","text":"Create Database Syntax CREATE DATABASE database_name WITH [OWNER = role_name] [TEMPLATE = template] [ENCODING = encoding] [LC_COLLATE = collate] [LC_CTYPE = ctype] [TABLESPACE = tablespace_name] [ALLOW_CONNECTIONS = true | false] [CONNECTION LIMIT = max_concurrent_connection] [IS_TEMPLATE = true | false ] Creating new database with default parameter CREATE database mydatabase; List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ------------+----------+----------+-------------+-------------+----------------------- mydatabase | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | Creating database with some parameter create database mydatbase1 with owner = prabin; List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ------------+----------+----------+-------------+-------------+----------------------- mydatabase | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydatbase1 | prabin | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | List all the database \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+-------------+-------------+----------------------- mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows) List all database with more information \\l+ List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges | Size | Tablespace | Description -----------+----------+----------+-------------+-------------+-----------------------+---------+------------+-------------------------------------------- mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | | 15 MB | pg_default | postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | | 8577 kB | pg_default | default administrative connection database template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +| 8417 kB | pg_default | unmodifiable empty database | | | | | postgres=CTc/postgres | | | template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +| 8569 kB | pg_default | default template for new databases | | | | | postgres=CTc/postgres | | | (4 rows) Show current database select current_database(); current_database ------------------ postgres (1 row) Switch to other database postgres=# \\c mydb; You are now connected to database \"mydb\" as user \"postgres\". mydb=# \\connect postgres You are now connected to database \"postgres\" as user \"postgres\". Rename the database Alter database mydatabase Rename to database; List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ------------+----------+----------+-------------+-------------+----------------------- database | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydatbase1 | prabin | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | Change the owner of the database alter database mydb owner to postgres; Drop Database drop database mydatbase1; Get the size of database select pg_size_pretty(pg_database_size('mydb')); pg_size_pretty ---------------- 15 MB (1 row)","title":"02.Database"},{"location":"Database%20Management%20System/Postgres/02.Database/#create-database-syntax","text":"CREATE DATABASE database_name WITH [OWNER = role_name] [TEMPLATE = template] [ENCODING = encoding] [LC_COLLATE = collate] [LC_CTYPE = ctype] [TABLESPACE = tablespace_name] [ALLOW_CONNECTIONS = true | false] [CONNECTION LIMIT = max_concurrent_connection] [IS_TEMPLATE = true | false ]","title":"Create Database Syntax"},{"location":"Database%20Management%20System/Postgres/02.Database/#creating-new-database-with-default-parameter","text":"CREATE database mydatabase; List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ------------+----------+----------+-------------+-------------+----------------------- mydatabase | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 |","title":"Creating new database with default parameter"},{"location":"Database%20Management%20System/Postgres/02.Database/#creating-database-with-some-parameter","text":"create database mydatbase1 with owner = prabin; List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ------------+----------+----------+-------------+-------------+----------------------- mydatabase | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydatbase1 | prabin | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 |","title":"Creating database with some parameter"},{"location":"Database%20Management%20System/Postgres/02.Database/#list-all-the-database","text":"\\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+-------------+-------------+----------------------- mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres (4 rows)","title":"List all the database"},{"location":"Database%20Management%20System/Postgres/02.Database/#list-all-database-with-more-information","text":"\\l+ List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges | Size | Tablespace | Description -----------+----------+----------+-------------+-------------+-----------------------+---------+------------+-------------------------------------------- mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | | 15 MB | pg_default | postgres | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | | 8577 kB | pg_default | default administrative connection database template0 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +| 8417 kB | pg_default | unmodifiable empty database | | | | | postgres=CTc/postgres | | | template1 | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | =c/postgres +| 8569 kB | pg_default | default template for new databases | | | | | postgres=CTc/postgres | | | (4 rows)","title":"List all database with more information"},{"location":"Database%20Management%20System/Postgres/02.Database/#show-current-database","text":"select current_database(); current_database ------------------ postgres (1 row)","title":"Show current database"},{"location":"Database%20Management%20System/Postgres/02.Database/#switch-to-other-database","text":"postgres=# \\c mydb; You are now connected to database \"mydb\" as user \"postgres\". mydb=# \\connect postgres You are now connected to database \"postgres\" as user \"postgres\".","title":"Switch to other database"},{"location":"Database%20Management%20System/Postgres/02.Database/#rename-the-database","text":"Alter database mydatabase Rename to database; List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges ------------+----------+----------+-------------+-------------+----------------------- database | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydatbase1 | prabin | UTF8 | en_US.UTF-8 | en_US.UTF-8 | mydb | postgres | UTF8 | en_US.UTF-8 | en_US.UTF-8 |","title":"Rename the database"},{"location":"Database%20Management%20System/Postgres/02.Database/#change-the-owner-of-the-database","text":"alter database mydb owner to postgres;","title":"Change the owner of the database"},{"location":"Database%20Management%20System/Postgres/02.Database/#drop-database","text":"drop database mydatbase1;","title":"Drop Database"},{"location":"Database%20Management%20System/Postgres/02.Database/#get-the-size-of-database","text":"select pg_size_pretty(pg_database_size('mydb')); pg_size_pretty ---------------- 15 MB (1 row)","title":"Get the size of database"},{"location":"Database%20Management%20System/Postgres/03.Schemas/","text":"Introduction to Schemas in Postgresql In PostgreSQL, a schema is a namespace that contains named database objects such as tables, views, indexes, data types, functions, stored procedures and operators. A database can contain one or multiple schemas and each schema belongs to only one database. Two schemas can have different objects that share the same name. For example, you may have sales schema that has staff table and the public schema which also has the staff table. When you refer to the staff table you must qualify it as follows: public.staff Or sales.staff PostgreSQL automatically creates a schema called public for every new database. Whatever object you create without specifying the schema name, PostgreSQL will place it into this public schema. Create a new schema create schema marketting; Create a new schema for a user create schema sales authorization prabin; List all schema \\dn List of schemas Name | Owner ------------+---------- marketting | postgres public | postgres sales | prabin (3 rows) Show the current schema select current_schema(); current_schema ---------------- public (1 row) Rename schema alter schema marketting rename to finance; List of schemas Name | Owner ---------+---------- finance | postgres public | postgres sales | prabin (3 rows) Change the owener of schema alter schema finance owner to prabin; List of schemas Name | Owner ---------+---------- finance | prabin public | postgres sales | prabin (3 rows) Drop Schema drop schema sales; List of schemas Name | Owner ---------+---------- finance | prabin public | postgres (2 rows)","title":"Introduction to Schemas in Postgresql"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#introduction-to-schemas-in-postgresql","text":"In PostgreSQL, a schema is a namespace that contains named database objects such as tables, views, indexes, data types, functions, stored procedures and operators. A database can contain one or multiple schemas and each schema belongs to only one database. Two schemas can have different objects that share the same name. For example, you may have sales schema that has staff table and the public schema which also has the staff table. When you refer to the staff table you must qualify it as follows: public.staff Or sales.staff PostgreSQL automatically creates a schema called public for every new database. Whatever object you create without specifying the schema name, PostgreSQL will place it into this public schema.","title":"Introduction to Schemas in Postgresql"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#create-a-new-schema","text":"create schema marketting;","title":"Create a new schema"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#create-a-new-schema-for-a-user","text":"create schema sales authorization prabin;","title":"Create a new schema for a user"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#list-all-schema","text":"\\dn List of schemas Name | Owner ------------+---------- marketting | postgres public | postgres sales | prabin (3 rows)","title":"List all schema"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#show-the-current-schema","text":"select current_schema(); current_schema ---------------- public (1 row)","title":"Show the current schema"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#rename-schema","text":"alter schema marketting rename to finance; List of schemas Name | Owner ---------+---------- finance | postgres public | postgres sales | prabin (3 rows)","title":"Rename schema"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#change-the-owener-of-schema","text":"alter schema finance owner to prabin; List of schemas Name | Owner ---------+---------- finance | prabin public | postgres sales | prabin (3 rows)","title":"Change the owener of schema"},{"location":"Database%20Management%20System/Postgres/03.Schemas/#drop-schema","text":"drop schema sales; List of schemas Name | Owner ---------+---------- finance | prabin public | postgres (2 rows)","title":"Drop Schema"},{"location":"Database%20Management%20System/Postgres/04.Data%20Types/","text":"Data Types Supported by Postgresql Boolean 1, yes, y, t, true values are converted to true 0, no, false, f values are converted to false. Character (char, varchar, text) CHAR(n) is the fixed-length character with space padded. If you insert a string that is shorter than the length of the column, PostgreSQL pads spaces. If you insert a string that is longer than the length of the column, PostgreSQL will issue an error. VARCHAR(n) is the variable-length character string. With VARCHAR(n), you can store up to n characters. PostgreSQL does not pad spaces when the stored string is shorter than the length of the column. TEXT is the variable-length character string. Theoretically, text data is a character string with unlimited length. Numberic (integer, float) Integer ``` Small integer ( SMALLINT) is 2-byte signed integer that has a range from -32,768 to 32,767. Integer ( INT) is a 4-byte integer that has a range from -2,147,483,648 to 2,147,483,647. Serial is the same as integer except that PostgreSQL will automatically generate and populate values into the SERIAL column. This is similar to AUTO_INCREMENT column in MySQL or AUTOINCREMENT column in SQLite. ``` Floating Point ``` float(n) is a floating-point number whose precision, at least, n, up to a maximum of 8 bytes. realor float8is a 4-byte floating-point number. numeric or numeric(p,s) is a real number with p digits with s number after the decimal point. The numeric(p,s) is the exact number. ``` Temporal Types (date, datetime, timestamp, interval) DATE stores the dates only. TIME stores the time of day values. TIMESTAMP stores both date and time values. TIMESTAMPTZ is a timezone-aware timestamp data type. It is the abbreviation for timestamp with the time zone. INTERVAL stores periods of time. UUID (for storing Universally Unique Indentifiers) The UUID data type allows you to store Universal Unique Identifiers defined by RFC 4122 . The UUID values guarantee a better uniqueness than SERIAL. It can be used to hide sensitive data exposed to the public such as values of id in URL. Array (store array of string, numbers etc) In PostgreSQL, you can store an array of strings, an array of integers, etc., in array columns. The array comes in handy in some situations e.g., storing days of the week, months of the year. JSON (stores JSON data) PostgreSQL provides two JSON data types: JSON and JSONB for storing JSON data. The JSON data type stores plain JSON data that requires reparsing for each processing. While JSONB data type stores JSON data in a binary format which is faster to process but slower to insert. In addition, JSONB supports indexing, which can be an advantage. hstore (stores key-value pair) The hstore module implements the hstore data type for storing key-value pairs in a single value. The hstore data type is very useful in many cases, such as semi-structured data or rows with many attributes that are rarely queried. Notice that keys and values are just text strings only. Special Types (Numeric Address, Geospatial Data) box\u2013 a rectangular box. line \u2013 a set of points. point\u2013 a geometric pair of numbers. lseg\u2013 a line segment. polygon\u2013 a closed geometric. inet\u2013 an IP4 address. macaddr\u2013 a MAC address.","title":"Data Types Supported by Postgresql"},{"location":"Database%20Management%20System/Postgres/04.Data%20Types/#data-types-supported-by-postgresql","text":"Boolean 1, yes, y, t, true values are converted to true 0, no, false, f values are converted to false. Character (char, varchar, text) CHAR(n) is the fixed-length character with space padded. If you insert a string that is shorter than the length of the column, PostgreSQL pads spaces. If you insert a string that is longer than the length of the column, PostgreSQL will issue an error. VARCHAR(n) is the variable-length character string. With VARCHAR(n), you can store up to n characters. PostgreSQL does not pad spaces when the stored string is shorter than the length of the column. TEXT is the variable-length character string. Theoretically, text data is a character string with unlimited length. Numberic (integer, float) Integer ``` Small integer ( SMALLINT) is 2-byte signed integer that has a range from -32,768 to 32,767. Integer ( INT) is a 4-byte integer that has a range from -2,147,483,648 to 2,147,483,647. Serial is the same as integer except that PostgreSQL will automatically generate and populate values into the SERIAL column. This is similar to AUTO_INCREMENT column in MySQL or AUTOINCREMENT column in SQLite. ``` Floating Point ``` float(n) is a floating-point number whose precision, at least, n, up to a maximum of 8 bytes. realor float8is a 4-byte floating-point number. numeric or numeric(p,s) is a real number with p digits with s number after the decimal point. The numeric(p,s) is the exact number. ``` Temporal Types (date, datetime, timestamp, interval) DATE stores the dates only. TIME stores the time of day values. TIMESTAMP stores both date and time values. TIMESTAMPTZ is a timezone-aware timestamp data type. It is the abbreviation for timestamp with the time zone. INTERVAL stores periods of time. UUID (for storing Universally Unique Indentifiers) The UUID data type allows you to store Universal Unique Identifiers defined by RFC 4122 . The UUID values guarantee a better uniqueness than SERIAL. It can be used to hide sensitive data exposed to the public such as values of id in URL. Array (store array of string, numbers etc) In PostgreSQL, you can store an array of strings, an array of integers, etc., in array columns. The array comes in handy in some situations e.g., storing days of the week, months of the year. JSON (stores JSON data) PostgreSQL provides two JSON data types: JSON and JSONB for storing JSON data. The JSON data type stores plain JSON data that requires reparsing for each processing. While JSONB data type stores JSON data in a binary format which is faster to process but slower to insert. In addition, JSONB supports indexing, which can be an advantage. hstore (stores key-value pair) The hstore module implements the hstore data type for storing key-value pairs in a single value. The hstore data type is very useful in many cases, such as semi-structured data or rows with many attributes that are rarely queried. Notice that keys and values are just text strings only. Special Types (Numeric Address, Geospatial Data) box\u2013 a rectangular box. line \u2013 a set of points. point\u2013 a geometric pair of numbers. lseg\u2013 a line segment. polygon\u2013 a closed geometric. inet\u2013 an IP4 address. macaddr\u2013 a MAC address.","title":"Data Types Supported by Postgresql"},{"location":"Database%20Management%20System/Postgres/05.Tables/","text":"Managing Tables in Postgresql Create Operations Creating a table named \"collection\" create table collection( id serial primary key, name varchar(50) Unique not null, description text not null, created_on timestamp not null); Describing the table named \"collection\" \\d collection Table \"public.collection\" Column | Type | Collation | Nullable | Default -------------+-----------------------------+-----------+----------+---------------------------------------- id | integer | | not null | nextval('collection_id_seq'::regclass) name | character varying(50) | | not null | description | text | | not null | created_on | timestamp without time zone | | not null | Indexes: \"collection_pkey\" PRIMARY KEY, btree (id) \"collection_name_key\" UNIQUE CONSTRAINT, btree (name) Creating post table Create table post( id serial primary key, collection_id int not null, title char(100) not null, body text not null, is_public boolean, created_on timestamp not null, Foreign Key (collection_id) References collection(id)); Table \"public.post\" Column | Type | Collation | Nullable | Default ---------------+-----------------------------+-----------+----------+---------------------------------- id | integer | | not null | nextval('post_id_seq'::regclass) collection_id | integer | | not null | title | character(100) | | not null | body | text | | not null | is_public | boolean | | | created_on | timestamp without time zone | | not null | Indexes: \"post_pkey\" PRIMARY KEY, btree (id) Foreign-key constraints: \"post_collection_id_fkey\" FOREIGN KEY (collection_id) REFERENCES collection(id) Alter Operation Rename the table Alter table post rename to posts; Drop a column Alter table post drop column is_public; Add a new column Alter table post Add column is_public boolean not null; Rename the column Alter table post rename column is_public to is_private; Drop Primary Key Constraint alter table post drop constraint post_pkey; Add Primary Key Constraint Alter table post Add Primary key (id); Modify existing column structure Set the default value to false Alter table post alter column is_private set default false; Drop the not null constraint Alter table post Alter column is_private drop not null; Add unique constraint Alter table post Add constraint title_unique UNIQUE (title); Change data type of column Alter table post Alter column title Type varchar(100); Rename Table alter table post rename to posts; Drop Table Syntax: DROP TABLE [IF EXISTS] table_name [CASCADE | RESTRICT]; Example: DROP TABLE comments; Truncate Table The TRUNCATE TABLE statement deletes all data from a table without scanning it. This is the reason why it is faster than the DELETE statement. In addition, the TRUNCATE TABLE statement reclaims the storage right away so you do not have to perform a subsequent VACUMM operation, which is useful in the case of large tables. Syntax: TRUNCATE TABLE table_name; Example: Truncate table posts; By default, the TRUNCATE TABLE statement does not remove any data from the table that has foreign key references. To remove data from a table and other tables that have foreign key reference the table, you use CASCADE option in the TRUNCATE TABLE statement as follows : TRUNCATE TABLE posts CASCADE; The TRUNCATE TABLE does not fire ON DELETE trigger. Instead, it fires the BEFORE TRUNCATE and AFTER TRUNCATE triggers. The TRUNCATE TABLE statement is transaction-safe. Temporary Table A temporary table, as its named implied, is a short-lived table that exists for the duration of a database session. PostgreSQL automatically drops the temporary tables at the end of a session or a transaction. Creating a temporary table: CREATE TEMPORARY TABLE temp_table_name( column_list ); Dropping a temporary table DROP TABLE temp_table_name; Copy the table Without data CREATE TABLE blog AS TABLE posts WITH NO DATA; With data CREATE TABLE blog AS TABLE posts; With partial data CREATE TABLE blog AS SELECT * FROM posts WHERE id>100;","title":"Managing Tables in Postgresql"},{"location":"Database%20Management%20System/Postgres/05.Tables/#managing-tables-in-postgresql","text":"","title":"Managing Tables in Postgresql"},{"location":"Database%20Management%20System/Postgres/05.Tables/#create-operations","text":"","title":"Create Operations"},{"location":"Database%20Management%20System/Postgres/05.Tables/#creating-a-table-named-collection","text":"create table collection( id serial primary key, name varchar(50) Unique not null, description text not null, created_on timestamp not null);","title":"Creating a table named \"collection\""},{"location":"Database%20Management%20System/Postgres/05.Tables/#describing-the-table-named-collection","text":"\\d collection Table \"public.collection\" Column | Type | Collation | Nullable | Default -------------+-----------------------------+-----------+----------+---------------------------------------- id | integer | | not null | nextval('collection_id_seq'::regclass) name | character varying(50) | | not null | description | text | | not null | created_on | timestamp without time zone | | not null | Indexes: \"collection_pkey\" PRIMARY KEY, btree (id) \"collection_name_key\" UNIQUE CONSTRAINT, btree (name)","title":"Describing the table named \"collection\""},{"location":"Database%20Management%20System/Postgres/05.Tables/#creating-post-table","text":"Create table post( id serial primary key, collection_id int not null, title char(100) not null, body text not null, is_public boolean, created_on timestamp not null, Foreign Key (collection_id) References collection(id)); Table \"public.post\" Column | Type | Collation | Nullable | Default ---------------+-----------------------------+-----------+----------+---------------------------------- id | integer | | not null | nextval('post_id_seq'::regclass) collection_id | integer | | not null | title | character(100) | | not null | body | text | | not null | is_public | boolean | | | created_on | timestamp without time zone | | not null | Indexes: \"post_pkey\" PRIMARY KEY, btree (id) Foreign-key constraints: \"post_collection_id_fkey\" FOREIGN KEY (collection_id) REFERENCES collection(id)","title":"Creating post table"},{"location":"Database%20Management%20System/Postgres/05.Tables/#alter-operation","text":"","title":"Alter Operation"},{"location":"Database%20Management%20System/Postgres/05.Tables/#rename-the-table","text":"Alter table post rename to posts;","title":"Rename the table"},{"location":"Database%20Management%20System/Postgres/05.Tables/#drop-a-column","text":"Alter table post drop column is_public;","title":"Drop a column"},{"location":"Database%20Management%20System/Postgres/05.Tables/#add-a-new-column","text":"Alter table post Add column is_public boolean not null;","title":"Add a new column"},{"location":"Database%20Management%20System/Postgres/05.Tables/#rename-the-column","text":"Alter table post rename column is_public to is_private;","title":"Rename the column"},{"location":"Database%20Management%20System/Postgres/05.Tables/#drop-primary-key-constraint","text":"alter table post drop constraint post_pkey;","title":"Drop Primary Key Constraint"},{"location":"Database%20Management%20System/Postgres/05.Tables/#add-primary-key-constraint","text":"Alter table post Add Primary key (id);","title":"Add Primary Key Constraint"},{"location":"Database%20Management%20System/Postgres/05.Tables/#modify-existing-column-structure","text":"Set the default value to false Alter table post alter column is_private set default false; Drop the not null constraint Alter table post Alter column is_private drop not null; Add unique constraint Alter table post Add constraint title_unique UNIQUE (title); Change data type of column Alter table post Alter column title Type varchar(100);","title":"Modify existing column structure"},{"location":"Database%20Management%20System/Postgres/05.Tables/#rename-table","text":"alter table post rename to posts;","title":"Rename Table"},{"location":"Database%20Management%20System/Postgres/05.Tables/#drop-table","text":"Syntax: DROP TABLE [IF EXISTS] table_name [CASCADE | RESTRICT]; Example: DROP TABLE comments;","title":"Drop Table"},{"location":"Database%20Management%20System/Postgres/05.Tables/#truncate-table","text":"The TRUNCATE TABLE statement deletes all data from a table without scanning it. This is the reason why it is faster than the DELETE statement. In addition, the TRUNCATE TABLE statement reclaims the storage right away so you do not have to perform a subsequent VACUMM operation, which is useful in the case of large tables. Syntax: TRUNCATE TABLE table_name; Example: Truncate table posts; By default, the TRUNCATE TABLE statement does not remove any data from the table that has foreign key references. To remove data from a table and other tables that have foreign key reference the table, you use CASCADE option in the TRUNCATE TABLE statement as follows : TRUNCATE TABLE posts CASCADE; The TRUNCATE TABLE does not fire ON DELETE trigger. Instead, it fires the BEFORE TRUNCATE and AFTER TRUNCATE triggers. The TRUNCATE TABLE statement is transaction-safe.","title":"Truncate Table"},{"location":"Database%20Management%20System/Postgres/05.Tables/#temporary-table","text":"A temporary table, as its named implied, is a short-lived table that exists for the duration of a database session. PostgreSQL automatically drops the temporary tables at the end of a session or a transaction. Creating a temporary table: CREATE TEMPORARY TABLE temp_table_name( column_list ); Dropping a temporary table DROP TABLE temp_table_name;","title":"Temporary Table"},{"location":"Database%20Management%20System/Postgres/05.Tables/#copy-the-table","text":"Without data CREATE TABLE blog AS TABLE posts WITH NO DATA; With data CREATE TABLE blog AS TABLE posts; With partial data CREATE TABLE blog AS SELECT * FROM posts WHERE id>100;","title":"Copy the table"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/","text":"Querying data Table Structure Table \"public.product\" Column | Type | Collation | Nullable | Default ---------+---------------+-----------+----------+------------------------------------- id | integer | | not null | nextval('product_id_seq'::regclass) name | character(50) | | not null | price | integer | | not null | country | character(25) | | not null | Indexes: \"product_pkey\" PRIMARY KEY, btree (id) Selecting all columns select * from product; id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 1600 | INDIA (6 rows) Selecting specific columns select id, name, price from product; id | name | price ----+----------------------------------------------------+------- 1 | Iphone | 10000 2 | Realme | 1000 3 | Vivo | 2000 4 | CG | 500 5 | Tesla | 11500 6 | Jio | 1600 (6 rows) Concatenating two columns || is concatenation operator SELECT first_name || ' ' || last_name, email FROM customer; Column Aliases Select name as product_name from product; select name as \"Product Name\" from product; SELECT first_name || ' ' || last_name AS full_name FROM customer; Selecting distinct column select distinct country from product; country --------------------------- USA NEPAL CHINA INDIA (4 rows) Order By SYNTAX: ORDER BY sort_expresssion [ASC | DESC] [NULLS FIRST | NULLS LAST] Select * from product order by price; Select * from product order by price ASC; Select * from product order by price DESC; select * from product order by price desc, name asc; select name, length(name) as len from product order by len desc; Select * from product order by price DESC nulls last;","title":"Querying data"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#querying-data","text":"Table Structure Table \"public.product\" Column | Type | Collation | Nullable | Default ---------+---------------+-----------+----------+------------------------------------- id | integer | | not null | nextval('product_id_seq'::regclass) name | character(50) | | not null | price | integer | | not null | country | character(25) | | not null | Indexes: \"product_pkey\" PRIMARY KEY, btree (id)","title":"Querying data"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#selecting-all-columns","text":"select * from product; id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 1600 | INDIA (6 rows)","title":"Selecting all columns"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#selecting-specific-columns","text":"select id, name, price from product; id | name | price ----+----------------------------------------------------+------- 1 | Iphone | 10000 2 | Realme | 1000 3 | Vivo | 2000 4 | CG | 500 5 | Tesla | 11500 6 | Jio | 1600 (6 rows)","title":"Selecting specific columns"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#concatenating-two-columns","text":"|| is concatenation operator SELECT first_name || ' ' || last_name, email FROM customer;","title":"Concatenating two columns"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#column-aliases","text":"Select name as product_name from product; select name as \"Product Name\" from product; SELECT first_name || ' ' || last_name AS full_name FROM customer;","title":"Column Aliases"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#selecting-distinct-column","text":"select distinct country from product; country --------------------------- USA NEPAL CHINA INDIA (4 rows)","title":"Selecting distinct column"},{"location":"Database%20Management%20System/Postgres/06.Querying%20Data/#order-by","text":"SYNTAX: ORDER BY sort_expresssion [ASC | DESC] [NULLS FIRST | NULLS LAST] Select * from product order by price; Select * from product order by price ASC; Select * from product order by price DESC; select * from product order by price desc, name asc; select name, length(name) as len from product order by len desc; Select * from product order by price DESC nulls last;","title":"Order By"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/","text":"Filtering Data Where clause SELECT select_list FROM table_name WHERE condition ORDER BY sort_expression Besides the SELECT statement, you can use the WHERE clause in the UPDATE and DELETE statement to specify rows to be updated or deleted. To form the condition in the WHERE clause, you use comparison and logical operators: ``` = Equal Greater than < Less than = Greater than or equal <= Less than or equal <> or != Not equal AND Logical operator AND OR Logical operator OR IN Return true if a value matches any value in a list BETWEEN Return true if a value is between a range of values LIKE Return true if a value matches a pattern IS NULL Return true if a value is NULL IS NOT NULL Returns true if a value is not null NOT Negate the result of other operators ``` Examples select * from product where id in (1,2,3,4) AND price between 5000 AND 11000; Select * from product where id >= 3 AND NOT(country is null); select * from product where id is not null; Select * from product where country <> 'CHINA' AND name Like '%a%'; Limit Clause PostgreSQL LIMIT is an optional clause of the SELECT statement that constrains the number of rows returned by the query. SELECT select_list FROM table_name LIMIT row_count OFFSET row_to_skip; Example select * from product order by id Limit 2 offset 3; id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA Fetch Clause To constrain the number of rows returned by a query, you often use the LIMIT clause. The LIMIT clause is widely used by many relational database management systems such as MySQL, H2, and HSQLDB. However, the LIMIT clause is not a SQL-standard. To conform with the SQL standard, PostgreSQL supports the FETCH clause to retrieve a number of rows returned by a query. OFFSET start { ROW | ROWS } FETCH { FIRST | NEXT } [ row_count ] { ROW | ROWS } ONLY Examples: select * from product order by id OFFSET 5 ROWS FETCH FIRST 5 ROWS ONLY;","title":"Filtering Data"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#filtering-data","text":"","title":"Filtering Data"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#where-clause","text":"SELECT select_list FROM table_name WHERE condition ORDER BY sort_expression Besides the SELECT statement, you can use the WHERE clause in the UPDATE and DELETE statement to specify rows to be updated or deleted. To form the condition in the WHERE clause, you use comparison and logical operators: ``` = Equal Greater than < Less than = Greater than or equal <= Less than or equal <> or != Not equal AND Logical operator AND OR Logical operator OR IN Return true if a value matches any value in a list BETWEEN Return true if a value is between a range of values LIKE Return true if a value matches a pattern IS NULL Return true if a value is NULL IS NOT NULL Returns true if a value is not null NOT Negate the result of other operators ```","title":"Where clause"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#examples","text":"select * from product where id in (1,2,3,4) AND price between 5000 AND 11000; Select * from product where id >= 3 AND NOT(country is null); select * from product where id is not null; Select * from product where country <> 'CHINA' AND name Like '%a%';","title":"Examples"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#limit-clause","text":"PostgreSQL LIMIT is an optional clause of the SELECT statement that constrains the number of rows returned by the query. SELECT select_list FROM table_name LIMIT row_count OFFSET row_to_skip;","title":"Limit Clause"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#example","text":"select * from product order by id Limit 2 offset 3; id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA","title":"Example"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#fetch-clause","text":"To constrain the number of rows returned by a query, you often use the LIMIT clause. The LIMIT clause is widely used by many relational database management systems such as MySQL, H2, and HSQLDB. However, the LIMIT clause is not a SQL-standard. To conform with the SQL standard, PostgreSQL supports the FETCH clause to retrieve a number of rows returned by a query. OFFSET start { ROW | ROWS } FETCH { FIRST | NEXT } [ row_count ] { ROW | ROWS } ONLY","title":"Fetch Clause"},{"location":"Database%20Management%20System/Postgres/07.Filtering%20Data/#examples_1","text":"select * from product order by id OFFSET 5 ROWS FETCH FIRST 5 ROWS ONLY;","title":"Examples:"},{"location":"Database%20Management%20System/Postgres/08.Joins/","text":"Joins PostgreSQL supports inner join, left join, right join, full outer join, cross join, natural join, and a special kind of join called self-join. basket_a a | fruit_a ---+---------- 1 | Apple 2 | Orange 3 | Banana 4 | Cucumber (4 rows) basket_b b | fruit_b ---+------------ 1 | Orange 2 | Apple 3 | Watermelon 4 | Pear (4 rows) Inner Join Returns the rows whose values are equal based on the \"ON\" condition. SELECT a, fruit_a, b, fruit_b FROM basket_a INNER JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+---------+---+--------- 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange (2 rows) Left Join / Left Outer Join Returns the rows which are present in left table but not in right table (except common rows). SELECT a, fruit_a, b, fruit_b FROM basket_a LEFT JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+----------+---+--------- 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange 3 | Banana | | 4 | Cucumber | | (4 rows) Right Join / Right Outer Join Returns the rows from right table which are not present in left table (except common rows). SELECT a, fruit_a, b, fruit_b FROM basket_a RIGHT JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+---------+---+------------ 2 | Orange | 1 | Orange 1 | Apple | 2 | Apple | | 3 | Watermelon | | 4 | Pear (4 rows) Full Outer Join Returns rows from both left and right table. SELECT a, fruit_a, b, fruit_b FROM basket_a FULL OUTER JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+----------+---+------------ 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange 3 | Banana | | 4 | Cucumber | | | | 3 | Watermelon | | 4 | Pear (6 rows) Table Aliases SELECT c.customer_id, first_name, amount, payment_date FROM customer c INNER JOIN payment p ON p.customer_id = c.customer_id ORDER BY payment_date DESC; Cross Join A CROSS JOIN clause allows you to produce a Cartesian Product of rows in two or more tables. Different from other join clauses such as LEFT JOIN or INNER JOIN, the CROSS JOIN clause does not have a join predicate. SELECT select_list FROM T1 CROSS JOIN T2; Natural Join A natural join is a join that creates an implicit join based on the same column names in the joined tables. A natural join can be an inner join, left join, or right join. If you do not specify a join explicitly e.g., INNER JOIN, LEFT JOIN, RIGHT JOIN, PostgreSQL will use the INNER JOIN by default. SELECT * FROM products NATURAL JOIN categories; is same as SELECT * FROM products INNER JOIN categories USING (category_id);","title":"Joins"},{"location":"Database%20Management%20System/Postgres/08.Joins/#joins","text":"PostgreSQL supports inner join, left join, right join, full outer join, cross join, natural join, and a special kind of join called self-join. basket_a a | fruit_a ---+---------- 1 | Apple 2 | Orange 3 | Banana 4 | Cucumber (4 rows) basket_b b | fruit_b ---+------------ 1 | Orange 2 | Apple 3 | Watermelon 4 | Pear (4 rows)","title":"Joins"},{"location":"Database%20Management%20System/Postgres/08.Joins/#inner-join","text":"Returns the rows whose values are equal based on the \"ON\" condition. SELECT a, fruit_a, b, fruit_b FROM basket_a INNER JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+---------+---+--------- 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange (2 rows)","title":"Inner Join"},{"location":"Database%20Management%20System/Postgres/08.Joins/#left-join-left-outer-join","text":"Returns the rows which are present in left table but not in right table (except common rows). SELECT a, fruit_a, b, fruit_b FROM basket_a LEFT JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+----------+---+--------- 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange 3 | Banana | | 4 | Cucumber | | (4 rows)","title":"Left Join / Left Outer Join"},{"location":"Database%20Management%20System/Postgres/08.Joins/#right-join-right-outer-join","text":"Returns the rows from right table which are not present in left table (except common rows). SELECT a, fruit_a, b, fruit_b FROM basket_a RIGHT JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+---------+---+------------ 2 | Orange | 1 | Orange 1 | Apple | 2 | Apple | | 3 | Watermelon | | 4 | Pear (4 rows)","title":"Right Join / Right Outer Join"},{"location":"Database%20Management%20System/Postgres/08.Joins/#full-outer-join","text":"Returns rows from both left and right table. SELECT a, fruit_a, b, fruit_b FROM basket_a FULL OUTER JOIN basket_b ON fruit_a = fruit_b; a | fruit_a | b | fruit_b ---+----------+---+------------ 1 | Apple | 2 | Apple 2 | Orange | 1 | Orange 3 | Banana | | 4 | Cucumber | | | | 3 | Watermelon | | 4 | Pear (6 rows)","title":"Full Outer Join"},{"location":"Database%20Management%20System/Postgres/08.Joins/#table-aliases","text":"SELECT c.customer_id, first_name, amount, payment_date FROM customer c INNER JOIN payment p ON p.customer_id = c.customer_id ORDER BY payment_date DESC;","title":"Table Aliases"},{"location":"Database%20Management%20System/Postgres/08.Joins/#cross-join","text":"A CROSS JOIN clause allows you to produce a Cartesian Product of rows in two or more tables. Different from other join clauses such as LEFT JOIN or INNER JOIN, the CROSS JOIN clause does not have a join predicate. SELECT select_list FROM T1 CROSS JOIN T2;","title":"Cross Join"},{"location":"Database%20Management%20System/Postgres/08.Joins/#natural-join","text":"A natural join is a join that creates an implicit join based on the same column names in the joined tables. A natural join can be an inner join, left join, or right join. If you do not specify a join explicitly e.g., INNER JOIN, LEFT JOIN, RIGHT JOIN, PostgreSQL will use the INNER JOIN by default. SELECT * FROM products NATURAL JOIN categories; is same as SELECT * FROM products INNER JOIN categories USING (category_id);","title":"Natural Join"},{"location":"Database%20Management%20System/Postgres/09.Grouping%20Data/","text":"Grouping Data Group By Clause The GROUP BY clause divides the rows returned from the SELECT statement into groups. For each group, you can apply an aggregate function e.g., SUM() to calculate the sum of items or COUNT() to get the number of items in the groups. PostgreSQL evaluates the GROUP BY clause after the FROM and WHERE clauses and before the HAVING SELECT, DISTINCT, ORDER BY and LIMIT clauses. SELECT column_1, column_2, ..., aggregate_function(column_3) FROM table_name GROUP BY column_1, column_2, ...; select country, COUNT(country) as \"number of brands\" from product group by country order by country; country | number of brands ---------------------------+-------- CHINA | 1 INDIA | 2 NEPAL | 1 USA | 2 (4 rows) Having Clause The HAVING clause specifies a search condition for a group or an aggregate. The HAVING clause is often used with the GROUP BY clause to filter groups or aggregates based on a specified condition. PostgreSQL evaluates the HAVING clause after the FROM, WHERE, GROUP BY, and before the SELECT, DISTINCT, ORDER BY and LIMIT clauses. SELECT column1, aggregate_function (column2) FROM table_name GROUP BY column1 HAVING condition; select country, COUNT(country) as \"Number of brand\" from product group by country having Count(country) > 1 order by country; country | Number of brand ---------------------------+----------------- INDIA | 2 USA | 2 (2 rows)","title":"Grouping Data"},{"location":"Database%20Management%20System/Postgres/09.Grouping%20Data/#grouping-data","text":"","title":"Grouping Data"},{"location":"Database%20Management%20System/Postgres/09.Grouping%20Data/#group-by-clause","text":"The GROUP BY clause divides the rows returned from the SELECT statement into groups. For each group, you can apply an aggregate function e.g., SUM() to calculate the sum of items or COUNT() to get the number of items in the groups. PostgreSQL evaluates the GROUP BY clause after the FROM and WHERE clauses and before the HAVING SELECT, DISTINCT, ORDER BY and LIMIT clauses. SELECT column_1, column_2, ..., aggregate_function(column_3) FROM table_name GROUP BY column_1, column_2, ...; select country, COUNT(country) as \"number of brands\" from product group by country order by country; country | number of brands ---------------------------+-------- CHINA | 1 INDIA | 2 NEPAL | 1 USA | 2 (4 rows)","title":"Group By Clause"},{"location":"Database%20Management%20System/Postgres/09.Grouping%20Data/#having-clause","text":"The HAVING clause specifies a search condition for a group or an aggregate. The HAVING clause is often used with the GROUP BY clause to filter groups or aggregates based on a specified condition. PostgreSQL evaluates the HAVING clause after the FROM, WHERE, GROUP BY, and before the SELECT, DISTINCT, ORDER BY and LIMIT clauses. SELECT column1, aggregate_function (column2) FROM table_name GROUP BY column1 HAVING condition; select country, COUNT(country) as \"Number of brand\" from product group by country having Count(country) > 1 order by country; country | Number of brand ---------------------------+----------------- INDIA | 2 USA | 2 (2 rows)","title":"Having Clause"},{"location":"Database%20Management%20System/Postgres/10.Set%20Operations/","text":"Set Operations UNION operator The UNION operator combines result sets of two or more SELECT statements into a single result set. The UNION operator removes all duplicate rows from the combined data set. To retain the duplicate rows, you use the the UNION ALL instead. SELECT select_list_1 FROM table_expresssion_1 UNION SELECT select_list_2 FROM table_expression_2 select * from product where id < 2 UNION select * from product where id > 2; id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 4 | CG | 500 | NEPAL 1 | Iphone | 10000 | USA 6 | Jio | 1600 | INDIA 5 | Tesla | 11500 | USA 3 | Vivo | 2000 | CHINA (5 rows) Intersect Operator The INTERSECT operator returns any rows that are available in both result sets. SELECT select_list FROM A INTERSECT SELECT select_list FROM B; select * from product where id < 2 INTERSECT select * from product where id IN (1,2,3,4,5); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 1 | Iphone | 10000 | USA (1 row) Except Opeartor The EXCEPT operator is used to return distinct rows from the first (left) query that are not in the output of the second (right) query while comparing result sets of two or more queries. SELECT column_list FROM A WHERE condition_a EXCEPT SELECT column_list FROM B WHERE condition_b; select * from product where id > 5 Except select * from product where id IN (1,2,3,4,5); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 6 | Jio | 1600 | INDIA (1 row)","title":"Set Operations"},{"location":"Database%20Management%20System/Postgres/10.Set%20Operations/#set-operations","text":"","title":"Set Operations"},{"location":"Database%20Management%20System/Postgres/10.Set%20Operations/#union-operator","text":"The UNION operator combines result sets of two or more SELECT statements into a single result set. The UNION operator removes all duplicate rows from the combined data set. To retain the duplicate rows, you use the the UNION ALL instead. SELECT select_list_1 FROM table_expresssion_1 UNION SELECT select_list_2 FROM table_expression_2 select * from product where id < 2 UNION select * from product where id > 2; id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 4 | CG | 500 | NEPAL 1 | Iphone | 10000 | USA 6 | Jio | 1600 | INDIA 5 | Tesla | 11500 | USA 3 | Vivo | 2000 | CHINA (5 rows)","title":"UNION operator"},{"location":"Database%20Management%20System/Postgres/10.Set%20Operations/#intersect-operator","text":"The INTERSECT operator returns any rows that are available in both result sets. SELECT select_list FROM A INTERSECT SELECT select_list FROM B; select * from product where id < 2 INTERSECT select * from product where id IN (1,2,3,4,5); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 1 | Iphone | 10000 | USA (1 row)","title":"Intersect Operator"},{"location":"Database%20Management%20System/Postgres/10.Set%20Operations/#except-opeartor","text":"The EXCEPT operator is used to return distinct rows from the first (left) query that are not in the output of the second (right) query while comparing result sets of two or more queries. SELECT column_list FROM A WHERE condition_a EXCEPT SELECT column_list FROM B WHERE condition_b; select * from product where id > 5 Except select * from product where id IN (1,2,3,4,5); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 6 | Jio | 1600 | INDIA (1 row)","title":"Except Opeartor"},{"location":"Database%20Management%20System/Postgres/11.Sub%20Query/","text":"Sub-query A subquery is a query nested inside another query such as SELECT, INSERT, DELETE and UPDATE. ANY ANY is equivalent to IN operator. select * from product where id = ANY(Select id from product where id>2); ALL The PostgreSQL ALL operator allows you to query data by comparing a value with a list of values returned by a subquery. Syntax: comparison_operator ALL (subquery) The ALL operator must be preceded by a comparison operator such as equal (=), not equal (!=), greater than (>), greater than or equal to (>=), less than (<), and less than or equal to (<=). The ALL operator must be followed by a subquery which also must be surrounded by the parentheses. select * from product where id > ALL(Select id from product where id <= 3); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 1600 | INDIA (3 rows) Exists / Not Exists The EXISTS operator is a boolean operator that tests for existence of rows in a subquery. If the subquery returns at least one row, the result of EXISTS is true. In case the subquery returns no row, the result is of EXISTS is false. select * from product where exists (select id from product where id>=3); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 1600 | INDIA (6 rows) Co-related Subquery When a Subquery is executed for each of the rows of the outer query then it is termed as a Correlated Subquery. SELECT * from EMP WHERE \u2018RIYA\u2019 IN (SELECT Name from DEPT WHERE EMP.EMPID=DEPT.EMPID);","title":"Sub-query"},{"location":"Database%20Management%20System/Postgres/11.Sub%20Query/#sub-query","text":"A subquery is a query nested inside another query such as SELECT, INSERT, DELETE and UPDATE.","title":"Sub-query"},{"location":"Database%20Management%20System/Postgres/11.Sub%20Query/#any","text":"ANY is equivalent to IN operator. select * from product where id = ANY(Select id from product where id>2);","title":"ANY"},{"location":"Database%20Management%20System/Postgres/11.Sub%20Query/#all","text":"The PostgreSQL ALL operator allows you to query data by comparing a value with a list of values returned by a subquery. Syntax: comparison_operator ALL (subquery) The ALL operator must be preceded by a comparison operator such as equal (=), not equal (!=), greater than (>), greater than or equal to (>=), less than (<), and less than or equal to (<=). The ALL operator must be followed by a subquery which also must be surrounded by the parentheses. select * from product where id > ALL(Select id from product where id <= 3); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 1600 | INDIA (3 rows)","title":"ALL"},{"location":"Database%20Management%20System/Postgres/11.Sub%20Query/#exists-not-exists","text":"The EXISTS operator is a boolean operator that tests for existence of rows in a subquery. If the subquery returns at least one row, the result of EXISTS is true. In case the subquery returns no row, the result is of EXISTS is false. select * from product where exists (select id from product where id>=3); id | name | price | country ----+----------------------------------------------------+-------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 500 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 1600 | INDIA (6 rows)","title":"Exists / Not Exists"},{"location":"Database%20Management%20System/Postgres/11.Sub%20Query/#co-related-subquery","text":"When a Subquery is executed for each of the rows of the outer query then it is termed as a Correlated Subquery. SELECT * from EMP WHERE \u2018RIYA\u2019 IN (SELECT Name from DEPT WHERE EMP.EMPID=DEPT.EMPID);","title":"Co-related Subquery"},{"location":"Database%20Management%20System/Postgres/12.Modifying%20Data/","text":"Modifying Data in Postgresql Insert The PostgreSQL INSERT statement allows you to insert a new row into a table. Syntax INSERT INTO table_name(column1, column2, \u2026) VALUES (value1, value2, \u2026); The INSERT statement also has an optional RETURNING clause that returns the information of the inserted row. INSERT INTO table_name(column1, column2, \u2026) VALUES (value1, value2, \u2026) RETURNING *; Example 1: insert into product(id, name, price, country) Values (7, 'SAMSUNG', 120000, 'KOREA'); Example 2: insert into product(id, name, price, country) Values (8, 'ONEPLUS', 130000, 'CHINA') returning id; Update The PostgreSQL UPDATE statement allows you to modify data in a table. Syntax: UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE condition; Example: ``` Update product SET price = 12000 where id = 4; ``` Update product set price = 8000 where id=6 returning id; Delete The PostgreSQL DELETE statement allows you to delete one or more rows from a table. Syntax: DELETE FROM table_name WHERE condition RETURNING (select_list | *) Example: delete from product where id=8;","title":"Modifying Data in Postgresql"},{"location":"Database%20Management%20System/Postgres/12.Modifying%20Data/#modifying-data-in-postgresql","text":"","title":"Modifying Data in Postgresql"},{"location":"Database%20Management%20System/Postgres/12.Modifying%20Data/#insert","text":"The PostgreSQL INSERT statement allows you to insert a new row into a table. Syntax INSERT INTO table_name(column1, column2, \u2026) VALUES (value1, value2, \u2026); The INSERT statement also has an optional RETURNING clause that returns the information of the inserted row. INSERT INTO table_name(column1, column2, \u2026) VALUES (value1, value2, \u2026) RETURNING *; Example 1: insert into product(id, name, price, country) Values (7, 'SAMSUNG', 120000, 'KOREA'); Example 2: insert into product(id, name, price, country) Values (8, 'ONEPLUS', 130000, 'CHINA') returning id;","title":"Insert"},{"location":"Database%20Management%20System/Postgres/12.Modifying%20Data/#update","text":"The PostgreSQL UPDATE statement allows you to modify data in a table. Syntax: UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE condition; Example: ``` Update product SET price = 12000 where id = 4; ``` Update product set price = 8000 where id=6 returning id;","title":"Update"},{"location":"Database%20Management%20System/Postgres/12.Modifying%20Data/#delete","text":"The PostgreSQL DELETE statement allows you to delete one or more rows from a table. Syntax: DELETE FROM table_name WHERE condition RETURNING (select_list | *) Example: delete from product where id=8;","title":"Delete"},{"location":"Database%20Management%20System/Postgres/13.Transactions/","text":"Transaction A PostgreSQL transaction is atomic, consistent, isolated, and durable. These properties are often referred to as ACID: Atomicity guarantees that the transaction completes in an all-or-nothing manner. Consistency ensures the change to data written to the database must be valid and follow predefined rules. Isolation determines how transaction integrity is visible to other transactions. Durability makes sure that transactions that have been committed will be stored in the database permanently. Starting a transaction: BEGIN TRANSACTION; BEGIN WORK; BEGIN; Commit a transaction: COMMIT TRANSACTION; COMMIT WORK; COMMIT; Rollback a transaction: ROLLBACK TRANSACTION; ROLLBACK WORK; ROLLBACK; Savepoint : define a new savepoint within the current transaction SAVEPOINT savepoint_name; Example mydb=# select * from product order by id; id | name | price | country ----+----------------------------------------------------+--------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 12000 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 8000 | INDIA 7 | SAMSUNG | 120000 | KOREA (7 rows) mydb=# Begin transaction; BEGIN mydb=*# Insert into product Values (8, 'Apple', 120000, 'USA'); INSERT 0 1 mydb=*# SAVEPOINT S1; SAVEPOINT mydb=*# Insert into product Values (9, 'Banana', 130000, 'USA'); INSERT 0 1 mydb=*# Rollback to s1; ROLLBACK mydb=*# Commit transaction; COMMIT mydb=# select * from product order by id; id | name | price | country ----+----------------------------------------------------+--------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 12000 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 8000 | INDIA 7 | SAMSUNG | 120000 | KOREA 8 | Apple | 120000 | USA (8 rows)","title":"Transaction"},{"location":"Database%20Management%20System/Postgres/13.Transactions/#transaction","text":"A PostgreSQL transaction is atomic, consistent, isolated, and durable. These properties are often referred to as ACID: Atomicity guarantees that the transaction completes in an all-or-nothing manner. Consistency ensures the change to data written to the database must be valid and follow predefined rules. Isolation determines how transaction integrity is visible to other transactions. Durability makes sure that transactions that have been committed will be stored in the database permanently. Starting a transaction: BEGIN TRANSACTION; BEGIN WORK; BEGIN; Commit a transaction: COMMIT TRANSACTION; COMMIT WORK; COMMIT; Rollback a transaction: ROLLBACK TRANSACTION; ROLLBACK WORK; ROLLBACK; Savepoint : define a new savepoint within the current transaction SAVEPOINT savepoint_name;","title":"Transaction"},{"location":"Database%20Management%20System/Postgres/13.Transactions/#example","text":"mydb=# select * from product order by id; id | name | price | country ----+----------------------------------------------------+--------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 12000 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 8000 | INDIA 7 | SAMSUNG | 120000 | KOREA (7 rows) mydb=# Begin transaction; BEGIN mydb=*# Insert into product Values (8, 'Apple', 120000, 'USA'); INSERT 0 1 mydb=*# SAVEPOINT S1; SAVEPOINT mydb=*# Insert into product Values (9, 'Banana', 130000, 'USA'); INSERT 0 1 mydb=*# Rollback to s1; ROLLBACK mydb=*# Commit transaction; COMMIT mydb=# select * from product order by id; id | name | price | country ----+----------------------------------------------------+--------+--------------------------- 1 | Iphone | 10000 | USA 2 | Realme | 1000 | INDIA 3 | Vivo | 2000 | CHINA 4 | CG | 12000 | NEPAL 5 | Tesla | 11500 | USA 6 | Jio | 8000 | INDIA 7 | SAMSUNG | 120000 | KOREA 8 | Apple | 120000 | USA (8 rows)","title":"Example"},{"location":"Database%20Management%20System/Postgres/14.Constraints/","text":"Constraints Primary Key A primary key is a column or a group of columns used to identify a row uniquely in a table. A table can have one and only one primary key but the primary key can consists of two or more columns. When you add a primary key to a table, PostgreSQL creates a unique B-tree index on the column or a group of columns used to define the primary key. Creating Primary Key on Table Creation: Create table post( id serial primary key, title char(50) not null); Create table post( id serial not null, no int not null, title char(50), primary key (id, no)); Creating Primary Key on Altering Table ALTER TABLE table_name ADD PRIMARY KEY (column_1, column_2); Alter table post Add primary key (id); Removing Primary key from table ALTER TABLE table_name DROP CONSTRAINT primary_key_constraint; alter table post drop constraint post_pkey; Foriegn Key A foreign key is a column or a group of columns in a table that reference the primary key of another table. The table that contains the foreign key is called the referencing table or child table. The table referenced by the foreign key is called the referenced table or parent table. A table can have multiple foreign keys depending on its relationships with other tables. Syntax: [CONSTRAINT fk_name] FOREIGN KEY(fk_columns) REFERENCES parent_table(parent_key_columns) [ON DELETE delete_action] [ON UPDATE update_action] PostgreSQL supports the following actions: SET NULL: The SET NULL automatically sets NULL to the foreign key columns in the referencing rows of the child table when the referenced rows in the parent table are deleted. SET DEFAULT: The ON DELETE SET DEFAULT sets the default value to the foreign key column of the referencing rows in the child table when the referenced rows from the parent table are deleted. RESTRICT RESTRICT prevents deletion of a referenced row. NO ACTION: NO ACTION means that if any referencing rows still exist when the constraint is checked, an error is raised. CASCADE: The ON DELETE CASCADE automatically deletes all the referencing rows in the child table when the referenced rows in the parent table are deleted. In practice, the ON DELETE CASCADE is the most commonly used option. Example: ``` DROP TABLE IF EXISTS customers; DROP TABLE IF EXISTS contacts; CREATE TABLE customers( customer_id INT GENERATED ALWAYS AS IDENTITY, customer_name VARCHAR(255) NOT NULL, PRIMARY KEY(customer_id) ); CREATE TABLE contacts( contact_id INT GENERATED ALWAYS AS IDENTITY, customer_id INT, contact_name VARCHAR(255) NOT NULL, phone VARCHAR(15), email VARCHAR(100), PRIMARY KEY(contact_id), CONSTRAINT fk_customer FOREIGN KEY(customer_id) REFERENCES customers(customer_id) ); ``` Check A CHECK constraint is a kind of constraint that allows you to specify if values in a column must meet a specific requirement. The CHECK constraint uses a Boolean expression to evaluate the values before they are inserted or updated to the column. If the values pass the check, PostgreSQL will insert or update these values to the column. Otherwise, PostgreSQL will reject the changes and issue a constraint violation error. Adding check while creating new table: DROP TABLE IF EXISTS employees; CREATE TABLE employees ( id SERIAL PRIMARY KEY, first_name VARCHAR (50), last_name VARCHAR (50), birth_date DATE CHECK (birth_date > '1900-01-01'), joined_date DATE CHECK (joined_date > birth_date), salary numeric CHECK(salary > 0) ); Adding check for existing table: ALTER TABLE prices_list ADD CONSTRAINT valid_range_check CHECK (valid_to >= valid_from); Unique PostgreSQL UNIQUE constraint to make sure that values stored in a column or a group of columns are unique across rows in a table. Sometimes, you want to ensure that values stored in a column or a group of columns are unique across the whole table such as email addresses or usernames. PostgreSQL provides you with the UNIQUE constraint that maintains the uniqueness of the data correctly. When a UNIQUE constraint is in place, every time you insert a new row, it checks if the value is already in the table. It rejects the change and issues an error if the value already exists. The same process is carried out for updating existing data. When you add a UNIQUE constraint to a column or a group of columns, PostgreSQL will automatically create a unique index on the column or the group of columns. Example: CREATE TABLE person ( id SERIAL PRIMARY KEY, first_name VARCHAR (50), last_name VARCHAR (50), email VARCHAR (50) UNIQUE ); CREATE TABLE table ( c1 data_type, c2 data_type, c3 data_type, UNIQUE (c2, c3) ); Null In database theory, NULL represents unknown or information missing. NULL is not the same as an empty string or the number zero. NULL is very special. It does not equal anything, even itself. The expression NULL = NULL returns NULL because it makes sense that two unknown values should not be equal. To check if a value is NULL or not, you use the IS NULL boolean operator. CREATE TABLE invoices( id SERIAL PRIMARY KEY, product_id INT NOT NULL, qty numeric NOT NULL CHECK(qty > 0), net_price numeric CHECK(net_price > 0) );","title":"Constraints"},{"location":"Database%20Management%20System/Postgres/14.Constraints/#constraints","text":"","title":"Constraints"},{"location":"Database%20Management%20System/Postgres/14.Constraints/#primary-key","text":"A primary key is a column or a group of columns used to identify a row uniquely in a table. A table can have one and only one primary key but the primary key can consists of two or more columns. When you add a primary key to a table, PostgreSQL creates a unique B-tree index on the column or a group of columns used to define the primary key. Creating Primary Key on Table Creation: Create table post( id serial primary key, title char(50) not null); Create table post( id serial not null, no int not null, title char(50), primary key (id, no)); Creating Primary Key on Altering Table ALTER TABLE table_name ADD PRIMARY KEY (column_1, column_2); Alter table post Add primary key (id); Removing Primary key from table ALTER TABLE table_name DROP CONSTRAINT primary_key_constraint; alter table post drop constraint post_pkey;","title":"Primary Key"},{"location":"Database%20Management%20System/Postgres/14.Constraints/#foriegn-key","text":"A foreign key is a column or a group of columns in a table that reference the primary key of another table. The table that contains the foreign key is called the referencing table or child table. The table referenced by the foreign key is called the referenced table or parent table. A table can have multiple foreign keys depending on its relationships with other tables. Syntax: [CONSTRAINT fk_name] FOREIGN KEY(fk_columns) REFERENCES parent_table(parent_key_columns) [ON DELETE delete_action] [ON UPDATE update_action] PostgreSQL supports the following actions: SET NULL: The SET NULL automatically sets NULL to the foreign key columns in the referencing rows of the child table when the referenced rows in the parent table are deleted. SET DEFAULT: The ON DELETE SET DEFAULT sets the default value to the foreign key column of the referencing rows in the child table when the referenced rows from the parent table are deleted. RESTRICT RESTRICT prevents deletion of a referenced row. NO ACTION: NO ACTION means that if any referencing rows still exist when the constraint is checked, an error is raised. CASCADE: The ON DELETE CASCADE automatically deletes all the referencing rows in the child table when the referenced rows in the parent table are deleted. In practice, the ON DELETE CASCADE is the most commonly used option. Example: ``` DROP TABLE IF EXISTS customers; DROP TABLE IF EXISTS contacts; CREATE TABLE customers( customer_id INT GENERATED ALWAYS AS IDENTITY, customer_name VARCHAR(255) NOT NULL, PRIMARY KEY(customer_id) ); CREATE TABLE contacts( contact_id INT GENERATED ALWAYS AS IDENTITY, customer_id INT, contact_name VARCHAR(255) NOT NULL, phone VARCHAR(15), email VARCHAR(100), PRIMARY KEY(contact_id), CONSTRAINT fk_customer FOREIGN KEY(customer_id) REFERENCES customers(customer_id) ); ```","title":"Foriegn Key"},{"location":"Database%20Management%20System/Postgres/14.Constraints/#check","text":"A CHECK constraint is a kind of constraint that allows you to specify if values in a column must meet a specific requirement. The CHECK constraint uses a Boolean expression to evaluate the values before they are inserted or updated to the column. If the values pass the check, PostgreSQL will insert or update these values to the column. Otherwise, PostgreSQL will reject the changes and issue a constraint violation error. Adding check while creating new table: DROP TABLE IF EXISTS employees; CREATE TABLE employees ( id SERIAL PRIMARY KEY, first_name VARCHAR (50), last_name VARCHAR (50), birth_date DATE CHECK (birth_date > '1900-01-01'), joined_date DATE CHECK (joined_date > birth_date), salary numeric CHECK(salary > 0) ); Adding check for existing table: ALTER TABLE prices_list ADD CONSTRAINT valid_range_check CHECK (valid_to >= valid_from);","title":"Check"},{"location":"Database%20Management%20System/Postgres/14.Constraints/#unique","text":"PostgreSQL UNIQUE constraint to make sure that values stored in a column or a group of columns are unique across rows in a table. Sometimes, you want to ensure that values stored in a column or a group of columns are unique across the whole table such as email addresses or usernames. PostgreSQL provides you with the UNIQUE constraint that maintains the uniqueness of the data correctly. When a UNIQUE constraint is in place, every time you insert a new row, it checks if the value is already in the table. It rejects the change and issues an error if the value already exists. The same process is carried out for updating existing data. When you add a UNIQUE constraint to a column or a group of columns, PostgreSQL will automatically create a unique index on the column or the group of columns. Example: CREATE TABLE person ( id SERIAL PRIMARY KEY, first_name VARCHAR (50), last_name VARCHAR (50), email VARCHAR (50) UNIQUE ); CREATE TABLE table ( c1 data_type, c2 data_type, c3 data_type, UNIQUE (c2, c3) );","title":"Unique"},{"location":"Database%20Management%20System/Postgres/14.Constraints/#null","text":"In database theory, NULL represents unknown or information missing. NULL is not the same as an empty string or the number zero. NULL is very special. It does not equal anything, even itself. The expression NULL = NULL returns NULL because it makes sense that two unknown values should not be equal. To check if a value is NULL or not, you use the IS NULL boolean operator. CREATE TABLE invoices( id SERIAL PRIMARY KEY, product_id INT NOT NULL, qty numeric NOT NULL CHECK(qty > 0), net_price numeric CHECK(net_price > 0) );","title":"Null"},{"location":"Database%20Management%20System/Postgres/15.pgSQL/","text":"PL/pgSQL PL/pgSQL is a procedural programming language for the PostgreSQL database system. PL/pgSQL allows you to extend the functionality of the PostgreSQL database server by creating server objects with complex logic. PL/pgSQL was designed to : Create user-defined functions, stored procedures, and triggers. Extend standard SQL by adding control structures such as if, case, and loop statements. Inherit all user-defined functions, operators, and types. PL/pgSQL wraps multiple statements in an object and store it on the PostgreSQL database server. Instead of sending multiple statements to the server one by one, you can send one statement to execute the object stored in the server.","title":"PL/pgSQL"},{"location":"Database%20Management%20System/Postgres/15.pgSQL/#plpgsql","text":"PL/pgSQL is a procedural programming language for the PostgreSQL database system. PL/pgSQL allows you to extend the functionality of the PostgreSQL database server by creating server objects with complex logic. PL/pgSQL was designed to : Create user-defined functions, stored procedures, and triggers. Extend standard SQL by adding control structures such as if, case, and loop statements. Inherit all user-defined functions, operators, and types. PL/pgSQL wraps multiple statements in an object and store it on the PostgreSQL database server. Instead of sending multiple statements to the server one by one, you can send one statement to execute the object stored in the server.","title":"PL/pgSQL"},{"location":"Database%20Management%20System/Postgres/16.Views/","text":"Views PostgreSQL view is a logical table that represents data of one or more underlying tables through a SELECT statement. A view does not store data physically except for a materialized view. A view can be very useful in some cases such as: A view helps simplify the complexity of a query because you can query a view, which is based on a complex query, using a simple SELECT statement. Like a table, you can grant permission to users through a view that contains specific data that the users are authorized to see. A view provides a consistent layer even the columns of underlying table changes. Creating View in Postgresql: CREATE VIEW view_name AS query; Altering View ALTER VIEW customer_master RENAME TO customer_info; Dropping a view DROP VIEW IF EXISTS customer_info; Materialized View PostgreSQL extends the view concept to the next level that allows views to store data physically. And these views are called materialized views. Materialized views cache the result of a complex and expensive query and allow you to refresh this result periodically. The materialized views are useful in many cases that require fast data access therefore they are often used in data warehouses and business intelligence applications.","title":"Views"},{"location":"Database%20Management%20System/Postgres/16.Views/#views","text":"PostgreSQL view is a logical table that represents data of one or more underlying tables through a SELECT statement. A view does not store data physically except for a materialized view. A view can be very useful in some cases such as: A view helps simplify the complexity of a query because you can query a view, which is based on a complex query, using a simple SELECT statement. Like a table, you can grant permission to users through a view that contains specific data that the users are authorized to see. A view provides a consistent layer even the columns of underlying table changes. Creating View in Postgresql: CREATE VIEW view_name AS query; Altering View ALTER VIEW customer_master RENAME TO customer_info; Dropping a view DROP VIEW IF EXISTS customer_info;","title":"Views"},{"location":"Database%20Management%20System/Postgres/16.Views/#materialized-view","text":"PostgreSQL extends the view concept to the next level that allows views to store data physically. And these views are called materialized views. Materialized views cache the result of a complex and expensive query and allow you to refresh this result periodically. The materialized views are useful in many cases that require fast data access therefore they are often used in data warehouses and business intelligence applications.","title":"Materialized View"},{"location":"Database%20Management%20System/Postgres/17.Trigger/","text":"Trigger A PostgreSQL trigger is a user-defined function invoked automatically whenever an event associated with a table occurs. An event could be any of the following: INSERT, UPDATE, DELETE or TRUNCATE. PostgreSQL provides two main types of triggers: row and statement-level triggers. The differences between the two kinds are how many times the trigger is invoked and at what time. For example, if you issue an UPDATE statement that affects 20 rows, the row-level trigger will be invoked 20 times, while the statement level trigger will be invoked 1 time. Triggers are useful in case the database is accessed by various applications, and you want to keep the cross-functionality within the database that runs automatically whenever the data of the table is modified. For example, if you want to keep the history of data without requiring the application to have logic to check for every event such as INSERT or UDPATE. You can also use triggers to maintain complex data integrity rules which you cannot implement elsewhere except at the database level. For example, when a new row is added into the customer table, other rows must be also created in tables of banks and credits. The main drawback of using a trigger is that you must know the trigger exists and understand its logic to figure it out the effects when data changes. Even though PostgreSQL implements SQL standard, triggers in PostgreSQL has some specific features: PostgreSQL fires trigger for the TRUNCATE event. PostgreSQL allows you to define the statement-level trigger on views. PostgreSQL requires you to define a user-defined function as the action of the trigger, while the SQL standard allows you to use any SQL commands.","title":"Trigger"},{"location":"Database%20Management%20System/Postgres/17.Trigger/#trigger","text":"A PostgreSQL trigger is a user-defined function invoked automatically whenever an event associated with a table occurs. An event could be any of the following: INSERT, UPDATE, DELETE or TRUNCATE. PostgreSQL provides two main types of triggers: row and statement-level triggers. The differences between the two kinds are how many times the trigger is invoked and at what time. For example, if you issue an UPDATE statement that affects 20 rows, the row-level trigger will be invoked 20 times, while the statement level trigger will be invoked 1 time. Triggers are useful in case the database is accessed by various applications, and you want to keep the cross-functionality within the database that runs automatically whenever the data of the table is modified. For example, if you want to keep the history of data without requiring the application to have logic to check for every event such as INSERT or UDPATE. You can also use triggers to maintain complex data integrity rules which you cannot implement elsewhere except at the database level. For example, when a new row is added into the customer table, other rows must be also created in tables of banks and credits. The main drawback of using a trigger is that you must know the trigger exists and understand its logic to figure it out the effects when data changes. Even though PostgreSQL implements SQL standard, triggers in PostgreSQL has some specific features: PostgreSQL fires trigger for the TRUNCATE event. PostgreSQL allows you to define the statement-level trigger on views. PostgreSQL requires you to define a user-defined function as the action of the trigger, while the SQL standard allows you to use any SQL commands.","title":"Trigger"},{"location":"Database%20Management%20System/Postgres/18.Indexes/","text":"Indexes PostgreSQL indexes are effective tools to enhance database performance. Indexes help the database server find specific rows much faster than it could do without indexes. Indexes add write and storage overheads to the database system. Therefore, using them appropriately is very important. PostgreSQL provides several index types: B-tree, Hash, GiST, SP-GiST, GIN and BRIN. Each index type uses a different algorithm that is best suited to different types of queries. By default, the CREATE INDEX command creates B-tree indexes, which fit the most common situations.","title":"Indexes"},{"location":"Database%20Management%20System/Postgres/18.Indexes/#indexes","text":"PostgreSQL indexes are effective tools to enhance database performance. Indexes help the database server find specific rows much faster than it could do without indexes. Indexes add write and storage overheads to the database system. Therefore, using them appropriately is very important. PostgreSQL provides several index types: B-tree, Hash, GiST, SP-GiST, GIN and BRIN. Each index type uses a different algorithm that is best suited to different types of queries. By default, the CREATE INDEX command creates B-tree indexes, which fit the most common situations.","title":"Indexes"},{"location":"Database%20Management%20System/Theory/01.Introduction/","text":"Introduction to Database Management System Database Collection of inter-related data organized in the form of a table, schemas, views etc Types of database: Centralized Database Distributed Database Relational Database Non-relational database (NoSQL) Cloud Database Object Oriented Database Hierarchial Database Network Database Personal Database Operational Database Enterprise Database Database Management System A software to manage database. Provides an interface to perform various operations like database creation, updation, deletion, table creation, updation, deletion etc. Relational Database Management System Uses table to store data Example: MySQL, Postgres, etc Some Terminologies: Table: Collection of related data enteries Contains rows and columns to store data Row: Horizontal entity in table Contains specific information about every record in table. Columns: Vertical Entity in table Contains all information assosicated with a specific field in table. Data Integrity: Entity Integrity : It specifies that there should be no duplicate rows in a table. Domain Integrity : It enforces valid entries for a given column by restricting the type, the format or, the range of values. Referential Integrity : It specifies that rows cann't be deleted which are used by other records. User-defined Integrity : It enforces some specific business rules that are defined by the users.","title":"Introduction to Database Management System"},{"location":"Database%20Management%20System/Theory/01.Introduction/#introduction-to-database-management-system","text":"","title":"Introduction to Database Management System"},{"location":"Database%20Management%20System/Theory/01.Introduction/#database","text":"Collection of inter-related data organized in the form of a table, schemas, views etc Types of database: Centralized Database Distributed Database Relational Database Non-relational database (NoSQL) Cloud Database Object Oriented Database Hierarchial Database Network Database Personal Database Operational Database Enterprise Database","title":"Database"},{"location":"Database%20Management%20System/Theory/01.Introduction/#database-management-system","text":"A software to manage database. Provides an interface to perform various operations like database creation, updation, deletion, table creation, updation, deletion etc.","title":"Database Management System"},{"location":"Database%20Management%20System/Theory/01.Introduction/#relational-database-management-system","text":"Uses table to store data Example: MySQL, Postgres, etc","title":"Relational Database Management System"},{"location":"Database%20Management%20System/Theory/01.Introduction/#some-terminologies","text":"Table: Collection of related data enteries Contains rows and columns to store data Row: Horizontal entity in table Contains specific information about every record in table. Columns: Vertical Entity in table Contains all information assosicated with a specific field in table.","title":"Some Terminologies:"},{"location":"Database%20Management%20System/Theory/01.Introduction/#data-integrity","text":"Entity Integrity : It specifies that there should be no duplicate rows in a table. Domain Integrity : It enforces valid entries for a given column by restricting the type, the format or, the range of values. Referential Integrity : It specifies that rows cann't be deleted which are used by other records. User-defined Integrity : It enforces some specific business rules that are defined by the users.","title":"Data Integrity:"},{"location":"Database%20Management%20System/Theory/02.Architecture/","text":"DBMS Architecture 1-Tier Architecture Database is directly available to the user. 2-Tier Architecture Application on client side can directly communicate with the database at server-side. For this interactions, api's like ODBC, JDBC are used. 3-Tier Architecture Application on client side communicates with the application on server side and then application on server side will further communicates with the database system.","title":"DBMS Architecture"},{"location":"Database%20Management%20System/Theory/02.Architecture/#dbms-architecture","text":"1-Tier Architecture Database is directly available to the user. 2-Tier Architecture Application on client side can directly communicate with the database at server-side. For this interactions, api's like ODBC, JDBC are used. 3-Tier Architecture Application on client side communicates with the application on server side and then application on server side will further communicates with the database system.","title":"DBMS Architecture"},{"location":"Database%20Management%20System/Theory/03.Data%20Model/","text":"Data Model Relational Data Model : It represents the data in the forms of rows and columns within a table. Entity-Relational Data Model : It represents the data in the form of entities / ER diagrams. Object-Based Data Model : Represents the data in the form of classes and objects. Semi-structured Data Model : XML is widely used for representing the semi-structured data.","title":"Data Model"},{"location":"Database%20Management%20System/Theory/03.Data%20Model/#data-model","text":"Relational Data Model : It represents the data in the forms of rows and columns within a table. Entity-Relational Data Model : It represents the data in the form of entities / ER diagrams. Object-Based Data Model : Represents the data in the form of classes and objects. Semi-structured Data Model : XML is widely used for representing the semi-structured data.","title":"Data Model"},{"location":"Database%20Management%20System/Theory/04.DBMS%20Language/","text":"DBMS Language DDL - Data Definition Language CREATE ALTER DROP TRUNCATE RENAME DML - Data Manipulation Language INSERT UPDATE DELETE DCL - Data Control Language GRANT REVOKE TCL - Transaction Control Language COMMIT ROLLBACK","title":"DBMS Language"},{"location":"Database%20Management%20System/Theory/04.DBMS%20Language/#dbms-language","text":"DDL - Data Definition Language CREATE ALTER DROP TRUNCATE RENAME DML - Data Manipulation Language INSERT UPDATE DELETE DCL - Data Control Language GRANT REVOKE TCL - Transaction Control Language COMMIT ROLLBACK","title":"DBMS Language"},{"location":"Database%20Management%20System/Theory/05.ACID%20Properties/","text":"ACID Properties 1. Atomicity Defines that data remains atomic. It means if any operation is performed on the data, either it should be executed completely or it should not be executed at all. 2. Consistency If there is any change in database, it should remain preserved always. In case of transaction, the integiry of data is very essential so that the database remains constant before and after the transaction. 3. Isolation In case of transaction, when two or more transactions occur simultaneously, the consistency should remain maintained. Any changes that occur in any particular transaction will not be seen by other transactions until the change is not commited into the memory. 4. Durability Durability ensures the permanency of something. Durability ensures that the data after the successful execution of the operation becomes permanent in the database.","title":"ACID Properties"},{"location":"Database%20Management%20System/Theory/05.ACID%20Properties/#acid-properties","text":"","title":"ACID Properties"},{"location":"Database%20Management%20System/Theory/05.ACID%20Properties/#1-atomicity","text":"Defines that data remains atomic. It means if any operation is performed on the data, either it should be executed completely or it should not be executed at all.","title":"1. Atomicity"},{"location":"Database%20Management%20System/Theory/05.ACID%20Properties/#2-consistency","text":"If there is any change in database, it should remain preserved always. In case of transaction, the integiry of data is very essential so that the database remains constant before and after the transaction.","title":"2. Consistency"},{"location":"Database%20Management%20System/Theory/05.ACID%20Properties/#3-isolation","text":"In case of transaction, when two or more transactions occur simultaneously, the consistency should remain maintained. Any changes that occur in any particular transaction will not be seen by other transactions until the change is not commited into the memory.","title":"3. Isolation"},{"location":"Database%20Management%20System/Theory/05.ACID%20Properties/#4-durability","text":"Durability ensures the permanency of something. Durability ensures that the data after the successful execution of the operation becomes permanent in the database.","title":"4. Durability"},{"location":"Database%20Management%20System/Theory/06.ER%20Model/","text":"Entity Relationship Model ER Model High-Level Data Model used to define the data elements and relatinship for a specified system. It consists of entity, attribute and relationship. Entity An entity can be an object, class, person or place. Represented By square. Types: Strong Entity: They have key attribute. Weak Entity: They dont have key attribute. Attribute Property of an entity. Represented by Eclipse. Types: Key attribute Represents a primary key. Composite Attribute Attribute composed of other attribute. Multi-valued Attribute Can have More than one value. Derived Attribute Attribute derived from other attribute. Represented by dashed ellipse. Example: age Relationship One-to-one One-to-many Many-to-one Many-to-many","title":"Entity Relationship Model"},{"location":"Database%20Management%20System/Theory/06.ER%20Model/#entity-relationship-model","text":"","title":"Entity Relationship Model"},{"location":"Database%20Management%20System/Theory/06.ER%20Model/#er-model","text":"High-Level Data Model used to define the data elements and relatinship for a specified system. It consists of entity, attribute and relationship.","title":"ER Model"},{"location":"Database%20Management%20System/Theory/06.ER%20Model/#entity","text":"An entity can be an object, class, person or place. Represented By square. Types: Strong Entity: They have key attribute. Weak Entity: They dont have key attribute.","title":"Entity"},{"location":"Database%20Management%20System/Theory/06.ER%20Model/#attribute","text":"Property of an entity. Represented by Eclipse. Types: Key attribute Represents a primary key. Composite Attribute Attribute composed of other attribute. Multi-valued Attribute Can have More than one value. Derived Attribute Attribute derived from other attribute. Represented by dashed ellipse. Example: age","title":"Attribute"},{"location":"Database%20Management%20System/Theory/06.ER%20Model/#relationship","text":"One-to-one One-to-many Many-to-one Many-to-many","title":"Relationship"},{"location":"Database%20Management%20System/Theory/07.Key/","text":"DBMS Key Used to uniquely identify any row from the table. Used to establish relationship between tables. Types of DBMS Key Primary Key Used to identify a row uniquely in a table. Foreign Key Foreign key is a column of the table which is pointing to the primary key of another table. Super Key Super key is the set of one or more columns which can be used to uniquely identify a row in a table. Candidate Key Candidate key is the minimal super key. It is the minimal combination of columns which can be used to identify each row in a table.","title":"DBMS Key"},{"location":"Database%20Management%20System/Theory/07.Key/#dbms-key","text":"Used to uniquely identify any row from the table. Used to establish relationship between tables.","title":"DBMS Key"},{"location":"Database%20Management%20System/Theory/07.Key/#types-of-dbms-key","text":"","title":"Types of DBMS Key"},{"location":"Database%20Management%20System/Theory/07.Key/#primary-key","text":"Used to identify a row uniquely in a table.","title":"Primary Key"},{"location":"Database%20Management%20System/Theory/07.Key/#foreign-key","text":"Foreign key is a column of the table which is pointing to the primary key of another table.","title":"Foreign Key"},{"location":"Database%20Management%20System/Theory/07.Key/#super-key","text":"Super key is the set of one or more columns which can be used to uniquely identify a row in a table.","title":"Super Key"},{"location":"Database%20Management%20System/Theory/07.Key/#candidate-key","text":"Candidate key is the minimal super key. It is the minimal combination of columns which can be used to identify each row in a table.","title":"Candidate Key"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/","text":"Some Important Concepts Association: If two classes in a model need to communicate with each other, there must be a link between them, and that can be represented by an association Example 1 : A single student can associate with multiple teachers. Example 2 : Every Instructor has one or more Students. Aggregation and Composition are subsets of association Aggregation: Aggregation is a subset of Association. Aggregation implies a relationship where the child can exist independently of the parent. Example: Class (parent) and Student (child). Delete the Class and the Students still exist. Composition: Composition is a subset of Association. Composition implies a relationship where the child cannot exist independent of the parent. Example: House (parent) and Room (child). Rooms don't exist separate to a House. Generalization: Generalization is a mechanism for combining similar classes of objects into a single, more general class. Generalization is the term that we use to denote abstraction of common properties into a base class in UML. The UML diagram's Generalization association is also known as Inheritance. When we implement Generalization in a programming language, it is often called Inheritance instead. Generalization and inheritance are the same. The terminology just differs depending on the context where it is being used. Specialization: Specialization is the reverse process of Generalization means creating new sub-classes from an existing class.","title":"Some Important Concepts"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/#some-important-concepts","text":"","title":"Some Important Concepts"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/#association","text":"If two classes in a model need to communicate with each other, there must be a link between them, and that can be represented by an association Example 1 : A single student can associate with multiple teachers. Example 2 : Every Instructor has one or more Students. Aggregation and Composition are subsets of association","title":"Association:"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/#aggregation","text":"Aggregation is a subset of Association. Aggregation implies a relationship where the child can exist independently of the parent. Example: Class (parent) and Student (child). Delete the Class and the Students still exist.","title":"Aggregation:"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/#composition","text":"Composition is a subset of Association. Composition implies a relationship where the child cannot exist independent of the parent. Example: House (parent) and Room (child). Rooms don't exist separate to a House.","title":"Composition:"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/#generalization","text":"Generalization is a mechanism for combining similar classes of objects into a single, more general class. Generalization is the term that we use to denote abstraction of common properties into a base class in UML. The UML diagram's Generalization association is also known as Inheritance. When we implement Generalization in a programming language, it is often called Inheritance instead. Generalization and inheritance are the same. The terminology just differs depending on the context where it is being used.","title":"Generalization:"},{"location":"Database%20Management%20System/Theory/08.Some%20Terminology/#specialization","text":"Specialization is the reverse process of Generalization means creating new sub-classes from an existing class.","title":"Specialization:"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/","text":"Relational Algebra It is procedural query language. It gives a step by step process to obtain the result of the query. It uses operators to perform queries. Types of Relational Operation 1. Select Operation Selects the tuples that satisfies a given predicate. Denoted by sigma (\u03c3). 2. Project Operation Shows the list of those attributes that we wish to appear in the result. Denoted by \u220f. 3. Union Operation Union operation contains all the tuples that are either in table A or B or both A and B. Notation: A\u222aB 4. Set Intersection: Suppose there are two tuples R and S. The set intersection operation contains all tuples that are in both R & S. Notation: R \u2229 S 5. Set Difference: Suppose there are two tuples R and S. The set intersection operation contains all tuples that are in R but not in S. Notation: R - S 6. Cartesian Product: The Cartesian product is used to combine each row in one table with each row in the other table. Notation: R x S 7. Rename Operation: Rename the output relation. Denoted by rho(\u03c1)","title":"Relational Algebra"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#relational-algebra","text":"It is procedural query language. It gives a step by step process to obtain the result of the query. It uses operators to perform queries.","title":"Relational Algebra"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#types-of-relational-operation","text":"","title":"Types of Relational Operation"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#1-select-operation","text":"Selects the tuples that satisfies a given predicate. Denoted by sigma (\u03c3).","title":"1. Select Operation"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#2-project-operation","text":"Shows the list of those attributes that we wish to appear in the result. Denoted by \u220f.","title":"2. Project Operation"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#3-union-operation","text":"Union operation contains all the tuples that are either in table A or B or both A and B. Notation: A\u222aB","title":"3. Union Operation"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#4-set-intersection","text":"Suppose there are two tuples R and S. The set intersection operation contains all tuples that are in both R & S. Notation: R \u2229 S","title":"4. Set Intersection:"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#5-set-difference","text":"Suppose there are two tuples R and S. The set intersection operation contains all tuples that are in R but not in S. Notation: R - S","title":"5. Set Difference:"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#6-cartesian-product","text":"The Cartesian product is used to combine each row in one table with each row in the other table. Notation: R x S","title":"6. Cartesian Product:"},{"location":"Database%20Management%20System/Theory/09.Relational%20Algebra/#7-rename-operation","text":"Rename the output relation. Denoted by rho(\u03c1)","title":"7. Rename Operation:"},{"location":"Database%20Management%20System/Theory/10.Functional%20Dependency/","text":"Functional Dependency It represents the relationship that exists between two attributes. Notation: X \u2192 Y where, X = Determinant, Y = Dependent Types of Functional Dependency 1. Trival Functinonal Dependency A \u2192 B has trival functional dependency if B is a subset of A. 2. Non-trival Functional Dependency A \u2192 B has non-trival functional dependency if B is not a subset of A.","title":"Functional Dependency"},{"location":"Database%20Management%20System/Theory/10.Functional%20Dependency/#functional-dependency","text":"It represents the relationship that exists between two attributes. Notation: X \u2192 Y where, X = Determinant, Y = Dependent","title":"Functional Dependency"},{"location":"Database%20Management%20System/Theory/10.Functional%20Dependency/#types-of-functional-dependency","text":"","title":"Types of Functional Dependency"},{"location":"Database%20Management%20System/Theory/10.Functional%20Dependency/#1-trival-functinonal-dependency","text":"A \u2192 B has trival functional dependency if B is a subset of A.","title":"1. Trival Functinonal Dependency"},{"location":"Database%20Management%20System/Theory/10.Functional%20Dependency/#2-non-trival-functional-dependency","text":"A \u2192 B has non-trival functional dependency if B is not a subset of A.","title":"2. Non-trival Functional Dependency"},{"location":"Database%20Management%20System/Theory/11.Normalization/","text":"DBMS Normalization Process of organizating data in the database. Used to minimize the redundancy from the relation or set of relation. Divides the larger table into smaller table and links them using relationship. Normal Form is used to reduce the redundancy from the database table. Some Terminology: 1. Partial Dependency Partial Dependency occurs when a non-prime attribute is functionally dependent on part of a candidate key. In other words, A functional dependency X->Y is a partial dependency, if Y is functionally dependent on X, and Y can be determined by any proper subset of X. 2. Transitive Dependency When an indirect relationship causes functional dependency, it is called transitive dependency. Example: P -> Q and Q -> R then P -> R is a transitive dependency. Types of Normal Form: 1NF A relation is in 1NF if it contains an atomic value. Example: ``` Employee Table: EMP_ID EMP_NAME EMP_PHONE EMP_STATE 14 John 7272826385,9064738238 UP 20 Harry 8574783832 Bihar 12 Sam 7390372389,8589830302 Punjab The decomposition of the EMPLOYEE table into 1NF has been shown below: EMP_ID EMP_NAME EMP_PHONE EMP_STATE 14 John 7272826385 UP 14 John 9064738238 UP 20 Harry 8574783832 Bihar 12 Sam 7390372389 Punjab 12 Sam 8589830302 Punjab ``` 2NF A relation will be in 2NF if it is in 1Nf and all the non-key attributes are fully functional dependent on the primary key i.e it has no partial dependency. Example: Let's assume, a school can store the data of teachers and the subjects they teach. In a school, a teacher can teach more than one subject. ``` TEACHER table TEACHER_ID SUBJECT TEACHER_AGE 25 Chemistry 30 25 Biology 30 47 English 35 83 Math 38 83 Computer 38 ``` In the given table, non-prime attribute TEACHER_AGE is dependent on TEACHER_ID which is a proper subset of a candidate key. That's why it violates the rule for 2NF. To convert the given table into 2NF, we decompose it into two tables: ``` TEACHER_DETAIL table: TEACHER_ID TEACHER_AGE 25 30 47 35 83 38 TEACHER_SUBJECT table: TEACHER_ID SUBJECT 25 Chemistry 25 Biology 47 English 83 Math 83 Computer ``` 3NF A relation will be in 3NF if it is in 2NF and it deoesn't contain any transitive dependency for non-prime attributes. 3NF is used to reduce the data duplication. Boyce Codd Normal Form (BCNF) A relation is in BCNF if it is in 3NF and for every functional dependency X -> Y, X must be the super key of the table.","title":"DBMS Normalization"},{"location":"Database%20Management%20System/Theory/11.Normalization/#dbms-normalization","text":"Process of organizating data in the database. Used to minimize the redundancy from the relation or set of relation. Divides the larger table into smaller table and links them using relationship. Normal Form is used to reduce the redundancy from the database table.","title":"DBMS Normalization"},{"location":"Database%20Management%20System/Theory/11.Normalization/#some-terminology","text":"","title":"Some Terminology:"},{"location":"Database%20Management%20System/Theory/11.Normalization/#1-partial-dependency","text":"Partial Dependency occurs when a non-prime attribute is functionally dependent on part of a candidate key. In other words, A functional dependency X->Y is a partial dependency, if Y is functionally dependent on X, and Y can be determined by any proper subset of X.","title":"1. Partial Dependency"},{"location":"Database%20Management%20System/Theory/11.Normalization/#2-transitive-dependency","text":"When an indirect relationship causes functional dependency, it is called transitive dependency. Example: P -> Q and Q -> R then P -> R is a transitive dependency.","title":"2. Transitive Dependency"},{"location":"Database%20Management%20System/Theory/11.Normalization/#types-of-normal-form","text":"","title":"Types of Normal Form:"},{"location":"Database%20Management%20System/Theory/11.Normalization/#1nf","text":"A relation is in 1NF if it contains an atomic value. Example: ``` Employee Table: EMP_ID EMP_NAME EMP_PHONE EMP_STATE 14 John 7272826385,9064738238 UP 20 Harry 8574783832 Bihar 12 Sam 7390372389,8589830302 Punjab The decomposition of the EMPLOYEE table into 1NF has been shown below: EMP_ID EMP_NAME EMP_PHONE EMP_STATE 14 John 7272826385 UP 14 John 9064738238 UP 20 Harry 8574783832 Bihar 12 Sam 7390372389 Punjab 12 Sam 8589830302 Punjab ```","title":"1NF"},{"location":"Database%20Management%20System/Theory/11.Normalization/#2nf","text":"A relation will be in 2NF if it is in 1Nf and all the non-key attributes are fully functional dependent on the primary key i.e it has no partial dependency. Example: Let's assume, a school can store the data of teachers and the subjects they teach. In a school, a teacher can teach more than one subject. ``` TEACHER table TEACHER_ID SUBJECT TEACHER_AGE 25 Chemistry 30 25 Biology 30 47 English 35 83 Math 38 83 Computer 38 ``` In the given table, non-prime attribute TEACHER_AGE is dependent on TEACHER_ID which is a proper subset of a candidate key. That's why it violates the rule for 2NF. To convert the given table into 2NF, we decompose it into two tables: ``` TEACHER_DETAIL table: TEACHER_ID TEACHER_AGE 25 30 47 35 83 38 TEACHER_SUBJECT table: TEACHER_ID SUBJECT 25 Chemistry 25 Biology 47 English 83 Math 83 Computer ```","title":"2NF"},{"location":"Database%20Management%20System/Theory/11.Normalization/#3nf","text":"A relation will be in 3NF if it is in 2NF and it deoesn't contain any transitive dependency for non-prime attributes. 3NF is used to reduce the data duplication.","title":"3NF"},{"location":"Database%20Management%20System/Theory/11.Normalization/#boyce-codd-normal-form-bcnf","text":"A relation is in BCNF if it is in 3NF and for every functional dependency X -> Y, X must be the super key of the table.","title":"Boyce Codd Normal Form (BCNF)"},{"location":"Database%20Management%20System/Theory/12.Transaction/","text":"DBMS Transaction A transaction is a series of action. It is performed by a single user to perform some operations. It has two important operations: Commit : To save the work done permanently. Rollback : To undo the work done. Properties of Transaction: Atomicity : It guarantees that the transaction completes in an all-or-nothing manner. Consistency : It ensures the change to data written to the database must be valid and follow predefined rules. Isolation : It determines how transaction integrity is visible to other transactions. Durability: It makes sure that transactions that have been committed will be stored in the database permanently. State of transaction: Active: Transaction is being executed. Partially Committed: Transaction executes its final operation but data is still not saved on database. Committed: Execution completed successfully and changes made in the database. Failed: If any of the checks made by the database recovery system fails, then the transaction is said to be in the failed state. Aborted: If any of the checks fail and the transaction has reached a failed state then the database recovery system will make sure that the database is in its previous consistent state. If not then it will abort or roll back the transaction to bring the database into a consistent state. If the transaction fails in the middle of the transaction then before executing the transaction, all the executed transactions are rolled back to its consistent state.","title":"DBMS Transaction"},{"location":"Database%20Management%20System/Theory/12.Transaction/#dbms-transaction","text":"A transaction is a series of action. It is performed by a single user to perform some operations. It has two important operations: Commit : To save the work done permanently. Rollback : To undo the work done.","title":"DBMS Transaction"},{"location":"Database%20Management%20System/Theory/12.Transaction/#properties-of-transaction","text":"Atomicity : It guarantees that the transaction completes in an all-or-nothing manner. Consistency : It ensures the change to data written to the database must be valid and follow predefined rules. Isolation : It determines how transaction integrity is visible to other transactions. Durability: It makes sure that transactions that have been committed will be stored in the database permanently.","title":"Properties of Transaction:"},{"location":"Database%20Management%20System/Theory/12.Transaction/#state-of-transaction","text":"Active: Transaction is being executed. Partially Committed: Transaction executes its final operation but data is still not saved on database. Committed: Execution completed successfully and changes made in the database. Failed: If any of the checks made by the database recovery system fails, then the transaction is said to be in the failed state. Aborted: If any of the checks fail and the transaction has reached a failed state then the database recovery system will make sure that the database is in its previous consistent state. If not then it will abort or roll back the transaction to bring the database into a consistent state. If the transaction fails in the middle of the transaction then before executing the transaction, all the executed transactions are rolled back to its consistent state.","title":"State of transaction:"},{"location":"Database%20Management%20System/Theory/13.Schedule/","text":"Schedule A series of operation from one transaction to another transaction is called schedule. In other words, it is a process of lining the transactions and executing them one by one. When there are multiple transactions that are running in a concurrent manner and the order of operation is needed to be set so that the operations do not overlap each other, Scheduling is brought into play and the transactions are timed accordingly. Types of Schedule 1. Serial Schedules The serial schedule is a type of schedule where one transaction is executed completely before starting another transaction. In the serial schedule, when the first transaction completes its cycle, then the next transaction is executed. 2. Non-serial Schedules This is a type of Scheduling where the operations of multiple transactions are interleaved. This might lead to a rise in the concurrency problem. The transactions are executed in a non-serial manner, keeping the end result correct and same as the serial schedule. Unlike the serial schedule where one transaction must wait for another to complete all its operation, in the non-serial schedule, the other transaction proceeds without waiting for the previous transaction to complete. This sort of schedule does not provide any benefit of the concurrent transaction. It can be of two types namely, Serializable and Non-Serializable Schedule. a. Serializable Schedule: This is used to maintain the consistency of the database. It is mainly used in the Non-Serial scheduling to verify whether the scheduling will lead to any inconsistency or not. Types - Conflict Serializable, View Serializable. Conflict Serializable : A schedule is called conflict serializable if it can be transformed into a serial schedule by swapping non-conflicting operations. Two operations are said to be conflicting if all conditions satisfy: They belong to different transactions They operate on the same data item At Least one of them is a write operation View Serializable : A schedule will view serializable if it is view equivalent to a serial schedule (no overlapping transactions). If a schedule is conflict serializable, then it will be view serializable. The view serializable which does not conflict serializable contains blind writes. b. Non-serializable Schedule: A non-serial schedule which is not serializable is called as non-serializable schedule. Non-serializable schedules may/may not be consistent or recoverable. Non-serializable schedule is divided into types: Recoverable schedule, Non-recoverable schedule Recoverable Schedule : A schedule is recoverable if each transaction commits only after all the transactions from which it has read has committed. In other words, if some transaction Ty reads value that has been updated/written by some other transaction Tx, then the commit of Ty must occur after the commit of Tx. Recoverable schedules are further categorised into 3 types: Cascading Schedule: When there is a failure in one transaction and this leads to the rolling back or aborting other dependent transactions, then such scheduling is referred to as Cascading rollback or cascading abort. Cascadeless Schedule: Schedules in which transactions read values only after all transactions whose changes they are going to read commit are called cascadeless schedules. Strict Schedule: A schedule is strict if for any two transactions Ti, Tj, if a write operation of Ti precedes a conflicting operation of Tj (either read or write), then the commit or abort event of Ti also precedes that conflicting operation of Tj. In other words, Tj can read or write updated or written value of Ti only after Ti commits/aborts. Non-recoverable Schedule : If a transaction reads the value of an operation from an uncommitted transaction and commits before the transaction from where it has read the value, then such a schedule is called Non-Recoverable schedule. A non recoverable schedule means when there is a system failure, we may not be able to recover to a consistent database state. If the commit operation of Ti doesn't occur before the commit operation of Tj, it is non-recoverable.","title":"Schedule"},{"location":"Database%20Management%20System/Theory/13.Schedule/#schedule","text":"A series of operation from one transaction to another transaction is called schedule. In other words, it is a process of lining the transactions and executing them one by one. When there are multiple transactions that are running in a concurrent manner and the order of operation is needed to be set so that the operations do not overlap each other, Scheduling is brought into play and the transactions are timed accordingly.","title":"Schedule"},{"location":"Database%20Management%20System/Theory/13.Schedule/#types-of-schedule","text":"","title":"Types of Schedule"},{"location":"Database%20Management%20System/Theory/13.Schedule/#1-serial-schedules","text":"The serial schedule is a type of schedule where one transaction is executed completely before starting another transaction. In the serial schedule, when the first transaction completes its cycle, then the next transaction is executed.","title":"1. Serial Schedules"},{"location":"Database%20Management%20System/Theory/13.Schedule/#2-non-serial-schedules","text":"This is a type of Scheduling where the operations of multiple transactions are interleaved. This might lead to a rise in the concurrency problem. The transactions are executed in a non-serial manner, keeping the end result correct and same as the serial schedule. Unlike the serial schedule where one transaction must wait for another to complete all its operation, in the non-serial schedule, the other transaction proceeds without waiting for the previous transaction to complete. This sort of schedule does not provide any benefit of the concurrent transaction. It can be of two types namely, Serializable and Non-Serializable Schedule.","title":"2. Non-serial Schedules"},{"location":"Database%20Management%20System/Theory/13.Schedule/#a-serializable-schedule","text":"This is used to maintain the consistency of the database. It is mainly used in the Non-Serial scheduling to verify whether the scheduling will lead to any inconsistency or not. Types - Conflict Serializable, View Serializable. Conflict Serializable : A schedule is called conflict serializable if it can be transformed into a serial schedule by swapping non-conflicting operations. Two operations are said to be conflicting if all conditions satisfy: They belong to different transactions They operate on the same data item At Least one of them is a write operation View Serializable : A schedule will view serializable if it is view equivalent to a serial schedule (no overlapping transactions). If a schedule is conflict serializable, then it will be view serializable. The view serializable which does not conflict serializable contains blind writes.","title":"a. Serializable Schedule:"},{"location":"Database%20Management%20System/Theory/13.Schedule/#b-non-serializable-schedule","text":"A non-serial schedule which is not serializable is called as non-serializable schedule. Non-serializable schedules may/may not be consistent or recoverable. Non-serializable schedule is divided into types: Recoverable schedule, Non-recoverable schedule Recoverable Schedule : A schedule is recoverable if each transaction commits only after all the transactions from which it has read has committed. In other words, if some transaction Ty reads value that has been updated/written by some other transaction Tx, then the commit of Ty must occur after the commit of Tx. Recoverable schedules are further categorised into 3 types: Cascading Schedule: When there is a failure in one transaction and this leads to the rolling back or aborting other dependent transactions, then such scheduling is referred to as Cascading rollback or cascading abort. Cascadeless Schedule: Schedules in which transactions read values only after all transactions whose changes they are going to read commit are called cascadeless schedules. Strict Schedule: A schedule is strict if for any two transactions Ti, Tj, if a write operation of Ti precedes a conflicting operation of Tj (either read or write), then the commit or abort event of Ti also precedes that conflicting operation of Tj. In other words, Tj can read or write updated or written value of Ti only after Ti commits/aborts. Non-recoverable Schedule : If a transaction reads the value of an operation from an uncommitted transaction and commits before the transaction from where it has read the value, then such a schedule is called Non-Recoverable schedule. A non recoverable schedule means when there is a system failure, we may not be able to recover to a consistent database state. If the commit operation of Ti doesn't occur before the commit operation of Tj, it is non-recoverable.","title":"b. Non-serializable Schedule:"},{"location":"Database%20Management%20System/Theory/14.Failure/","text":"Types of Failure in DBMS 1. Transaction Failure The transaction failure occurs when it fails to execute or when it reaches a point from where it can't go any further. If a few transaction or process is hurt, then this is called as transaction failure. Reasons for a transaction failure could be - Logical errors: If a transaction cannot complete due to some code error or an internal error condition, then the logical error occurs. Syntax error: It occurs where the DBMS itself terminates an active transaction because the database system is not able to execute it. For example, The system aborts an active transaction, in case of deadlock or resource unavailability. 2. System Failure System failure can occur due to power failure or other hardware or software failure. Example: Operating system error. Fail-stop assumption: In the system crash, non-volatile storage is assumed not to be corrupted. 3. Disk Failure It occurs where hard-disk drives or storage drives used to fail frequently. It was a common problem in the early days of technology evolution. Disk failure occurs due to the formation of bad sectors, disk head crash, and unreachability to the disk or any other failure, which destroy all or part of disk storage.","title":"Types of Failure in DBMS"},{"location":"Database%20Management%20System/Theory/14.Failure/#types-of-failure-in-dbms","text":"","title":"Types of Failure in DBMS"},{"location":"Database%20Management%20System/Theory/14.Failure/#1-transaction-failure","text":"The transaction failure occurs when it fails to execute or when it reaches a point from where it can't go any further. If a few transaction or process is hurt, then this is called as transaction failure. Reasons for a transaction failure could be - Logical errors: If a transaction cannot complete due to some code error or an internal error condition, then the logical error occurs. Syntax error: It occurs where the DBMS itself terminates an active transaction because the database system is not able to execute it. For example, The system aborts an active transaction, in case of deadlock or resource unavailability.","title":"1. Transaction Failure"},{"location":"Database%20Management%20System/Theory/14.Failure/#2-system-failure","text":"System failure can occur due to power failure or other hardware or software failure. Example: Operating system error. Fail-stop assumption: In the system crash, non-volatile storage is assumed not to be corrupted.","title":"2. System Failure"},{"location":"Database%20Management%20System/Theory/14.Failure/#3-disk-failure","text":"It occurs where hard-disk drives or storage drives used to fail frequently. It was a common problem in the early days of technology evolution. Disk failure occurs due to the formation of bad sectors, disk head crash, and unreachability to the disk or any other failure, which destroy all or part of disk storage.","title":"3. Disk Failure"},{"location":"Database%20Management%20System/Theory/15.Recovery/","text":"Log-based Recovery The log is a sequence of records. Log of each transaction is maintained in some stable storage so that if any failure occurs, then it can be recovered from there. If any operation is performed on the database, then it will be recorded in the log. But the process of storing the logs should be done before the actual transaction is applied in the database. Recovery using Log records When the system is crashed, then the system consults the log to find which transactions need to be undone and which need to be redone. If the log contains the record and or , then the Transaction Ti needs to be redone. If log contains record but does not contain the record either or , then the Transaction Ti needs to be undone.","title":"Log-based Recovery"},{"location":"Database%20Management%20System/Theory/15.Recovery/#log-based-recovery","text":"The log is a sequence of records. Log of each transaction is maintained in some stable storage so that if any failure occurs, then it can be recovered from there. If any operation is performed on the database, then it will be recorded in the log. But the process of storing the logs should be done before the actual transaction is applied in the database.","title":"Log-based Recovery"},{"location":"Database%20Management%20System/Theory/15.Recovery/#recovery-using-log-records","text":"When the system is crashed, then the system consults the log to find which transactions need to be undone and which need to be redone. If the log contains the record and or , then the Transaction Ti needs to be redone. If log contains record but does not contain the record either or , then the Transaction Ti needs to be undone.","title":"Recovery using Log records"},{"location":"Database%20Management%20System/Theory/16.Checkpoint/","text":"DBMS Checkpoint The checkpoint is like a bookmark. While the execution of the transaction, such checkpoints are marked, and the transaction is executed then using the steps of the transaction, the log files will be created. When it reaches to the checkpoint, then the transaction will be updated into the database, and till that point, the entire log file will be removed from the file. Then the log file is updated with the new step of transaction till next checkpoint and so on. The checkpoint is used to declare a point before which the DBMS was in the consistent state, and all transactions were committed.","title":"DBMS Checkpoint"},{"location":"Database%20Management%20System/Theory/16.Checkpoint/#dbms-checkpoint","text":"The checkpoint is like a bookmark. While the execution of the transaction, such checkpoints are marked, and the transaction is executed then using the steps of the transaction, the log files will be created. When it reaches to the checkpoint, then the transaction will be updated into the database, and till that point, the entire log file will be removed from the file. Then the log file is updated with the new step of transaction till next checkpoint and so on. The checkpoint is used to declare a point before which the DBMS was in the consistent state, and all transactions were committed.","title":"DBMS Checkpoint"},{"location":"Database%20Management%20System/Theory/17.Deadlock/","text":"Deadlock in DBMS A deadlock is a condition where two or more transactions are waiting indefinitely for one another to give up locks. Deadlock is said to be one of the most feared complications in DBMS as no task ever gets finished and is in waiting state forever. In the student table, transaction T1 holds a lock on some rows and needs to update some rows in the grade table. Simultaneously, transaction T2 holds locks on some rows in the grade table and needs to update the rows in the Student table held by Transaction T1. Deadlock Avoidance When a database is stuck in a deadlock state, then it is better to avoid the database rather than aborting or restating the database. This is a waste of time and resource. Deadlock avoidance mechanism is used to detect any deadlock situation in advance. A method like \"wait for graph\" is used for detecting the deadlock situation but this method is suitable only for the smaller database. For the larger database, deadlock prevention method can be used. Deadlock Detection In a database, when a transaction waits indefinitely to obtain a lock, then the DBMS should detect whether the transaction is involved in a deadlock or not. The lock manager maintains a Wait for the graph to detect the deadlock cycle in the database. Wait for Graph This is the suitable method for deadlock detection. In this method, a graph is created based on the transaction and their lock. If the created graph has a cycle or closed loop, then there is a deadlock. The wait for the graph is maintained by the system for every transaction which is waiting for some data held by the others. The system keeps checking the graph if there is any cycle in the graph. Deadlock Prevention Deadlock prevention method is suitable for a large database. If the resources are allocated in such a way that deadlock never occurs, then the deadlock can be prevented. The Database management system analyzes the operations of the transaction whether they can create a deadlock situation or not. If they do, then the DBMS never allowed that transaction to be executed.","title":"Deadlock in DBMS"},{"location":"Database%20Management%20System/Theory/17.Deadlock/#deadlock-in-dbms","text":"A deadlock is a condition where two or more transactions are waiting indefinitely for one another to give up locks. Deadlock is said to be one of the most feared complications in DBMS as no task ever gets finished and is in waiting state forever. In the student table, transaction T1 holds a lock on some rows and needs to update some rows in the grade table. Simultaneously, transaction T2 holds locks on some rows in the grade table and needs to update the rows in the Student table held by Transaction T1.","title":"Deadlock in DBMS"},{"location":"Database%20Management%20System/Theory/17.Deadlock/#deadlock-avoidance","text":"When a database is stuck in a deadlock state, then it is better to avoid the database rather than aborting or restating the database. This is a waste of time and resource. Deadlock avoidance mechanism is used to detect any deadlock situation in advance. A method like \"wait for graph\" is used for detecting the deadlock situation but this method is suitable only for the smaller database. For the larger database, deadlock prevention method can be used.","title":"Deadlock Avoidance"},{"location":"Database%20Management%20System/Theory/17.Deadlock/#deadlock-detection","text":"In a database, when a transaction waits indefinitely to obtain a lock, then the DBMS should detect whether the transaction is involved in a deadlock or not. The lock manager maintains a Wait for the graph to detect the deadlock cycle in the database.","title":"Deadlock Detection"},{"location":"Database%20Management%20System/Theory/17.Deadlock/#wait-for-graph","text":"This is the suitable method for deadlock detection. In this method, a graph is created based on the transaction and their lock. If the created graph has a cycle or closed loop, then there is a deadlock. The wait for the graph is maintained by the system for every transaction which is waiting for some data held by the others. The system keeps checking the graph if there is any cycle in the graph.","title":"Wait for Graph"},{"location":"Database%20Management%20System/Theory/17.Deadlock/#deadlock-prevention","text":"Deadlock prevention method is suitable for a large database. If the resources are allocated in such a way that deadlock never occurs, then the deadlock can be prevented. The Database management system analyzes the operations of the transaction whether they can create a deadlock situation or not. If they do, then the DBMS never allowed that transaction to be executed.","title":"Deadlock Prevention"},{"location":"Database%20Management%20System/Theory/18.Concurrency/","text":"DBMS Concurrency Control Concurrent Execution in DBMS In a multi-user system, multiple users can access and use the same database at one time, which is known as the concurrent execution of the database. It means that the same database is executed simultaneously on a multi-user system by different users. While working on the database transactions, there occurs the requirement of using the database by multiple users for performing different operations, and in that case, concurrent execution of the database is performed. The thing is that the simultaneous execution that is performed should be done in an interleaved manner, and no operation should affect the other executing operations, thus maintaining the consistency of the database. Thus, on making the concurrent execution of the transaction operations, there occur several challenging problems that need to be solved. Problems with Concurrent Execution 1. Lost Update Problems (W - W Conflict) The problem occurs when two different database transactions perform the read/write operations on the same database items in an interleaved manner (i.e., concurrent execution) that makes the values of the items incorrect hence making the database inconsistent. 2. Dirty Read Problems (W-R Conflict) The dirty read problem occurs when one transaction updates an item of the database, and somehow the transaction fails, and before the data gets rollback, the updated database item is accessed by another transaction. There comes the Read-Write Conflict between both transactions. 3. Unrepeatable Read Problem (W-R Conflict) Also known as Inconsistent Retrievals Problem that occurs when in a transaction, two different values are read for the same database item. Concurrency Control Concurrency Control is the working concept that is required for controlling and managing the concurrent execution of database operations and thus avoiding the inconsistencies in the database. Thus, for maintaining the concurrency of the database, we have the concurrency control protocols. Concurrency Control Protocols The concurrency control protocols ensure the atomicity, consistency, isolation, durability and serializability of the concurrent execution of the database transactions. Therefore, these protocols are categorized as: Lock Based Concurrency Control Protocol Time Stamp Concurrency Control Protocol Validation Based Concurrency Control Protocol Lock Based Concurrency Control Protocol In this type of protocol, any transaction cannot read or write data until it acquires an appropriate lock on it. There are two types of lock: Shared lock: It is also known as a Read-only lock. In a shared lock, the data item can only read by the transaction. It can be shared between the transactions because when the transaction holds a lock, then it can't update the data on the data item. Exclusive lock: In the exclusive lock, the data item can be both reads as well as written by the transaction. This lock is exclusive, and in this lock, multiple transactions do not modify the same data simultaneously. Timestamp Ordering Protocol The Timestamp Ordering Protocol is used to order the transactions based on their Timestamps. The order of transaction is nothing but the ascending order of the transaction creation. The priority of the older transaction is higher that's why it executes first. To determine the timestamp of the transaction, this protocol uses system time or logical counter. The lock-based protocol is used to manage the order between conflicting pairs among transactions at the execution time. But Timestamp based protocols start working as soon as a transaction is created. Let's assume there are two transactions T1 and T2. Suppose the transaction T1 has entered the system at 007 times and transaction T2 has entered the system at 009 times. T1 has the higher priority, so it executes first as it is entered the system first. The timestamp ordering protocol also maintains the timestamp of last 'read' and 'write' operation on a data. Validation Based Protocol Validation phase is also known as optimistic concurrency control technique. In the validation based protocol, the transaction is executed in the following three phases: Read phase: In this phase, the transaction T is read and executed. It is used to read the value of various data items and stores them in temporary local variables. It can perform all the write operations on temporary variables without an update to the actual database. Validation phase: In this phase, the temporary variable value will be validated against the actual data to see if it violates the serializability. Write phase: If the validation of the transaction is validated, then the temporary results are written to the database or system otherwise the transaction is rolled back.","title":"DBMS Concurrency Control"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#dbms-concurrency-control","text":"","title":"DBMS Concurrency Control"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#concurrent-execution-in-dbms","text":"In a multi-user system, multiple users can access and use the same database at one time, which is known as the concurrent execution of the database. It means that the same database is executed simultaneously on a multi-user system by different users. While working on the database transactions, there occurs the requirement of using the database by multiple users for performing different operations, and in that case, concurrent execution of the database is performed. The thing is that the simultaneous execution that is performed should be done in an interleaved manner, and no operation should affect the other executing operations, thus maintaining the consistency of the database. Thus, on making the concurrent execution of the transaction operations, there occur several challenging problems that need to be solved.","title":"Concurrent Execution in DBMS"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#problems-with-concurrent-execution","text":"","title":"Problems with Concurrent Execution"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#1-lost-update-problems-w-w-conflict","text":"The problem occurs when two different database transactions perform the read/write operations on the same database items in an interleaved manner (i.e., concurrent execution) that makes the values of the items incorrect hence making the database inconsistent.","title":"1. Lost Update Problems (W - W Conflict)"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#2-dirty-read-problems-w-r-conflict","text":"The dirty read problem occurs when one transaction updates an item of the database, and somehow the transaction fails, and before the data gets rollback, the updated database item is accessed by another transaction. There comes the Read-Write Conflict between both transactions.","title":"2. Dirty Read Problems (W-R Conflict)"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#3-unrepeatable-read-problem-w-r-conflict","text":"Also known as Inconsistent Retrievals Problem that occurs when in a transaction, two different values are read for the same database item.","title":"3. Unrepeatable Read Problem (W-R Conflict)"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#concurrency-control","text":"Concurrency Control is the working concept that is required for controlling and managing the concurrent execution of database operations and thus avoiding the inconsistencies in the database. Thus, for maintaining the concurrency of the database, we have the concurrency control protocols.","title":"Concurrency Control"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#concurrency-control-protocols","text":"The concurrency control protocols ensure the atomicity, consistency, isolation, durability and serializability of the concurrent execution of the database transactions. Therefore, these protocols are categorized as: Lock Based Concurrency Control Protocol Time Stamp Concurrency Control Protocol Validation Based Concurrency Control Protocol","title":"Concurrency Control Protocols"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#lock-based-concurrency-control-protocol","text":"In this type of protocol, any transaction cannot read or write data until it acquires an appropriate lock on it. There are two types of lock: Shared lock: It is also known as a Read-only lock. In a shared lock, the data item can only read by the transaction. It can be shared between the transactions because when the transaction holds a lock, then it can't update the data on the data item. Exclusive lock: In the exclusive lock, the data item can be both reads as well as written by the transaction. This lock is exclusive, and in this lock, multiple transactions do not modify the same data simultaneously.","title":"Lock Based Concurrency Control Protocol"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#timestamp-ordering-protocol","text":"The Timestamp Ordering Protocol is used to order the transactions based on their Timestamps. The order of transaction is nothing but the ascending order of the transaction creation. The priority of the older transaction is higher that's why it executes first. To determine the timestamp of the transaction, this protocol uses system time or logical counter. The lock-based protocol is used to manage the order between conflicting pairs among transactions at the execution time. But Timestamp based protocols start working as soon as a transaction is created. Let's assume there are two transactions T1 and T2. Suppose the transaction T1 has entered the system at 007 times and transaction T2 has entered the system at 009 times. T1 has the higher priority, so it executes first as it is entered the system first. The timestamp ordering protocol also maintains the timestamp of last 'read' and 'write' operation on a data.","title":"Timestamp Ordering Protocol"},{"location":"Database%20Management%20System/Theory/18.Concurrency/#validation-based-protocol","text":"Validation phase is also known as optimistic concurrency control technique. In the validation based protocol, the transaction is executed in the following three phases: Read phase: In this phase, the transaction T is read and executed. It is used to read the value of various data items and stores them in temporary local variables. It can perform all the write operations on temporary variables without an update to the actual database. Validation phase: In this phase, the temporary variable value will be validated against the actual data to see if it violates the serializability. Write phase: If the validation of the transaction is validated, then the temporary results are written to the database or system otherwise the transaction is rolled back.","title":"Validation Based Protocol"},{"location":"Database%20Management%20System/Theory/19.Indexing/","text":"DBMS Indexing Indexing is a way to optimize the performance of a database by minimizing the number of block of disk accessed required when a query is processed. It is a data structure technique which is used to quickly locate and access the data in a database. Index Structure The first column of the database is the search key that contains a copy of the primary key or candidate key of the table. The values of the primary key are stored in sorted order so that the corresponding data can be accessed easily. The second column of the database is the data reference / pointer. It contains a set of pointers holding the address of the disk block where the value of the particular key can be found. Indexing Methods 1. Primary Index If the index is created on the basis of the primary key of the table, then it is known as primary indexing. The dense index contains an index record for every search key value in the data file. It makes searching faster. In the data file, index record appears only for a few items. Each item points to a block. 2. Clustered Index Sometimes the index is created on non-primary key columns which may not be unique for each record. In this case, to identify the record faster, we will group two or more columns to get the unique value and create index out of them. This method is called a clustering index. 3. Secondary Index The secondary index can be generated by a field which has a unique value for each record. This two-level database indexing technique is used to reduce the mapping size of the first level. For the first level, a large range of numbers is selected, because of this mapping size always remains small. Multilevel Indexing Multilevel Indexing is created when a primary index does not fit in memory. In this type of indexing method, you can reduce the number of disk accesses to short any record and kept on a disk as a sequential file and create a sparse base on that file. B-Tree Indexing B-tree index is the widely used data structures for indexing. It is a multilevel index format technique which is balanced binary search trees. All leaf nodes of the B tree signify actual data pointers. In B-Tree indexing, all leaf nodes are interlinked with a link list, which allows a it to support both random and sequential access. Properties: Every path from the root to leaf are mostly of equal length. Every node which is not a root or a leaf has between n/2 and n children, where n is the degree of B-tree. Advantages of Indexing It helps you to reduce the total number of I/O operations needed to retrieve the data, so you don\u2019t need to access a row in the database from an index structure. Offers faster search and retrieval of data to users. Indexing also helps you to reduce table space as you don\u2019t need to link to a row in a table, as there is no need to store the ROWID in the Index. Thus you will able to reduce the table space. You don\u2019t need to sort data in the lead nodes as the value of the primary key classifies it. Disadvantages of Indexing To perform the indexing database management system, you need a primary key on the table with a unique value. You are not allowed to partition an index-organized table. SQL indexing decrease performance in INSERT, DELETE, and UPDATE query.","title":"DBMS Indexing"},{"location":"Database%20Management%20System/Theory/19.Indexing/#dbms-indexing","text":"Indexing is a way to optimize the performance of a database by minimizing the number of block of disk accessed required when a query is processed. It is a data structure technique which is used to quickly locate and access the data in a database.","title":"DBMS Indexing"},{"location":"Database%20Management%20System/Theory/19.Indexing/#index-structure","text":"The first column of the database is the search key that contains a copy of the primary key or candidate key of the table. The values of the primary key are stored in sorted order so that the corresponding data can be accessed easily. The second column of the database is the data reference / pointer. It contains a set of pointers holding the address of the disk block where the value of the particular key can be found.","title":"Index Structure"},{"location":"Database%20Management%20System/Theory/19.Indexing/#indexing-methods","text":"","title":"Indexing Methods"},{"location":"Database%20Management%20System/Theory/19.Indexing/#1-primary-index","text":"If the index is created on the basis of the primary key of the table, then it is known as primary indexing. The dense index contains an index record for every search key value in the data file. It makes searching faster. In the data file, index record appears only for a few items. Each item points to a block.","title":"1. Primary Index"},{"location":"Database%20Management%20System/Theory/19.Indexing/#2-clustered-index","text":"Sometimes the index is created on non-primary key columns which may not be unique for each record. In this case, to identify the record faster, we will group two or more columns to get the unique value and create index out of them. This method is called a clustering index.","title":"2. Clustered Index"},{"location":"Database%20Management%20System/Theory/19.Indexing/#3-secondary-index","text":"The secondary index can be generated by a field which has a unique value for each record. This two-level database indexing technique is used to reduce the mapping size of the first level. For the first level, a large range of numbers is selected, because of this mapping size always remains small.","title":"3. Secondary Index"},{"location":"Database%20Management%20System/Theory/19.Indexing/#multilevel-indexing","text":"Multilevel Indexing is created when a primary index does not fit in memory. In this type of indexing method, you can reduce the number of disk accesses to short any record and kept on a disk as a sequential file and create a sparse base on that file.","title":"Multilevel Indexing"},{"location":"Database%20Management%20System/Theory/19.Indexing/#b-tree-indexing","text":"B-tree index is the widely used data structures for indexing. It is a multilevel index format technique which is balanced binary search trees. All leaf nodes of the B tree signify actual data pointers. In B-Tree indexing, all leaf nodes are interlinked with a link list, which allows a it to support both random and sequential access. Properties: Every path from the root to leaf are mostly of equal length. Every node which is not a root or a leaf has between n/2 and n children, where n is the degree of B-tree.","title":"B-Tree Indexing"},{"location":"Database%20Management%20System/Theory/19.Indexing/#advantages-of-indexing","text":"It helps you to reduce the total number of I/O operations needed to retrieve the data, so you don\u2019t need to access a row in the database from an index structure. Offers faster search and retrieval of data to users. Indexing also helps you to reduce table space as you don\u2019t need to link to a row in a table, as there is no need to store the ROWID in the Index. Thus you will able to reduce the table space. You don\u2019t need to sort data in the lead nodes as the value of the primary key classifies it.","title":"Advantages of Indexing"},{"location":"Database%20Management%20System/Theory/19.Indexing/#disadvantages-of-indexing","text":"To perform the indexing database management system, you need a primary key on the table with a unique value. You are not allowed to partition an index-organized table. SQL indexing decrease performance in INSERT, DELETE, and UPDATE query.","title":"Disadvantages of Indexing"},{"location":"Nginx/01.NginxIntroduction/","text":"About Nginx It is an open-source, fast, lightweight and high-performance asynchronous web server. It is used for HTTP web serving, reverse proxy with caching, load balancing, websockets, handling static files and many more. It can handle a higher number of concurrent requests. It has faster static content delivery with low resource usage. How Does Nginx Works ? From javatpoint Nginx divided its job into the worker process and worker connections. Worker connections are used to manage the request made and the response obtained by users on the web server. At the same time, these requests are passed to its parent process which is called the worker process. Difference between apache and nginx Apache uses a multi-threaded approach to process client requests. But Nginx follows an event-driven approach to serve client requests. In Apache, a single thread can only process one connection. But in nginx, A single thread can handle multiple connections.","title":"About Nginx"},{"location":"Nginx/01.NginxIntroduction/#about-nginx","text":"It is an open-source, fast, lightweight and high-performance asynchronous web server. It is used for HTTP web serving, reverse proxy with caching, load balancing, websockets, handling static files and many more. It can handle a higher number of concurrent requests. It has faster static content delivery with low resource usage.","title":"About Nginx"},{"location":"Nginx/01.NginxIntroduction/#how-does-nginx-works","text":"From javatpoint Nginx divided its job into the worker process and worker connections. Worker connections are used to manage the request made and the response obtained by users on the web server. At the same time, these requests are passed to its parent process which is called the worker process.","title":"How Does Nginx Works ?"},{"location":"Nginx/01.NginxIntroduction/#difference-between-apache-and-nginx","text":"Apache uses a multi-threaded approach to process client requests. But Nginx follows an event-driven approach to serve client requests. In Apache, a single thread can only process one connection. But in nginx, A single thread can handle multiple connections.","title":"Difference between apache and nginx"},{"location":"Nginx/02.InstallationOnUbuntu/","text":"Installing Nginx on Ubuntu First of all, run the update sudo apt-get update Install nginx sudo apt-get install nginx Check nginx running status sudo service nginx status Check nginx status on browser by visiting localhost Start nginx sudo service nginx start Stop nginx sudo service nginx stop Restart nginx sudo service nginx restart Test nginx configuration sudo service nginx configtest","title":"Installing Nginx on Ubuntu"},{"location":"Nginx/02.InstallationOnUbuntu/#installing-nginx-on-ubuntu","text":"First of all, run the update sudo apt-get update Install nginx sudo apt-get install nginx Check nginx running status sudo service nginx status Check nginx status on browser by visiting localhost Start nginx sudo service nginx start Stop nginx sudo service nginx stop Restart nginx sudo service nginx restart Test nginx configuration sudo service nginx configtest","title":"Installing Nginx on Ubuntu"},{"location":"Nginx/03.NginxConfiguration/","text":"Nginx Configuration Opening Nginx Configuration cd /etc/nginx ls cat nginx.conf Rename the file for backup sudo mv nginx.conf nginx.conf.backup Create a new configuration file sudo touch nginx.conf Open configuration file using nano editor sudo nano nginx.conf Write this configuration in nginc.conf for serving text content. events { } http { server { listen 80; server_name nginx-handbook.test; return 200 \"Bonjour, mon ami!\\n\"; } } Test the configuration file for syntax problem sudo nginx -t Restart nginx after writing the configuration file sudo service nginx restart Writing configuration for serving static content First download the files from git and store it in srv directory The /srv directory is meant to contain site-specific data which is served by this system. Now cd into this directory and clone the code repository that comes with this book: cd /srv sudo git clone https://github.com/fhsinchy/nginx-handbook-projects.git Update the nginx.conf file for serving static content events { } http { server { listen 80; server_name nginx-handbook.test; root /srv/nginx-handbook-projects/static-demo; } }","title":"Nginx Configuration"},{"location":"Nginx/03.NginxConfiguration/#nginx-configuration","text":"","title":"Nginx Configuration"},{"location":"Nginx/03.NginxConfiguration/#opening-nginx-configuration","text":"cd /etc/nginx ls cat nginx.conf","title":"Opening Nginx Configuration"},{"location":"Nginx/03.NginxConfiguration/#rename-the-file-for-backup","text":"sudo mv nginx.conf nginx.conf.backup","title":"Rename the file for backup"},{"location":"Nginx/03.NginxConfiguration/#create-a-new-configuration-file","text":"sudo touch nginx.conf","title":"Create a new configuration file"},{"location":"Nginx/03.NginxConfiguration/#open-configuration-file-using-nano-editor","text":"sudo nano nginx.conf","title":"Open configuration file using nano editor"},{"location":"Nginx/03.NginxConfiguration/#write-this-configuration-in-ngincconf-for-serving-text-content","text":"events { } http { server { listen 80; server_name nginx-handbook.test; return 200 \"Bonjour, mon ami!\\n\"; } }","title":"Write this configuration in nginc.conf for serving text content."},{"location":"Nginx/03.NginxConfiguration/#test-the-configuration-file-for-syntax-problem","text":"sudo nginx -t","title":"Test the configuration file for syntax problem"},{"location":"Nginx/03.NginxConfiguration/#restart-nginx-after-writing-the-configuration-file","text":"sudo service nginx restart","title":"Restart nginx after writing the configuration file"},{"location":"Nginx/03.NginxConfiguration/#writing-configuration-for-serving-static-content","text":"","title":"Writing configuration for serving static content"},{"location":"Nginx/03.NginxConfiguration/#first-download-the-files-from-git-and-store-it-in-srv-directory","text":"The /srv directory is meant to contain site-specific data which is served by this system. Now cd into this directory and clone the code repository that comes with this book: cd /srv sudo git clone https://github.com/fhsinchy/nginx-handbook-projects.git","title":"First download the files from git and store it in srv directory"},{"location":"Nginx/03.NginxConfiguration/#update-the-nginxconf-file-for-serving-static-content","text":"events { } http { server { listen 80; server_name nginx-handbook.test; root /srv/nginx-handbook-projects/static-demo; } }","title":"Update the nginx.conf file for serving static content"},{"location":"Nginx/04.LocationMatches/","text":"Location Matches Nginx configuration events { } http { server { listen 80; server_name nginx-handbook.test; location =/agatha { return 200 \"Miss Marple.\\nHercule Poirot.\\n\"; } } } Visit localhost/agatha, you will get this response # HTTP/1.1 200 OK # Server: nginx/1.18.0 (Ubuntu) # Date: Wed, 21 Apr 2021 15:59:07 GMT # Content-Type: text/plain # Content-Length: 29 # Connection: keep-alive # Miss Marple. # Hercule Poirot. Adding an = sign before the location URI will instruct NGINX to respond only if the URL matches exactly. Now if you send a request to anything but /agatha, you'll get a 404 response.","title":"Location Matches"},{"location":"Nginx/04.LocationMatches/#location-matches","text":"","title":"Location Matches"},{"location":"Nginx/04.LocationMatches/#nginx-configuration","text":"events { } http { server { listen 80; server_name nginx-handbook.test; location =/agatha { return 200 \"Miss Marple.\\nHercule Poirot.\\n\"; } } } Visit localhost/agatha, you will get this response # HTTP/1.1 200 OK # Server: nginx/1.18.0 (Ubuntu) # Date: Wed, 21 Apr 2021 15:59:07 GMT # Content-Type: text/plain # Content-Length: 29 # Connection: keep-alive # Miss Marple. # Hercule Poirot. Adding an = sign before the location URI will instruct NGINX to respond only if the URL matches exactly. Now if you send a request to anything but /agatha, you'll get a 404 response.","title":"Nginx configuration"},{"location":"Nginx/05.Variables/","text":"Variables in Nginx The set directive can be used to declare new variables anywhere within the configuration file. set $<variable_name> <variable_value>; # set name \"Farhan\" # set age 25 # set is_working true Variables can be of three types: String, Integer and Boolean.","title":"Variables in Nginx"},{"location":"Nginx/05.Variables/#variables-in-nginx","text":"The set directive can be used to declare new variables anywhere within the configuration file. set $<variable_name> <variable_value>; # set name \"Farhan\" # set age 25 # set is_working true Variables can be of three types: String, Integer and Boolean.","title":"Variables in Nginx"},{"location":"Nginx/06.Redirections/","text":"Redirection Configuration in Nginx events { } http { include /etc/nginx/mime.types; server { listen 80; server_name nginx-handbook.test; root /srv/nginx-handbook-projects/static-demo; location = /index_page { return 307 /index.html; } location = /about_page { return 307 /about.html; } } }","title":"Redirection Configuration in Nginx"},{"location":"Nginx/06.Redirections/#redirection-configuration-in-nginx","text":"events { } http { include /etc/nginx/mime.types; server { listen 80; server_name nginx-handbook.test; root /srv/nginx-handbook-projects/static-demo; location = /index_page { return 307 /index.html; } location = /about_page { return 307 /about.html; } } }","title":"Redirection Configuration in Nginx"},{"location":"Nginx/07.Logging/","text":"Logging in Nginx By default, NGINX's log files are located inside /var/log/nginx. If you list the content of this directory, you may see something as follows: ls -lh /var/log/nginx/ # -rw-r----- 1 www-data adm 0 Apr 25 07:34 access.log # -rw-r----- 1 www-data adm 0 Apr 25 07:34 error.log Error messages have levels. A notice entry in the error log is harmless, but an emerg or emergency entry has to be addressed right away. There are eight levels of error messages: debug \u2013 Useful debugging information to help determine where the problem lies. info \u2013 Informational messages that aren't necessary to read but may be good to know. notice \u2013 Something normal happened that is worth noting. warn \u2013 Something unexpected happened, however is not a cause for concern. error \u2013 Something was unsuccessful. crit \u2013 There are problems that need to be critically addressed. alert \u2013 Prompt action is required. emerg \u2013 The system is in an unusable state and requires immediate attention.","title":"Logging in Nginx"},{"location":"Nginx/07.Logging/#logging-in-nginx","text":"By default, NGINX's log files are located inside /var/log/nginx. If you list the content of this directory, you may see something as follows: ls -lh /var/log/nginx/ # -rw-r----- 1 www-data adm 0 Apr 25 07:34 access.log # -rw-r----- 1 www-data adm 0 Apr 25 07:34 error.log Error messages have levels. A notice entry in the error log is harmless, but an emerg or emergency entry has to be addressed right away.","title":"Logging in Nginx"},{"location":"Nginx/07.Logging/#there-are-eight-levels-of-error-messages","text":"debug \u2013 Useful debugging information to help determine where the problem lies. info \u2013 Informational messages that aren't necessary to read but may be good to know. notice \u2013 Something normal happened that is worth noting. warn \u2013 Something unexpected happened, however is not a cause for concern. error \u2013 Something was unsuccessful. crit \u2013 There are problems that need to be critically addressed. alert \u2013 Prompt action is required. emerg \u2013 The system is in an unusable state and requires immediate attention.","title":"There are eight levels of error messages:"},{"location":"Nginx/08.ReverseProxy/","text":"Reverse Proxy Using Nginx When configured as a reverse proxy, NGINX sits between the client and a back end server. The client sends requests to NGINX, then NGINX passes the request to the back end. Once the back end server finishes processing the request, it sends it back to NGINX. In turn, NGINX returns the response to the client. During the whole process, the client doesn't have any idea about who's actually processing the request. It sounds complicated in writing, but once you do it for yourself you'll see how easy NGINX makes it. events { } http { listen 80; server_name nginx-handbook.test location / { proxy_pass http://localhost:3000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; } } The proxy_http_version directive sets the HTTP version for the server. By default it's 1.0, but web socket requires it to be at least 1.1. The proxy_set_header directive is used for setting a header on the back-end server. Generic syntax for this directive is as follows: proxy_set_header <header name> <header value> So, by writing proxy_set_header Upgrade $http_upgrade; you're instructing NGINX to pass the value of the $http_upgrade variable as a header named Upgrade \u2013 same for the Connection header.","title":"Reverse Proxy Using Nginx"},{"location":"Nginx/08.ReverseProxy/#reverse-proxy-using-nginx","text":"When configured as a reverse proxy, NGINX sits between the client and a back end server. The client sends requests to NGINX, then NGINX passes the request to the back end. Once the back end server finishes processing the request, it sends it back to NGINX. In turn, NGINX returns the response to the client. During the whole process, the client doesn't have any idea about who's actually processing the request. It sounds complicated in writing, but once you do it for yourself you'll see how easy NGINX makes it. events { } http { listen 80; server_name nginx-handbook.test location / { proxy_pass http://localhost:3000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; } } The proxy_http_version directive sets the HTTP version for the server. By default it's 1.0, but web socket requires it to be at least 1.1. The proxy_set_header directive is used for setting a header on the back-end server. Generic syntax for this directive is as follows: proxy_set_header <header name> <header value> So, by writing proxy_set_header Upgrade $http_upgrade; you're instructing NGINX to pass the value of the $http_upgrade variable as a header named Upgrade \u2013 same for the Connection header.","title":"Reverse Proxy Using Nginx"},{"location":"Operating%20System/01.Introduction/","text":"Introduction to Operating System An operating system is a program that controls the execution of application programs and acts as an interface between the user of a computer and the computer hardware. Functionalities: Resource Management: When parallel accessing happens in the OS means when multiple users are accessing the system the OS works as Resource Manager, Its responsibility is to provide hardware to the user. It decreases the load in the system. Process Management: It includes various tasks like scheduling, termination of the process. OS manages various tasks at a time. Here CPU Scheduling happens means all the tasks would be done by the many algorithms that use for scheduling. Storage Management: The file system mechanism used for the management of the storage. NIFS, CFS, CIFS, NFS, etc. are some file systems. All the data stores in various tracks of Hard disks that all managed by the storage manager. It included Hard Disk. Memory Management: Refers to the management of primary memory. The operating system has to keep track, how much memory has been used and by whom. It has to decide which process needs memory space and how much. OS also has to allocate and deallocate the memory space. Security/ Privacy Management: Privacy is also provided by the Operating system by means of passwords so that unauthorized applications can\u2019t access programs or data. For example, Windows uses Kerberos authentication to prevent unauthorized access to data. Types of Operating System 1. Batch Operating System This type of operating system does not interact with the computer directly. There is an operator which takes similar jobs having the same requirement and group them into batches. It is the responsibility of the operator to sort jobs with similar needs. Examples of Batch based Operating System: Payroll System 2. Time Sharing Operating System Each task is given some time to execute so that all the tasks work smoothly. Each user gets the time of CPU as they use a single system. After this time interval is over OS switches over to the next task. Examples of Time-Sharing OSs are: Unix, etc. 3. Distributed Operating System The Distributed Operating system is not installed on a single machine, it is divided into parts, and these parts are loaded on different machines. A part of the distributed Operating system is installed on each machine to make their communication possible. Examples of Distributed Operating System are- LOCUS, etc. 4. Network Operating System These systems run on a server and provide the capability to manage data, users, groups, security, applications, and other networking functions. These types of operating systems allow shared access of files, printers, security, applications, and other networking functions over a small private network. Examples of Network Operating System are: Linux. 5. Real-Time Operating System These types of OSs serve real-time systems. The time interval required to process and respond to inputs is very small. This time interval is called response time. Types of Memory RAM It is also called read-write memory or the main memory or the primary memory. The programs and data that the CPU requires during the execution of a program are stored in this memory. It is a volatile memory as the data is lost when the power is turned off. Types: SRAM: Used for cache. DRAM: Used for main memory. ROM Stores crucial information essential to operate the system, like the program essential to boot the computer. It is not volatile. Always retains its data. Used in embedded systems or where the programming needs no change. Used in calculators and peripheral devices. Types: PROM, EPROM, EEPROM Difference between 32-bit and 64-bit Operating System A 32-bit system can access 2^32 different memory addresses, i.e 4 GB of RAM or physical memory ideally, it can access more than 4 GB of RAM also. A 64-bit system can access 2^64 different memory addresses, i.e actually 18-Quintillion bytes of RAM. In short, any amount of memory greater than 4 GB can be easily handled by it. Some Terminologies Multiprogramming : Multiprogramming is known as keeping multiple programs in the main memory at the same time ready for execution. Multiprocessing : A computer using more than one CPU at a time. Multitasking : Multitasking is nothing but multiprogramming with a Round-robin scheduling algorithm. Multithreading: It is an extension of multitasking.","title":"Introduction to Operating System"},{"location":"Operating%20System/01.Introduction/#introduction-to-operating-system","text":"An operating system is a program that controls the execution of application programs and acts as an interface between the user of a computer and the computer hardware.","title":"Introduction to Operating System"},{"location":"Operating%20System/01.Introduction/#functionalities","text":"","title":"Functionalities:"},{"location":"Operating%20System/01.Introduction/#resource-management","text":"When parallel accessing happens in the OS means when multiple users are accessing the system the OS works as Resource Manager, Its responsibility is to provide hardware to the user. It decreases the load in the system.","title":"Resource Management:"},{"location":"Operating%20System/01.Introduction/#process-management","text":"It includes various tasks like scheduling, termination of the process. OS manages various tasks at a time. Here CPU Scheduling happens means all the tasks would be done by the many algorithms that use for scheduling.","title":"Process Management:"},{"location":"Operating%20System/01.Introduction/#storage-management","text":"The file system mechanism used for the management of the storage. NIFS, CFS, CIFS, NFS, etc. are some file systems. All the data stores in various tracks of Hard disks that all managed by the storage manager. It included Hard Disk.","title":"Storage Management:"},{"location":"Operating%20System/01.Introduction/#memory-management","text":"Refers to the management of primary memory. The operating system has to keep track, how much memory has been used and by whom. It has to decide which process needs memory space and how much. OS also has to allocate and deallocate the memory space.","title":"Memory Management:"},{"location":"Operating%20System/01.Introduction/#security-privacy-management","text":"Privacy is also provided by the Operating system by means of passwords so that unauthorized applications can\u2019t access programs or data. For example, Windows uses Kerberos authentication to prevent unauthorized access to data.","title":"Security/ Privacy Management:"},{"location":"Operating%20System/01.Introduction/#types-of-operating-system","text":"","title":"Types of Operating System"},{"location":"Operating%20System/01.Introduction/#1-batch-operating-system","text":"This type of operating system does not interact with the computer directly. There is an operator which takes similar jobs having the same requirement and group them into batches. It is the responsibility of the operator to sort jobs with similar needs. Examples of Batch based Operating System: Payroll System","title":"1. Batch Operating System"},{"location":"Operating%20System/01.Introduction/#2-time-sharing-operating-system","text":"Each task is given some time to execute so that all the tasks work smoothly. Each user gets the time of CPU as they use a single system. After this time interval is over OS switches over to the next task. Examples of Time-Sharing OSs are: Unix, etc.","title":"2. Time Sharing Operating System"},{"location":"Operating%20System/01.Introduction/#3-distributed-operating-system","text":"The Distributed Operating system is not installed on a single machine, it is divided into parts, and these parts are loaded on different machines. A part of the distributed Operating system is installed on each machine to make their communication possible. Examples of Distributed Operating System are- LOCUS, etc.","title":"3. Distributed Operating System"},{"location":"Operating%20System/01.Introduction/#4-network-operating-system","text":"These systems run on a server and provide the capability to manage data, users, groups, security, applications, and other networking functions. These types of operating systems allow shared access of files, printers, security, applications, and other networking functions over a small private network. Examples of Network Operating System are: Linux.","title":"4. Network Operating System"},{"location":"Operating%20System/01.Introduction/#5-real-time-operating-system","text":"These types of OSs serve real-time systems. The time interval required to process and respond to inputs is very small. This time interval is called response time.","title":"5. Real-Time Operating System"},{"location":"Operating%20System/01.Introduction/#types-of-memory","text":"","title":"Types of Memory"},{"location":"Operating%20System/01.Introduction/#ram","text":"It is also called read-write memory or the main memory or the primary memory. The programs and data that the CPU requires during the execution of a program are stored in this memory. It is a volatile memory as the data is lost when the power is turned off. Types: SRAM: Used for cache. DRAM: Used for main memory.","title":"RAM"},{"location":"Operating%20System/01.Introduction/#rom","text":"Stores crucial information essential to operate the system, like the program essential to boot the computer. It is not volatile. Always retains its data. Used in embedded systems or where the programming needs no change. Used in calculators and peripheral devices. Types: PROM, EPROM, EEPROM","title":"ROM"},{"location":"Operating%20System/01.Introduction/#difference-between-32-bit-and-64-bit-operating-system","text":"A 32-bit system can access 2^32 different memory addresses, i.e 4 GB of RAM or physical memory ideally, it can access more than 4 GB of RAM also. A 64-bit system can access 2^64 different memory addresses, i.e actually 18-Quintillion bytes of RAM. In short, any amount of memory greater than 4 GB can be easily handled by it.","title":"Difference between 32-bit and 64-bit Operating System"},{"location":"Operating%20System/01.Introduction/#some-terminologies","text":"Multiprogramming : Multiprogramming is known as keeping multiple programs in the main memory at the same time ready for execution. Multiprocessing : A computer using more than one CPU at a time. Multitasking : Multitasking is nothing but multiprogramming with a Round-robin scheduling algorithm. Multithreading: It is an extension of multitasking.","title":"Some Terminologies"},{"location":"Operating%20System/02.Kernel/","text":"Kernel Kernel is the core part of an operating system that manages system resources. It also acts as a bridge between the application and hardware of the computer. The CPU can execute certain instructions only when it is in kernel mode. The operating system puts the CPU in kernel mode when it is executing in the kernel so, that kernel can execute some special operation. The operating system puts the CPU in user mode when a user program is in execution so, that the user program cannot interface with the operating system program. Services of Kernel I/O Scheduling To schedule a set of I/O requests means to determine a good order in which to execute them. Buffering A buffer is a memory area that stores data being transferred between two devices or between a device and an application. Caching A cache is a region of fast memory that holds a copy of data. Access to the cached copy is much easier than the original file. Spooling A spool is a buffer that holds the output of a device, such as a printer that cannot accept interleaved data streams. Although a printer can serve only one job at a time, several applications may wish to print their output concurrently, without having their output mixes together. Error Handling I/O Protection Microkernel A microkernel is one of the classifications of the kernel. In a microkernel, the user services and kernel services are implemented in different address spaces. The user services are kept in user address space, and kernel services are kept under kernel address space, thus also reduces the size of kernel and size of an operating system as well. Monolithic Kernel Apart from microkernel, Monolithic Kernel is another classification of Kernel. Like microkernel, this one also manages system resources between application and hardware, but user services and kernel services are implemented under the same address space. It increases the size of the kernel, thus increases the size of the operating system as well. Dual Mode Operation User Mode / Non-Privileged Mode When the computer system is run by user applications like creating a text document or using any application program, then the system is in user mode. When the user application requests for a service from the operating system or an interrupt occurs or system call, then there will be a transition from user to kernel mode to fulfill the requests. Kernel Mode / Privileged Mode When the system boots, hardware starts in kernel mode and when the operating system is loaded, it starts user application in user mode. To provide protection to the hardware, we have privileged instructions which execute only in kernel mode. If the user attempts to run privileged instruction in user mode then it will treat instruction as illegal and traps to OS.","title":"02.Kernel"},{"location":"Operating%20System/02.Kernel/#kernel","text":"Kernel is the core part of an operating system that manages system resources. It also acts as a bridge between the application and hardware of the computer. The CPU can execute certain instructions only when it is in kernel mode. The operating system puts the CPU in kernel mode when it is executing in the kernel so, that kernel can execute some special operation. The operating system puts the CPU in user mode when a user program is in execution so, that the user program cannot interface with the operating system program.","title":"Kernel"},{"location":"Operating%20System/02.Kernel/#services-of-kernel","text":"I/O Scheduling To schedule a set of I/O requests means to determine a good order in which to execute them. Buffering A buffer is a memory area that stores data being transferred between two devices or between a device and an application. Caching A cache is a region of fast memory that holds a copy of data. Access to the cached copy is much easier than the original file. Spooling A spool is a buffer that holds the output of a device, such as a printer that cannot accept interleaved data streams. Although a printer can serve only one job at a time, several applications may wish to print their output concurrently, without having their output mixes together. Error Handling I/O Protection","title":"Services of Kernel"},{"location":"Operating%20System/02.Kernel/#microkernel","text":"A microkernel is one of the classifications of the kernel. In a microkernel, the user services and kernel services are implemented in different address spaces. The user services are kept in user address space, and kernel services are kept under kernel address space, thus also reduces the size of kernel and size of an operating system as well.","title":"Microkernel"},{"location":"Operating%20System/02.Kernel/#monolithic-kernel","text":"Apart from microkernel, Monolithic Kernel is another classification of Kernel. Like microkernel, this one also manages system resources between application and hardware, but user services and kernel services are implemented under the same address space. It increases the size of the kernel, thus increases the size of the operating system as well.","title":"Monolithic Kernel"},{"location":"Operating%20System/02.Kernel/#dual-mode-operation","text":"User Mode / Non-Privileged Mode When the computer system is run by user applications like creating a text document or using any application program, then the system is in user mode. When the user application requests for a service from the operating system or an interrupt occurs or system call, then there will be a transition from user to kernel mode to fulfill the requests. Kernel Mode / Privileged Mode When the system boots, hardware starts in kernel mode and when the operating system is loaded, it starts user application in user mode. To provide protection to the hardware, we have privileged instructions which execute only in kernel mode. If the user attempts to run privileged instruction in user mode then it will treat instruction as illegal and traps to OS.","title":"Dual Mode Operation"},{"location":"Operating%20System/03.System%20Call/","text":"System Call It is a programmatic method in which a computer program requests a service from the kernel of the OS. Types Process Control: This system calls perform the task of process creation, process termination, etc. File Management: File management system calls handle file manipulation jobs like creating a file, reading, and writing, etc. Device Management: Device management does the job of device manipulation like reading from device buffers, writing into device buffers, etc. Information Maintenance: It handles information and its transfer between the OS and the user program. Communications: These types of system calls are specially used for interprocess communications. Important System Calls Used in OS wait() fork() exec() kill() exit()","title":"System Call"},{"location":"Operating%20System/03.System%20Call/#system-call","text":"It is a programmatic method in which a computer program requests a service from the kernel of the OS.","title":"System Call"},{"location":"Operating%20System/03.System%20Call/#types","text":"Process Control: This system calls perform the task of process creation, process termination, etc. File Management: File management system calls handle file manipulation jobs like creating a file, reading, and writing, etc. Device Management: Device management does the job of device manipulation like reading from device buffers, writing into device buffers, etc. Information Maintenance: It handles information and its transfer between the OS and the user program. Communications: These types of system calls are specially used for interprocess communications.","title":"Types"},{"location":"Operating%20System/03.System%20Call/#important-system-calls-used-in-os","text":"wait() fork() exec() kill() exit()","title":"Important System Calls Used in OS"},{"location":"Operating%20System/04.Process%20Management/","text":"Process Management A program in execution is called a process. Attributes of a process Process ID When a process is created, a unique id is assigned to the process which is used for unique identification of the process in the system. Program Counter A program counter stores the address of the last instruction of the process on which the process was suspended. The CPU uses this address when the execution of this process is resumed. Process State The Process, from its creation to the completion, goes through various states. Priority Every process has its own priority. The process with the highest priority among the processes gets the CPU first. This is also stored on the process control block. General Purpose Registers Every process has its own set of registers which are used to hold the data which is generated during the execution of the process. List of open files During the Execution, Every process uses some files which need to be present in the main memory. OS also maintains a list of open files in the PCB. List of open devices OS also maintain the list of all open devices which are used during the execution of the process. State of a Process New A program which is going to be picked up by the OS into the main memory is called a new process. Ready The processes which are ready for the execution and reside in the main memory are called ready state processes. There can be many processes present in the ready state. Running One of the processes from the ready state will be chosen by the OS depending upon the scheduling algorithm. Block/wait When a process waits for a certain resource to be assigned or for the input from the user then the OS move this process to the block or wait state and assigns the CPU to the other processes. Suspend Ready A process in the ready state, which is moved to secondary memory from the main memory due to lack of the resources (mainly primary memory) is called in the suspend ready state. Suspend Wait Instead of removing the process from the ready queue, it's better to remove the blocked process which is waiting for some resources in the main memory. Since it is already waiting for some resource to get available hence it is better if it waits in the secondary memory and make room for the higher priority process. These processes complete their execution once the main memory gets available and their wait is finished. Termination: When a process finishes its execution, it comes in the termination state. All the context of the process (Process Control Block) will also be deleted the process will be terminated by the Operating system. Operation on a process Creation Once the process is created, it will be ready and come into the ready queue (main memory) and will be ready for the execution. Scheduling Out of the many processes present in the ready queue, the Operating system chooses one process and start executing it. Selecting the process which is to be executed next, is known as scheduling. Execution Once the process is scheduled for the execution, the processor starts executing it. Process may come to the blocked or wait state during the execution then in that case the processor starts executing the other processes. Deletion/Killing Once the purpose of the process gets over then the OS will kill the process. The Context of the process (PCB) will be deleted and the process gets terminated by the Operating system. Process Schedulers Long Term Scheduler Long term scheduler is also known as job scheduler. It chooses the processes from the pool (secondary memory) and keeps them in the ready queue maintained in the primary memory. Long Term scheduler mainly controls the degree of Multiprogramming. The purpose of long term scheduler is to choose a perfect mix of IO bound and CPU bound processes among the jobs present in the pool. If the job scheduler chooses more IO bound processes then all of the jobs may reside in the blocked state all the time and the CPU will remain idle most of the time. This will reduce the degree of Multiprogramming. Short Term Scheduler Short term scheduler is also known as CPU scheduler. It selects one of the Jobs from the ready queue and dispatch to the CPU for the execution. A scheduling algorithm is used to select which job is going to be dispatched for the execution. The Job of the short term scheduler can be very critical in the sense that if it selects job whose CPU burst time is very high then all the jobs after that, will have to wait in the ready queue for a very long time. This problem is called starvation which may arise if the short term scheduler makes some mistakes while selecting the job. Medium Term Scheduler Medium term scheduler takes care of the swapped out processes.If the running state processes needs some IO time for the completion then there is a need to change its state from running to waiting. It removes the process from the running state to make room for the other processes. Such processes are the swapped out processes and this procedure is called swapping. The medium term scheduler is responsible for suspending and resuming the processes. Process Queue Job Queue In starting, all the processes get stored in the job queue. It is maintained in the secondary memory. The long term scheduler (Job scheduler) picks some of the jobs and put them in the primary memory. Ready Queue Ready queue is maintained in primary memory. The short term scheduler picks the job from the ready queue and dispatch to the CPU for the execution. Waiting Queue When the process needs some IO operation in order to complete its execution, OS changes the state of the process from running to waiting. The context (PCB) associated with the process gets stored on the waiting queue which will be used by the Processor when the process finishes the IO. Times Related to the process Arrival Time The time at which the process enters into the ready queue is called the arrival time. Burst Time The total amount of time required by the CPU to execute the whole process is called the Burst Time. This does not include the waiting time. It is confusing to calculate the execution time for a process even before executing it hence the scheduling problems based on the burst time cannot be implemented in reality. Completion Time The Time at which the process enters into the completion state or the time at which the process completes its execution, is called completion time. Turnaround time The total amount of time spent by the process from its arrival to its completion, is called Turnaround time. Waiting Time The Total amount of time for which the process waits for the CPU to be assigned is called waiting time. Response Time The difference between the arrival time and the time at which the process first gets the CPU is called Response Time. CPU Scheduling In Multiprogramming systems, the Operating system schedules the processes on the CPU to have the maximum utilization of it and this procedure is called CPU scheduling. Whenever the running process requests some IO operation then the short term scheduler saves the current context of the process (also called PCB) and changes its state from running to waiting. During the time, process is in waiting state; the Short term scheduler picks another process from the ready queue and assigns the CPU to this process. This procedure is called context switching. The Operating system maintains a process control block during the lifetime of the process. The Process control block is deleted when the process is terminated or killed. In Multiprogramming, if the long term scheduler picks more I/O bound processes then most of the time, the CPU remains idol. The task of Operating system is to optimize the utilization of resources. If most of the running processes change their state from running to waiting then there may always be a possibility of deadlock in the system. Hence to reduce this overhead, the OS needs to schedule the jobs to get the optimal utilization of CPU and to avoid the possibility to deadlock. Scheduling Algorithms There are various algorithms which are used by the Operating System to schedule the processes on the processor in an efficient way. First Come First Serve It is the simplest algorithm to implement. The process with the minimal arrival time will get the CPU first. The lesser the arrival time, the sooner will the process gets the CPU. It is the non-preemptive type of scheduling. Round Robin In the Round Robin scheduling algorithm, the OS defines a time quantum (slice). All the processes will get executed in the cyclic way. Each of the process will get the CPU for a small amount of time (called time quantum) and then get back to the ready queue to wait for its next turn. It is a preemptive type of scheduling. Shortest Job First The job with the shortest burst time will get the CPU first. The lesser the burst time, the sooner will the process get the CPU. It is the non-preemptive type of scheduling. Shortest remaining time first It is the preemptive form of SJF. In this algorithm, the OS schedules the Job according to the remaining time of the execution. Priority based scheduling In this algorithm, the priority will be assigned to each of the processes. The higher the priority, the sooner will the process get the CPU. If the priority of the two processes is same then they will be scheduled according to their arrival time. Highest Response Ratio Next In this scheduling Algorithm, the process with highest response ratio will be scheduled next. This reduces the starvation in the system. Some Terminologies Convoy Effect / Starvation If the CPU gets the processes of the higher burst time at the front end of the ready queue then the processes of lower burst time may get blocked which means they may never get the CPU if the job in the execution has a very high burst time. This is called convoy effect or starvation. Priority Scheduling In Priority scheduling, there is a priority number assigned to each process. The Process with the higher priority among the available processes is given the CPU. There are two types of priority scheduling algorithm exists. One is Preemptive priority scheduling While the other is Non Preemptive Priority scheduling. The priority number assigned to each of the process may or may not vary. If the priority number doesn't change itself throughout the process, it is called static priority, while if it keeps changing itself at the regular intervals, it is called dynamic priority. Non-Preemptive Priority Scheduling In the Non Preemptive Priority scheduling, The processes are scheduled according to the priority number assigned to them. Once the process gets scheduled, it will run till the completion. Preemptive Priority Scheduling In Preemptive Priority Scheduling, at the time of arrival of a process in the ready queue, its Priority is compared with the priority of the other processes present in the ready queue as well as with the one which is being executed by the CPU at that point of time. The One with the highest priority among all the available processes will be given the CPU next.","title":"Process Management"},{"location":"Operating%20System/04.Process%20Management/#process-management","text":"A program in execution is called a process.","title":"Process Management"},{"location":"Operating%20System/04.Process%20Management/#attributes-of-a-process","text":"Process ID When a process is created, a unique id is assigned to the process which is used for unique identification of the process in the system. Program Counter A program counter stores the address of the last instruction of the process on which the process was suspended. The CPU uses this address when the execution of this process is resumed. Process State The Process, from its creation to the completion, goes through various states. Priority Every process has its own priority. The process with the highest priority among the processes gets the CPU first. This is also stored on the process control block. General Purpose Registers Every process has its own set of registers which are used to hold the data which is generated during the execution of the process. List of open files During the Execution, Every process uses some files which need to be present in the main memory. OS also maintains a list of open files in the PCB. List of open devices OS also maintain the list of all open devices which are used during the execution of the process.","title":"Attributes of a process"},{"location":"Operating%20System/04.Process%20Management/#state-of-a-process","text":"New A program which is going to be picked up by the OS into the main memory is called a new process. Ready The processes which are ready for the execution and reside in the main memory are called ready state processes. There can be many processes present in the ready state. Running One of the processes from the ready state will be chosen by the OS depending upon the scheduling algorithm. Block/wait When a process waits for a certain resource to be assigned or for the input from the user then the OS move this process to the block or wait state and assigns the CPU to the other processes. Suspend Ready A process in the ready state, which is moved to secondary memory from the main memory due to lack of the resources (mainly primary memory) is called in the suspend ready state. Suspend Wait Instead of removing the process from the ready queue, it's better to remove the blocked process which is waiting for some resources in the main memory. Since it is already waiting for some resource to get available hence it is better if it waits in the secondary memory and make room for the higher priority process. These processes complete their execution once the main memory gets available and their wait is finished. Termination: When a process finishes its execution, it comes in the termination state. All the context of the process (Process Control Block) will also be deleted the process will be terminated by the Operating system.","title":"State of a Process"},{"location":"Operating%20System/04.Process%20Management/#operation-on-a-process","text":"Creation Once the process is created, it will be ready and come into the ready queue (main memory) and will be ready for the execution. Scheduling Out of the many processes present in the ready queue, the Operating system chooses one process and start executing it. Selecting the process which is to be executed next, is known as scheduling. Execution Once the process is scheduled for the execution, the processor starts executing it. Process may come to the blocked or wait state during the execution then in that case the processor starts executing the other processes. Deletion/Killing Once the purpose of the process gets over then the OS will kill the process. The Context of the process (PCB) will be deleted and the process gets terminated by the Operating system.","title":"Operation on a process"},{"location":"Operating%20System/04.Process%20Management/#process-schedulers","text":"Long Term Scheduler Long term scheduler is also known as job scheduler. It chooses the processes from the pool (secondary memory) and keeps them in the ready queue maintained in the primary memory. Long Term scheduler mainly controls the degree of Multiprogramming. The purpose of long term scheduler is to choose a perfect mix of IO bound and CPU bound processes among the jobs present in the pool. If the job scheduler chooses more IO bound processes then all of the jobs may reside in the blocked state all the time and the CPU will remain idle most of the time. This will reduce the degree of Multiprogramming. Short Term Scheduler Short term scheduler is also known as CPU scheduler. It selects one of the Jobs from the ready queue and dispatch to the CPU for the execution. A scheduling algorithm is used to select which job is going to be dispatched for the execution. The Job of the short term scheduler can be very critical in the sense that if it selects job whose CPU burst time is very high then all the jobs after that, will have to wait in the ready queue for a very long time. This problem is called starvation which may arise if the short term scheduler makes some mistakes while selecting the job. Medium Term Scheduler Medium term scheduler takes care of the swapped out processes.If the running state processes needs some IO time for the completion then there is a need to change its state from running to waiting. It removes the process from the running state to make room for the other processes. Such processes are the swapped out processes and this procedure is called swapping. The medium term scheduler is responsible for suspending and resuming the processes.","title":"Process Schedulers"},{"location":"Operating%20System/04.Process%20Management/#process-queue","text":"Job Queue In starting, all the processes get stored in the job queue. It is maintained in the secondary memory. The long term scheduler (Job scheduler) picks some of the jobs and put them in the primary memory. Ready Queue Ready queue is maintained in primary memory. The short term scheduler picks the job from the ready queue and dispatch to the CPU for the execution. Waiting Queue When the process needs some IO operation in order to complete its execution, OS changes the state of the process from running to waiting. The context (PCB) associated with the process gets stored on the waiting queue which will be used by the Processor when the process finishes the IO.","title":"Process Queue"},{"location":"Operating%20System/04.Process%20Management/#times-related-to-the-process","text":"Arrival Time The time at which the process enters into the ready queue is called the arrival time. Burst Time The total amount of time required by the CPU to execute the whole process is called the Burst Time. This does not include the waiting time. It is confusing to calculate the execution time for a process even before executing it hence the scheduling problems based on the burst time cannot be implemented in reality. Completion Time The Time at which the process enters into the completion state or the time at which the process completes its execution, is called completion time. Turnaround time The total amount of time spent by the process from its arrival to its completion, is called Turnaround time. Waiting Time The Total amount of time for which the process waits for the CPU to be assigned is called waiting time. Response Time The difference between the arrival time and the time at which the process first gets the CPU is called Response Time.","title":"Times Related to the process"},{"location":"Operating%20System/04.Process%20Management/#cpu-scheduling","text":"In Multiprogramming systems, the Operating system schedules the processes on the CPU to have the maximum utilization of it and this procedure is called CPU scheduling. Whenever the running process requests some IO operation then the short term scheduler saves the current context of the process (also called PCB) and changes its state from running to waiting. During the time, process is in waiting state; the Short term scheduler picks another process from the ready queue and assigns the CPU to this process. This procedure is called context switching. The Operating system maintains a process control block during the lifetime of the process. The Process control block is deleted when the process is terminated or killed. In Multiprogramming, if the long term scheduler picks more I/O bound processes then most of the time, the CPU remains idol. The task of Operating system is to optimize the utilization of resources. If most of the running processes change their state from running to waiting then there may always be a possibility of deadlock in the system. Hence to reduce this overhead, the OS needs to schedule the jobs to get the optimal utilization of CPU and to avoid the possibility to deadlock.","title":"CPU Scheduling"},{"location":"Operating%20System/04.Process%20Management/#scheduling-algorithms","text":"There are various algorithms which are used by the Operating System to schedule the processes on the processor in an efficient way. First Come First Serve It is the simplest algorithm to implement. The process with the minimal arrival time will get the CPU first. The lesser the arrival time, the sooner will the process gets the CPU. It is the non-preemptive type of scheduling. Round Robin In the Round Robin scheduling algorithm, the OS defines a time quantum (slice). All the processes will get executed in the cyclic way. Each of the process will get the CPU for a small amount of time (called time quantum) and then get back to the ready queue to wait for its next turn. It is a preemptive type of scheduling. Shortest Job First The job with the shortest burst time will get the CPU first. The lesser the burst time, the sooner will the process get the CPU. It is the non-preemptive type of scheduling. Shortest remaining time first It is the preemptive form of SJF. In this algorithm, the OS schedules the Job according to the remaining time of the execution. Priority based scheduling In this algorithm, the priority will be assigned to each of the processes. The higher the priority, the sooner will the process get the CPU. If the priority of the two processes is same then they will be scheduled according to their arrival time. Highest Response Ratio Next In this scheduling Algorithm, the process with highest response ratio will be scheduled next. This reduces the starvation in the system.","title":"Scheduling Algorithms"},{"location":"Operating%20System/04.Process%20Management/#some-terminologies","text":"Convoy Effect / Starvation If the CPU gets the processes of the higher burst time at the front end of the ready queue then the processes of lower burst time may get blocked which means they may never get the CPU if the job in the execution has a very high burst time. This is called convoy effect or starvation. Priority Scheduling In Priority scheduling, there is a priority number assigned to each process. The Process with the higher priority among the available processes is given the CPU. There are two types of priority scheduling algorithm exists. One is Preemptive priority scheduling While the other is Non Preemptive Priority scheduling. The priority number assigned to each of the process may or may not vary. If the priority number doesn't change itself throughout the process, it is called static priority, while if it keeps changing itself at the regular intervals, it is called dynamic priority.","title":"Some Terminologies"},{"location":"Operating%20System/04.Process%20Management/#non-preemptive-priority-scheduling","text":"In the Non Preemptive Priority scheduling, The processes are scheduled according to the priority number assigned to them. Once the process gets scheduled, it will run till the completion.","title":"Non-Preemptive Priority Scheduling"},{"location":"Operating%20System/04.Process%20Management/#preemptive-priority-scheduling","text":"In Preemptive Priority Scheduling, at the time of arrival of a process in the ready queue, its Priority is compared with the priority of the other processes present in the ready queue as well as with the one which is being executed by the CPU at that point of time. The One with the highest priority among all the available processes will be given the CPU next.","title":"Preemptive Priority Scheduling"},{"location":"Operating%20System/05.Process%20Synchronization/","text":"Process Synchronization in Operating System On the basis of synchronization, processes are categorized as one of the following two types: Independent Process: The execution of one process does not affect the execution of other processes. Cooperative Process: A process that can affect or be affected by other processes executing in the system. Process synchronization problem arises in the case of Cooperative process also because resources are shared in Cooperative processes. Processes can communicate with each other through both: Shared Memory Message passing Some Terminologies Race Condition A Race Condition typically occurs when two or more threads try to read, write and possibly make the decisions based on the memory that they are accessing concurrently. It usually happens due to multiple threads accessing a shared resource or executing a common code block. Race conditions can leave the system vulnerable to security attacks where attackers can tamper with the shared data. Race conditions can be avoided by proper synchronization between threads. In Java usage of synchronized and volatile keywords helps us achieve the same Critical Section The regions of a program that try to access shared resources and may cause race conditions are called critical section. To avoid race condition among the processes, we need to assure that only one process at a time can execute within the critical section. Semaphore Semaphore is simply an integer variable that is shared between threads. This variable is used to solve the critical section problem and to achieve process synchronization in the multiprocessing environment. Semaphores are of two types: Binary Semaphore \u2013 This is also known as mutex lock. It can have only two values \u2013 0 and 1. Its value is initialized to 1. It is used to implement the solution of critical section problems with multiple processes. Counting Semaphore \u2013 Its value can range over an unrestricted domain. It is used to control access to a resource that has multiple instances. Mutex Mutex is a mutual exclusion object that synchronizes access to a resource. It is created with a unique name at the start of a program. The Mutex is a locking mechanism that makes sure only one thread can acquire the Mutex at a time and enter the critical section. This thread only releases the Mutex when it exits the critical section. Mutex VS Semaphore A Mutex is different than a semaphore as it is a locking mechanism while a semaphore is a signalling mechanism. A binary semaphore can be used as a Mutex but a Mutex can never be used as a semaphore. Producer - Consumer Problem The Producer-Consumer problem is a classic synchronization problem in operating systems. The problem is defined as follows: There is a fixed-size buffer and a Producer process, and a Consumer process. The Producer process creates an item and adds it to the shared buffer. The Consumer process takes items out of the shared buffer and \u201cconsumes\u201d them. Certain conditions must be met by the Producer and the Consumer processes to have consistent data synchronization: The Producer process must not produce an item if the shared buffer is full. The Consumer process must not consume an item if the shared buffer is empty. Access to the shared buffer must be mutually exclusive; this means that at any given instance, only one process should be able to access the shared buffer and make changes to it. The solution to the Producer-Consumer problem involves three semaphore variables. semaphore Full Tracks the space filled by the Producer process. It is initialized with a value of 0 as the buffer will have 0 filled spaces at the beginning. semaphore Empty Tracks the empty space in the buffer. It is initially set to buffer_size as the whole buffer is empty at the beginning. semaphore mutex Used for mutual exclusion so that only one process can access the shared buffer at a time. Using the signal() and wait() operations on these semaphores, we can arrive at a solution. Producer Solution: void Producer(){ while(true){ // Produce an item wait(Empty); wait(mutex); add(); signal(mutex); signal(Full); } } In the code above, the Producer process waits for the Empty semaphore. This means that the Producer process is kept in busy-waiting if the Empty semaphore value is 0 ,indicating that there are 0 empty spaces available. The Producer will have to wait for the Consumer to consume some items from the buffer and make some space available for itself. The Producer then waits for the mutex semaphore, which merely ensures that once a thread has entered the critical section of the code, the rest of the threads cannot access it and cause race conditions. The add() function appends the item to the shared buffer. Once a Producer process reaches this point in the code, it is guaranteed that no other process is accessing the shared buffer concurrently, preventing data inconsistency. After the Producer process adds the item to the shared buffer, it uses the signal() operation to increase the value of the mutex semaphore by one, thereby allowing any other threads which were busy-waiting in the mutex semaphore to access the critical section. Lastly, the Producer process uses the signal() operation on the Full semaphore, increasing its value by 1, indicating that an item has been added to the shared buffer and the count for the filled spaces has increased by one. Consumer Solution: void Consumer(){ while(true){ wait(Full); wait(mutex); consume(); signal(mutex); signal(Empty) } } The Consumer waits for the Full semaphore. If the Full semaphore value is 0, it indicates that there are no items to consume, and it must wait for the Producer process to produce an item and add it to the shared buffer for consumption. As previously mentioned, the mutex semaphore ensures mutually exclusive access to the critical section of the code so that the shared buffer is only accessed by one thread at a time for data synchronization. Once the Consumer process reaches the critical section of the code, i.e., the consume() function, it executes the function and takes one item from the shared buffer. After taking an item from the buffer, the Consumer process first uses signal(mutex) to release the mutex semaphore, allowing other threads that may have been busy-waiting in the mutex to access the critical section. Lastly, the Consumer uses signal(Empty) to increase the value of the Empty semaphore by one, indicating that a free slot has been made in the shared buffer. Any Producer processes that may have been waiting in the Empty semaphore are now allowed to add an item to the shared buffer. Requirements of Synchronization Mechanisms In order to synchronize the cooperative processes, our main task is to solve the critical section problem. We need to provide a solution in such a way that the following conditions can be satisfied. Primary Mutual Exclusion Our solution must provide mutual exclusion. By Mutual Exclusion, we mean that if one process is executing inside critical section then the other process must not enter in the critical section. Progress Progress means that if one process doesn't need to execute into critical section then it should not stop other processes to get into the critical section. Secondary Bounded Waiting We should be able to predict the waiting time for every process to get into the critical section. The process must not be endlessly waiting for getting into the critical section. Portability Our mechanism must be architectural natural. It means that if our solution is working fine on one architecture then it should also run on the other ones as well. Lock Variable Mechanism for Process Synchronization This is the simplest synchronization mechanism. This is a Software Mechanism implemented in User mode. This is a busy waiting solution which can be used for more than two processes. In this mechanism, a Lock variable lockis used. Two values of lock can be possible, either 0 or 1. Lock value 0 means that the critical section is vacant while the lock value 1 means that it is occupied. A process which wants to get into the critical section first checks the value of the lock variable. If it is 0 then it sets the value of lock as 1 and enters into the critical section, otherwise it waits. Every Synchronization mechanism is judged on the basis of four conditions. Mutual Exclusion Progress Bounded Waiting Portability The lock variable mechanism doesn't provide Mutual Exclusion in some of the cases. Let us consider that we have two processes P1 and P2. The process P1 wants to execute its critical section. P1 gets into the entry section. Since the value of lock is 0 hence P1 changes its value from 0 to 1 and enters into the critical section. Meanwhile, P1 is preempted by the CPU and P2 gets scheduled. Now there is no other process in the critical section and the value of lock variable is 0. P2 also wants to execute its critical section. It enters into the critical section by setting the lock variable to 1. Now, CPU changes P1's state from waiting to running. P1 is yet to finish its critical section. P1 has already checked the value of lock variable and remembers that its value was 0 when it previously checked it. Hence, it also enters into the critical section without checking the updated value of lock variable. Now, we got two processes in the critical section. According to the condition of mutual exclusion, morethan one process in the critical section must not be present at the same time. Hence, the lock variable mechanism doesn't guarantee the mutual exclusion. The problem with the lock variable mechanism is that, at the same time, more than one process can see the vacant tag and more than one process can enter in the critical section. Hence, the lock variable doesn't provide the mutual exclusion that's why it cannot be used in general. Peterson's Solution to Process Synchronization Peterson\u2019s Solution is a classical software-based solution to the critical section problem. It is a busy waiting solution can be implemented for only two processes. In Peterson\u2019s solution, we have two shared variables: A boolean Flag[]: A boolean array Flag which is initialized to FALSE. This Flag array represents which process wants to enter into the critical section. int Turn: A integer variable Turn indicates the process number which is ready to enter into the critical section. Peterson\u2019s Solution preserves all three conditions: Mutual Exclusion is assured as only one process can access the critical section at any time. Progress is also assured, as a process outside the critical section does not block other processes from entering the critical section. Bounded Waiting is preserved as every process gets a fair chance. Disadvantages of Peterson's solution are: The Peterson's solution involves Busy waiting The solution is also limited to only 2 processes.","title":"Process Synchronization in Operating System"},{"location":"Operating%20System/05.Process%20Synchronization/#process-synchronization-in-operating-system","text":"On the basis of synchronization, processes are categorized as one of the following two types: Independent Process: The execution of one process does not affect the execution of other processes. Cooperative Process: A process that can affect or be affected by other processes executing in the system. Process synchronization problem arises in the case of Cooperative process also because resources are shared in Cooperative processes. Processes can communicate with each other through both: Shared Memory Message passing","title":"Process Synchronization in Operating System"},{"location":"Operating%20System/05.Process%20Synchronization/#some-terminologies","text":"Race Condition A Race Condition typically occurs when two or more threads try to read, write and possibly make the decisions based on the memory that they are accessing concurrently. It usually happens due to multiple threads accessing a shared resource or executing a common code block. Race conditions can leave the system vulnerable to security attacks where attackers can tamper with the shared data. Race conditions can be avoided by proper synchronization between threads. In Java usage of synchronized and volatile keywords helps us achieve the same Critical Section The regions of a program that try to access shared resources and may cause race conditions are called critical section. To avoid race condition among the processes, we need to assure that only one process at a time can execute within the critical section. Semaphore Semaphore is simply an integer variable that is shared between threads. This variable is used to solve the critical section problem and to achieve process synchronization in the multiprocessing environment. Semaphores are of two types: Binary Semaphore \u2013 This is also known as mutex lock. It can have only two values \u2013 0 and 1. Its value is initialized to 1. It is used to implement the solution of critical section problems with multiple processes. Counting Semaphore \u2013 Its value can range over an unrestricted domain. It is used to control access to a resource that has multiple instances. Mutex Mutex is a mutual exclusion object that synchronizes access to a resource. It is created with a unique name at the start of a program. The Mutex is a locking mechanism that makes sure only one thread can acquire the Mutex at a time and enter the critical section. This thread only releases the Mutex when it exits the critical section. Mutex VS Semaphore A Mutex is different than a semaphore as it is a locking mechanism while a semaphore is a signalling mechanism. A binary semaphore can be used as a Mutex but a Mutex can never be used as a semaphore.","title":"Some Terminologies"},{"location":"Operating%20System/05.Process%20Synchronization/#producer-consumer-problem","text":"The Producer-Consumer problem is a classic synchronization problem in operating systems. The problem is defined as follows: There is a fixed-size buffer and a Producer process, and a Consumer process. The Producer process creates an item and adds it to the shared buffer. The Consumer process takes items out of the shared buffer and \u201cconsumes\u201d them. Certain conditions must be met by the Producer and the Consumer processes to have consistent data synchronization: The Producer process must not produce an item if the shared buffer is full. The Consumer process must not consume an item if the shared buffer is empty. Access to the shared buffer must be mutually exclusive; this means that at any given instance, only one process should be able to access the shared buffer and make changes to it. The solution to the Producer-Consumer problem involves three semaphore variables. semaphore Full Tracks the space filled by the Producer process. It is initialized with a value of 0 as the buffer will have 0 filled spaces at the beginning. semaphore Empty Tracks the empty space in the buffer. It is initially set to buffer_size as the whole buffer is empty at the beginning. semaphore mutex Used for mutual exclusion so that only one process can access the shared buffer at a time. Using the signal() and wait() operations on these semaphores, we can arrive at a solution. Producer Solution: void Producer(){ while(true){ // Produce an item wait(Empty); wait(mutex); add(); signal(mutex); signal(Full); } } In the code above, the Producer process waits for the Empty semaphore. This means that the Producer process is kept in busy-waiting if the Empty semaphore value is 0 ,indicating that there are 0 empty spaces available. The Producer will have to wait for the Consumer to consume some items from the buffer and make some space available for itself. The Producer then waits for the mutex semaphore, which merely ensures that once a thread has entered the critical section of the code, the rest of the threads cannot access it and cause race conditions. The add() function appends the item to the shared buffer. Once a Producer process reaches this point in the code, it is guaranteed that no other process is accessing the shared buffer concurrently, preventing data inconsistency. After the Producer process adds the item to the shared buffer, it uses the signal() operation to increase the value of the mutex semaphore by one, thereby allowing any other threads which were busy-waiting in the mutex semaphore to access the critical section. Lastly, the Producer process uses the signal() operation on the Full semaphore, increasing its value by 1, indicating that an item has been added to the shared buffer and the count for the filled spaces has increased by one. Consumer Solution: void Consumer(){ while(true){ wait(Full); wait(mutex); consume(); signal(mutex); signal(Empty) } } The Consumer waits for the Full semaphore. If the Full semaphore value is 0, it indicates that there are no items to consume, and it must wait for the Producer process to produce an item and add it to the shared buffer for consumption. As previously mentioned, the mutex semaphore ensures mutually exclusive access to the critical section of the code so that the shared buffer is only accessed by one thread at a time for data synchronization. Once the Consumer process reaches the critical section of the code, i.e., the consume() function, it executes the function and takes one item from the shared buffer. After taking an item from the buffer, the Consumer process first uses signal(mutex) to release the mutex semaphore, allowing other threads that may have been busy-waiting in the mutex to access the critical section. Lastly, the Consumer uses signal(Empty) to increase the value of the Empty semaphore by one, indicating that a free slot has been made in the shared buffer. Any Producer processes that may have been waiting in the Empty semaphore are now allowed to add an item to the shared buffer.","title":"Producer - Consumer Problem"},{"location":"Operating%20System/05.Process%20Synchronization/#requirements-of-synchronization-mechanisms","text":"In order to synchronize the cooperative processes, our main task is to solve the critical section problem. We need to provide a solution in such a way that the following conditions can be satisfied. Primary Mutual Exclusion Our solution must provide mutual exclusion. By Mutual Exclusion, we mean that if one process is executing inside critical section then the other process must not enter in the critical section. Progress Progress means that if one process doesn't need to execute into critical section then it should not stop other processes to get into the critical section. Secondary Bounded Waiting We should be able to predict the waiting time for every process to get into the critical section. The process must not be endlessly waiting for getting into the critical section. Portability Our mechanism must be architectural natural. It means that if our solution is working fine on one architecture then it should also run on the other ones as well.","title":"Requirements of Synchronization Mechanisms"},{"location":"Operating%20System/05.Process%20Synchronization/#lock-variable-mechanism-for-process-synchronization","text":"This is the simplest synchronization mechanism. This is a Software Mechanism implemented in User mode. This is a busy waiting solution which can be used for more than two processes. In this mechanism, a Lock variable lockis used. Two values of lock can be possible, either 0 or 1. Lock value 0 means that the critical section is vacant while the lock value 1 means that it is occupied. A process which wants to get into the critical section first checks the value of the lock variable. If it is 0 then it sets the value of lock as 1 and enters into the critical section, otherwise it waits. Every Synchronization mechanism is judged on the basis of four conditions. Mutual Exclusion Progress Bounded Waiting Portability The lock variable mechanism doesn't provide Mutual Exclusion in some of the cases. Let us consider that we have two processes P1 and P2. The process P1 wants to execute its critical section. P1 gets into the entry section. Since the value of lock is 0 hence P1 changes its value from 0 to 1 and enters into the critical section. Meanwhile, P1 is preempted by the CPU and P2 gets scheduled. Now there is no other process in the critical section and the value of lock variable is 0. P2 also wants to execute its critical section. It enters into the critical section by setting the lock variable to 1. Now, CPU changes P1's state from waiting to running. P1 is yet to finish its critical section. P1 has already checked the value of lock variable and remembers that its value was 0 when it previously checked it. Hence, it also enters into the critical section without checking the updated value of lock variable. Now, we got two processes in the critical section. According to the condition of mutual exclusion, morethan one process in the critical section must not be present at the same time. Hence, the lock variable mechanism doesn't guarantee the mutual exclusion. The problem with the lock variable mechanism is that, at the same time, more than one process can see the vacant tag and more than one process can enter in the critical section. Hence, the lock variable doesn't provide the mutual exclusion that's why it cannot be used in general.","title":"Lock Variable Mechanism for Process Synchronization"},{"location":"Operating%20System/05.Process%20Synchronization/#petersons-solution-to-process-synchronization","text":"Peterson\u2019s Solution is a classical software-based solution to the critical section problem. It is a busy waiting solution can be implemented for only two processes. In Peterson\u2019s solution, we have two shared variables: A boolean Flag[]: A boolean array Flag which is initialized to FALSE. This Flag array represents which process wants to enter into the critical section. int Turn: A integer variable Turn indicates the process number which is ready to enter into the critical section. Peterson\u2019s Solution preserves all three conditions: Mutual Exclusion is assured as only one process can access the critical section at any time. Progress is also assured, as a process outside the critical section does not block other processes from entering the critical section. Bounded Waiting is preserved as every process gets a fair chance. Disadvantages of Peterson's solution are: The Peterson's solution involves Busy waiting The solution is also limited to only 2 processes.","title":"Peterson's Solution to Process Synchronization"},{"location":"Operating%20System/06.%20Deadlock/","text":"Deadlock in Operating System A Deadlock is a situation where each of the computer process waits for a resource which is being assigned to some another process. In this situation, none of the process gets executed since the resource it needs, is held by some other process which is also waiting for some other resource to be released. Deadlock VS Starvation: Deadlock is a situation where no process got blocked and no process proceeds. Starvation is a situation where the low priority process got blocked and the high priority processes proceed. Necessary conditions for Deadlocks Mutual Exclusion A resource can only be shared in mutually exclusive manner. It implies, if two process cannot use the same resource at the same time. Hold and Wait A process waits for some resources while holding another resource at the same time. No preemption The process which once scheduled will be executed till the completion. No other process can be scheduled by the scheduler meanwhile. Circular Wait All the processes must be waiting for the resources in a cyclic manner so that the last process is waiting for the resource which is being held by the first process. Strategies to handle Deadlock Deadlock Ignorance Deadlock Ignorance is the most widely used approach among all the mechanism. This is being used by many operating systems mainly for end user uses. In this approach, the Operating system assumes that deadlock never occurs. It simply ignores deadlock. This approach is best suitable for a single end user system where User uses the system only for browsing and all other normal stuff. Deadlock prevention Deadlock happens only when Mutual Exclusion, hold and wait, No preemption and circular wait holds simultaneously. If it is possible to violate one of the four conditions at any time then the deadlock can never occur in the system. The idea behind the approach is very simple that we have to fail one of the four conditions but there can be a big argument on its physical implementation in the system. Deadlock avoidance In deadlock avoidance, the operating system checks whether the system is in safe state or in unsafe state at every step which the operating system performs. The process continues until the system is in safe state. Once the system moves to unsafe state, the OS has to backtrack one step. In simple words, The OS reviews each allocation so that the allocation doesn't cause the deadlock in the system. Deadlock detection and recovery This approach let the processes fall in deadlock and then periodically check whether deadlock occur in the system or not. If it occurs then it applies some of the recovery methods to the system to get rid of deadlock. Deadlock Prevention If we can be able to violate one of the four necessary conditions and don't let them occur together then we can prevent the deadlock. Mutual Exclusion Spooling can be an effective approach to violate mutual exclusion but it suffers from some kinds of problems. We cannot violate mutual exclusion for a process practically. Hold and Wait A process must be assigned all the necessary resources before the execution starts. A process must not wait for any resource once the execution has been started. But it is practically not possible. Possibility of getting starved will be increases due to the fact that some process may hold a resource for a very long time. No Preemption If we take the resource away from the process which is causing deadlock then we can prevent deadlock. This is not a good approach at all since if we take a resource away which is being used by the process then all the work which it has done till now can become inconsistent. Circular Wait To violate circular wait, we can assign a priority number to each of the resource. A process can't request for a lesser priority resource. This ensures that not a single process can request a resource which is being utilized by some other process and no cycle will be formed. Among all the methods, violating Circular wait is the only approach that can be implemented practically. Deadlock Avoidance In deadlock avoidance, the request for any resource will be granted if the resulting state of the system doesn't cause deadlock in the system. The state of the system will continuously be checked for safe and unsafe states. In order to avoid deadlocks, the process must tell OS, the maximum number of resources a process can request to complete its execution. The simplest and most useful approach states that the process should declare the maximum number of resources of each type it may ever need. The Deadlock avoidance algorithm examines the resource allocations so that there can never be a circular wait condition. A state of the system is called safe if the system can allocate all the resources requested by all the processes without entering into deadlock. If the system cannot fulfill the request of all processes then the state of the system is called unsafe. The key of Deadlock avoidance approach is when the request is made for resources then the request must only be approved in the case if the resulting state is also a safe state. Deadlock Detection The OS can detect the deadlocks with the help of Resource allocation graph. Detection Single Instance --> Detect Cycle Multiple Instance --> Safety Algorithm In single instanced resource types, if a cycle is being formed in the system then there will definitely be a deadlock. In multiple instanced resource type graph, detecting a cycle is not just enough. We have to apply the safety algorithm on the system by converting the resource allocation graph into the allocation matrix and request matrix. Deadlock Recovery In order to recover the system from deadlocks, either OS considers resources or processes. For Resource Preempt the resource We can snatch one of the resources from the owner of the resource (process) and give it to the other process with the expectation that it will complete the execution and will release this resource sooner. Well, choosing a resource which will be snatched is going to be a bit difficult. Rollback to a safe state System passes through various states to get into the deadlock state. The operating system canrollback the system to the previous safe state. For this purpose, OS needs to implement check pointing at every state. The moment, we get into deadlock, we will rollback all the allocations to get into the previous safe state. For Process Kill a process Killing a process can solve our problem but the bigger concern is to decide which process to kill. Generally, Operating system kills a process which has done least amount of work until now. Kill all process This is not a suggestible approach but can be implemented if the problem becomes very serious. Killing all process will lead to inefficiency in the system because all the processes will execute again from starting.","title":"Deadlock in Operating System"},{"location":"Operating%20System/06.%20Deadlock/#deadlock-in-operating-system","text":"A Deadlock is a situation where each of the computer process waits for a resource which is being assigned to some another process. In this situation, none of the process gets executed since the resource it needs, is held by some other process which is also waiting for some other resource to be released. Deadlock VS Starvation: Deadlock is a situation where no process got blocked and no process proceeds. Starvation is a situation where the low priority process got blocked and the high priority processes proceed.","title":"Deadlock in Operating System"},{"location":"Operating%20System/06.%20Deadlock/#necessary-conditions-for-deadlocks","text":"Mutual Exclusion A resource can only be shared in mutually exclusive manner. It implies, if two process cannot use the same resource at the same time. Hold and Wait A process waits for some resources while holding another resource at the same time. No preemption The process which once scheduled will be executed till the completion. No other process can be scheduled by the scheduler meanwhile. Circular Wait All the processes must be waiting for the resources in a cyclic manner so that the last process is waiting for the resource which is being held by the first process.","title":"Necessary conditions for Deadlocks"},{"location":"Operating%20System/06.%20Deadlock/#strategies-to-handle-deadlock","text":"Deadlock Ignorance Deadlock Ignorance is the most widely used approach among all the mechanism. This is being used by many operating systems mainly for end user uses. In this approach, the Operating system assumes that deadlock never occurs. It simply ignores deadlock. This approach is best suitable for a single end user system where User uses the system only for browsing and all other normal stuff. Deadlock prevention Deadlock happens only when Mutual Exclusion, hold and wait, No preemption and circular wait holds simultaneously. If it is possible to violate one of the four conditions at any time then the deadlock can never occur in the system. The idea behind the approach is very simple that we have to fail one of the four conditions but there can be a big argument on its physical implementation in the system. Deadlock avoidance In deadlock avoidance, the operating system checks whether the system is in safe state or in unsafe state at every step which the operating system performs. The process continues until the system is in safe state. Once the system moves to unsafe state, the OS has to backtrack one step. In simple words, The OS reviews each allocation so that the allocation doesn't cause the deadlock in the system. Deadlock detection and recovery This approach let the processes fall in deadlock and then periodically check whether deadlock occur in the system or not. If it occurs then it applies some of the recovery methods to the system to get rid of deadlock.","title":"Strategies to handle Deadlock"},{"location":"Operating%20System/06.%20Deadlock/#deadlock-prevention","text":"If we can be able to violate one of the four necessary conditions and don't let them occur together then we can prevent the deadlock. Mutual Exclusion Spooling can be an effective approach to violate mutual exclusion but it suffers from some kinds of problems. We cannot violate mutual exclusion for a process practically. Hold and Wait A process must be assigned all the necessary resources before the execution starts. A process must not wait for any resource once the execution has been started. But it is practically not possible. Possibility of getting starved will be increases due to the fact that some process may hold a resource for a very long time. No Preemption If we take the resource away from the process which is causing deadlock then we can prevent deadlock. This is not a good approach at all since if we take a resource away which is being used by the process then all the work which it has done till now can become inconsistent. Circular Wait To violate circular wait, we can assign a priority number to each of the resource. A process can't request for a lesser priority resource. This ensures that not a single process can request a resource which is being utilized by some other process and no cycle will be formed. Among all the methods, violating Circular wait is the only approach that can be implemented practically.","title":"Deadlock Prevention"},{"location":"Operating%20System/06.%20Deadlock/#deadlock-avoidance","text":"In deadlock avoidance, the request for any resource will be granted if the resulting state of the system doesn't cause deadlock in the system. The state of the system will continuously be checked for safe and unsafe states. In order to avoid deadlocks, the process must tell OS, the maximum number of resources a process can request to complete its execution. The simplest and most useful approach states that the process should declare the maximum number of resources of each type it may ever need. The Deadlock avoidance algorithm examines the resource allocations so that there can never be a circular wait condition. A state of the system is called safe if the system can allocate all the resources requested by all the processes without entering into deadlock. If the system cannot fulfill the request of all processes then the state of the system is called unsafe. The key of Deadlock avoidance approach is when the request is made for resources then the request must only be approved in the case if the resulting state is also a safe state.","title":"Deadlock Avoidance"},{"location":"Operating%20System/06.%20Deadlock/#deadlock-detection","text":"The OS can detect the deadlocks with the help of Resource allocation graph. Detection Single Instance --> Detect Cycle Multiple Instance --> Safety Algorithm In single instanced resource types, if a cycle is being formed in the system then there will definitely be a deadlock. In multiple instanced resource type graph, detecting a cycle is not just enough. We have to apply the safety algorithm on the system by converting the resource allocation graph into the allocation matrix and request matrix.","title":"Deadlock Detection"},{"location":"Operating%20System/06.%20Deadlock/#deadlock-recovery","text":"In order to recover the system from deadlocks, either OS considers resources or processes. For Resource Preempt the resource We can snatch one of the resources from the owner of the resource (process) and give it to the other process with the expectation that it will complete the execution and will release this resource sooner. Well, choosing a resource which will be snatched is going to be a bit difficult. Rollback to a safe state System passes through various states to get into the deadlock state. The operating system canrollback the system to the previous safe state. For this purpose, OS needs to implement check pointing at every state. The moment, we get into deadlock, we will rollback all the allocations to get into the previous safe state. For Process Kill a process Killing a process can solve our problem but the bigger concern is to decide which process to kill. Generally, Operating system kills a process which has done least amount of work until now. Kill all process This is not a suggestible approach but can be implemented if the problem becomes very serious. Killing all process will lead to inefficiency in the system because all the processes will execute again from starting.","title":"Deadlock Recovery"},{"location":"Operating%20System/07.Process%20and%20Threads/","text":"Process and Threads A process is a program in execution. A thread is a lightweight process. We achieve parallelism in OS by dividing a process into multiple threads. Similarity between Threads and Processes \u2013 Only one thread or process is active at a time Within process both execute sequential Both can create children Differences between Threads and Processes \u2013 Threads are not independent, processes are. Threads are designed to assist each other, processes may or may not do it Advantages of Thread over Process Responsiveness If the process is divided into multiple threads, if one thread completes its execution, then its output can be immediately returned. Faster context switch Context switch time between threads is lower compared to process context switch. Process context switching requires more overhead from the CPU. Effective utilization of multiprocessor system If we have multiple threads in a single process, then we can schedule multiple threads on multiple processor. This will make process execution faster. Resource sharing Resources like code, data, and files can be shared among all threads within a process. Note: stack and registers can\u2019t be shared among the threads. Each thread has its own stack and registers. Communication Communication between multiple threads is easier, as the threads shares common address space. While in process we have to follow some specific communication technique for communication between two process. Enhanced throughput of the system If a process is divided into multiple threads, and each thread function is considered as one job, then the number of jobs completed per unit of time is increased, thus increasing the throughput of the system. Types of Threads: User Level thread (ULT) User threads are implemented by users. Operating System doesn\u2019t recognize user level threads. Context switch time is less. If one user level thread performs blocking operation then entire process will be blocked. Multithreaded applications on user-level threads cannot benefit from multiprocessing. Kernel Level Thread (KLT) Kernel threads are implemented by Operating System (OS). Kernel threads are recognized by Operating System. Context switch time is more. If one kernel thread perform blocking operation then another thread can continue execution. Transferring control within a process from one thread to another necessitates a mode switch to kernel mode.","title":"Process and Threads"},{"location":"Operating%20System/07.Process%20and%20Threads/#process-and-threads","text":"A process is a program in execution. A thread is a lightweight process. We achieve parallelism in OS by dividing a process into multiple threads.","title":"Process and Threads"},{"location":"Operating%20System/07.Process%20and%20Threads/#similarity-between-threads-and-processes","text":"Only one thread or process is active at a time Within process both execute sequential Both can create children","title":"Similarity between Threads and Processes \u2013"},{"location":"Operating%20System/07.Process%20and%20Threads/#differences-between-threads-and-processes","text":"Threads are not independent, processes are. Threads are designed to assist each other, processes may or may not do it","title":"Differences between Threads and Processes \u2013"},{"location":"Operating%20System/07.Process%20and%20Threads/#advantages-of-thread-over-process","text":"Responsiveness If the process is divided into multiple threads, if one thread completes its execution, then its output can be immediately returned. Faster context switch Context switch time between threads is lower compared to process context switch. Process context switching requires more overhead from the CPU. Effective utilization of multiprocessor system If we have multiple threads in a single process, then we can schedule multiple threads on multiple processor. This will make process execution faster. Resource sharing Resources like code, data, and files can be shared among all threads within a process. Note: stack and registers can\u2019t be shared among the threads. Each thread has its own stack and registers. Communication Communication between multiple threads is easier, as the threads shares common address space. While in process we have to follow some specific communication technique for communication between two process. Enhanced throughput of the system If a process is divided into multiple threads, and each thread function is considered as one job, then the number of jobs completed per unit of time is increased, thus increasing the throughput of the system.","title":"Advantages of Thread over Process"},{"location":"Operating%20System/07.Process%20and%20Threads/#types-of-threads","text":"User Level thread (ULT) User threads are implemented by users. Operating System doesn\u2019t recognize user level threads. Context switch time is less. If one user level thread performs blocking operation then entire process will be blocked. Multithreaded applications on user-level threads cannot benefit from multiprocessing. Kernel Level Thread (KLT) Kernel threads are implemented by Operating System (OS). Kernel threads are recognized by Operating System. Context switch time is more. If one kernel thread perform blocking operation then another thread can continue execution. Transferring control within a process from one thread to another necessitates a mode switch to kernel mode.","title":"Types of Threads:"},{"location":"Operating%20System/08.Memory%20Management/","text":"Memory Management Memory devices are digital system that store data either temporarily or for a long term. Memories are made up of registers. Each register in the memory is one storage location/ memory location. Memory locations are identified using Address. The total number of bits a memory can store is its capacity. Each register is made up of a storage element in which one bit of data is stored. The data in a memory are stored and retrieved by the process called writing and reading respectively. Following are some important memory units : Bit (Binary Units): bit is a logical representation of the electric state. It can be 1 or 0. Nibble: it means the group of 4 bits. Byte: a byte is a group of 8 bits. Word: it is a fixed number of bits, it is different from computer to computer, but the same for each device. Compute store information in the form of words. Following are conversations of units: Kilobyte (kb): 1kb = 1024 byte Megabyte (mb): 1mb = 1024 kb Gigabyte (gb): 1gb = 1024 mb Terabyte (tb): 1tb = 1024 gb Petabyte (pb): 1pb = 1024 tb Four common memory management techniques in operating system Single contiguous allocation Simplest allocation method used by MS-DOS. All memory (except some reserved for OS) is available to a process. Partitioned allocation Memory is divided into different blocks or partitions. Each process is allocated according to the requirement. Paged memory management Memory is divided into fixed-sized units called page frames, used in a virtual memory environment. Segmented memory management Memory is divided into different segments (a segment is a logical grouping of the process\u2019 data or code).In this management, allocated memory doesn\u2019t have to be contiguous. Partition Allocation In Partition Allocation, when there is more than one partition freely available to accommodate a process\u2019s request, a partition must be selected. To choose a particular partition, a partition allocation method is needed. A partition allocation method is considered better if it avoids internal fragmentation. When it is time to load a process into the main memory and if there is more than one free block of memory of sufficient size then the OS decides which free block to allocate. There are different Placement Algorithm: First Fit In the first fit, the partition is allocated which is the first sufficient block from the top of Main Memory. It scans memory from the beginning and chooses the first available block that is large enough. Thus it allocates the first hole that is large enough. Best Fit Allocate the process to the partition which is the first smallest sufficient partition among the free available partition. It searches the entire list of holes to find the smallest hole whose size is greater than or equal to the size of the process. Worst Fit Allocate the process to the partition which is the largest sufficient among the freely available partitions available in the main memory. It is opposite to the best-fit algorithm. It searches the entire list of holes to find the largest hole and allocate it to process. Next Fit Next fit is similar to the first fit but it will search for the first sufficient partition from the last allocation point. Contiguous Memory Management There are two Memory Management Techniques: Contiguous, and Non-Contiguous. In Contiguous Technique, executing process must be loaded entirely in the main memory. Contiguous Technique can be divided into: Fixed (or static) partitioning Variable (or dynamic) partitioning Fixed / Static Partitioning In this technique, the main memory is divided into partitions of equal or different sizes. The operating system always resides in the first partition while the other partitions can be used to store user processes. The memory is assigned to the processes in contiguous way. In fixed partitioning, the partitions cannot overlap and a process must be contiguously present in a partition for the execution. Advantages of Fixed Partitioning: Easy to implement: Algorithms needed to implement Fixed Partitioning are easy to implement. It simply requires putting a process into a certain partition without focusing on the emergence of Internal and External Fragmentation. Little OS overhead: Processing of Fixed Partitioning requires lesser excess and indirect computational power. Disadvantages of Fixed Partitioning Internal Fragmentation: Main memory use is inefficient. Any program, no matter how small, occupies an entire partition. This can cause internal fragmentation. External Fragmentation: The total unused space (as stated above) of various partitions cannot be used to load the processes even though there is space available but not in the contiguous form (as spanning is not allowed). Limit process size: Process of size greater than the size of the partition in Main Memory cannot be accommodated. The partition size cannot be varied according to the size of the incoming process size. Hence, the process size of 32MB in the above-stated example is invalid. Limitation on Degree of Multiprogramming: Partitions in Main Memory are made before execution or during system configure. Main Memory is divided into a fixed number of partitions. Suppose if there are n1 partitions in RAM and n2 are the number of processes, then n2 <= n1 condition must be fulfilled. Number of processes greater than the number of partitions in RAM is invalid in Fixed Partitioning. Variable / Dynamic Partitioning Dynamic partitioning tries to overcome the problems caused by fixed partitioning. In this technique, the partition size is not declared initially. It is declared at the time of process loading. The first partition is reserved for the operating system. The remaining space is divided into parts. The size of each partition will be equal to the size of the process. The partition size varies according to the need of the process so that the internal fragmentation can be avoided. Advantages of Variable Partitioning \u2013 No Internal Fragmentation: In variable Partitioning, space in main memory is allocated strictly according to the need of process, hence there is no case of internal fragmentation. There will be no unused space left in the partition. No restriction on Degree of Multiprogramming: More number of processes can be accommodated due to absence of internal fragmentation. A process can be loaded until the memory is empty. No Limitation on the size of the process: In Fixed partitioning, the process with the size greater than the size of the largest partition could not be loaded and process can not be divided as it is invalid in contiguous allocation technique. Here, In variable partitioning, the process size can\u2019t be restricted since the partition size is decided according to the process size. Disadvantages of Variable Partitioning \u2013 Difficult Implementation: Implementing variable Partitioning is difficult as compared to Fixed Partitioning as it involves allocation of memory during run-time rather than during system configure. External Fragmentation: There will be external fragmentation inspite of absence of internal fragmentation.","title":"Memory Management"},{"location":"Operating%20System/08.Memory%20Management/#memory-management","text":"Memory devices are digital system that store data either temporarily or for a long term. Memories are made up of registers. Each register in the memory is one storage location/ memory location. Memory locations are identified using Address. The total number of bits a memory can store is its capacity. Each register is made up of a storage element in which one bit of data is stored. The data in a memory are stored and retrieved by the process called writing and reading respectively.","title":"Memory Management"},{"location":"Operating%20System/08.Memory%20Management/#following-are-some-important-memory-units","text":"Bit (Binary Units): bit is a logical representation of the electric state. It can be 1 or 0. Nibble: it means the group of 4 bits. Byte: a byte is a group of 8 bits. Word: it is a fixed number of bits, it is different from computer to computer, but the same for each device. Compute store information in the form of words.","title":"Following are some important memory units :"},{"location":"Operating%20System/08.Memory%20Management/#following-are-conversations-of-units","text":"Kilobyte (kb): 1kb = 1024 byte Megabyte (mb): 1mb = 1024 kb Gigabyte (gb): 1gb = 1024 mb Terabyte (tb): 1tb = 1024 gb Petabyte (pb): 1pb = 1024 tb","title":"Following are conversations of units:"},{"location":"Operating%20System/08.Memory%20Management/#four-common-memory-management-techniques-in-operating-system","text":"Single contiguous allocation Simplest allocation method used by MS-DOS. All memory (except some reserved for OS) is available to a process. Partitioned allocation Memory is divided into different blocks or partitions. Each process is allocated according to the requirement. Paged memory management Memory is divided into fixed-sized units called page frames, used in a virtual memory environment. Segmented memory management Memory is divided into different segments (a segment is a logical grouping of the process\u2019 data or code).In this management, allocated memory doesn\u2019t have to be contiguous.","title":"Four common memory management techniques in operating system"},{"location":"Operating%20System/08.Memory%20Management/#partition-allocation","text":"In Partition Allocation, when there is more than one partition freely available to accommodate a process\u2019s request, a partition must be selected. To choose a particular partition, a partition allocation method is needed. A partition allocation method is considered better if it avoids internal fragmentation. When it is time to load a process into the main memory and if there is more than one free block of memory of sufficient size then the OS decides which free block to allocate. There are different Placement Algorithm: First Fit In the first fit, the partition is allocated which is the first sufficient block from the top of Main Memory. It scans memory from the beginning and chooses the first available block that is large enough. Thus it allocates the first hole that is large enough. Best Fit Allocate the process to the partition which is the first smallest sufficient partition among the free available partition. It searches the entire list of holes to find the smallest hole whose size is greater than or equal to the size of the process. Worst Fit Allocate the process to the partition which is the largest sufficient among the freely available partitions available in the main memory. It is opposite to the best-fit algorithm. It searches the entire list of holes to find the largest hole and allocate it to process. Next Fit Next fit is similar to the first fit but it will search for the first sufficient partition from the last allocation point.","title":"Partition Allocation"},{"location":"Operating%20System/08.Memory%20Management/#contiguous-memory-management","text":"There are two Memory Management Techniques: Contiguous, and Non-Contiguous. In Contiguous Technique, executing process must be loaded entirely in the main memory. Contiguous Technique can be divided into: Fixed (or static) partitioning Variable (or dynamic) partitioning","title":"Contiguous Memory Management"},{"location":"Operating%20System/08.Memory%20Management/#fixed-static-partitioning","text":"In this technique, the main memory is divided into partitions of equal or different sizes. The operating system always resides in the first partition while the other partitions can be used to store user processes. The memory is assigned to the processes in contiguous way. In fixed partitioning, the partitions cannot overlap and a process must be contiguously present in a partition for the execution. Advantages of Fixed Partitioning: Easy to implement: Algorithms needed to implement Fixed Partitioning are easy to implement. It simply requires putting a process into a certain partition without focusing on the emergence of Internal and External Fragmentation. Little OS overhead: Processing of Fixed Partitioning requires lesser excess and indirect computational power. Disadvantages of Fixed Partitioning Internal Fragmentation: Main memory use is inefficient. Any program, no matter how small, occupies an entire partition. This can cause internal fragmentation. External Fragmentation: The total unused space (as stated above) of various partitions cannot be used to load the processes even though there is space available but not in the contiguous form (as spanning is not allowed). Limit process size: Process of size greater than the size of the partition in Main Memory cannot be accommodated. The partition size cannot be varied according to the size of the incoming process size. Hence, the process size of 32MB in the above-stated example is invalid. Limitation on Degree of Multiprogramming: Partitions in Main Memory are made before execution or during system configure. Main Memory is divided into a fixed number of partitions. Suppose if there are n1 partitions in RAM and n2 are the number of processes, then n2 <= n1 condition must be fulfilled. Number of processes greater than the number of partitions in RAM is invalid in Fixed Partitioning.","title":"Fixed / Static Partitioning"},{"location":"Operating%20System/08.Memory%20Management/#variable-dynamic-partitioning","text":"Dynamic partitioning tries to overcome the problems caused by fixed partitioning. In this technique, the partition size is not declared initially. It is declared at the time of process loading. The first partition is reserved for the operating system. The remaining space is divided into parts. The size of each partition will be equal to the size of the process. The partition size varies according to the need of the process so that the internal fragmentation can be avoided. Advantages of Variable Partitioning \u2013 No Internal Fragmentation: In variable Partitioning, space in main memory is allocated strictly according to the need of process, hence there is no case of internal fragmentation. There will be no unused space left in the partition. No restriction on Degree of Multiprogramming: More number of processes can be accommodated due to absence of internal fragmentation. A process can be loaded until the memory is empty. No Limitation on the size of the process: In Fixed partitioning, the process with the size greater than the size of the largest partition could not be loaded and process can not be divided as it is invalid in contiguous allocation technique. Here, In variable partitioning, the process size can\u2019t be restricted since the partition size is decided according to the process size. Disadvantages of Variable Partitioning \u2013 Difficult Implementation: Implementing variable Partitioning is difficult as compared to Fixed Partitioning as it involves allocation of memory during run-time rather than during system configure. External Fragmentation: There will be external fragmentation inspite of absence of internal fragmentation.","title":"Variable / Dynamic Partitioning"}]}